{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import tiktoken\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import inspect\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size:int = 1024 # this is max sequence len\n",
    "    vocab_size:int = 50304 #50257 # total vocab including 256 bytes + 1 special token (<|endoftext|>) and 1000-257 BPE merges\n",
    "    n_layer:int = 12 # number of layers \n",
    "    n_head:int = 12 # total number of attention heads\n",
    "    n_embd: int = 768 # embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        n_head = config.n_head\n",
    "        n_embd = config.n_embd\n",
    "        \n",
    "        assert n_embd % n_head == 0\n",
    "        \n",
    "        # query, key, value prjections all combined\n",
    "        self.c_attn = nn.Linear(n_embd, 3 * n_embd)\n",
    "        \n",
    "        # output projection, after `v` is already multiplied with attention_scores\n",
    "        self.c_proj = nn.Linear(n_embd, n_embd)\n",
    "        \n",
    "        self.c_proj.NANOGPT_SCALE_INIT=1\n",
    "\n",
    "        block_size = config.block_size\n",
    "        \n",
    "        self.register_buffer('bias', torch.tril(torch.ones(block_size, block_size)).view(1, 1, block_size, block_size))\n",
    "        \n",
    "        self.n_embd = n_embd\n",
    "        self.n_head = n_head\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch_size, sequence_len, embedding_dim (n_embd)\n",
    "        # total dim = n_head * head_size\n",
    "        # example GPT2 has 12 heads with each hs = 64 thus C= 12*64 = 768\n",
    "\n",
    "        qkv = self.c_attn(x) # get combined qkv matix B, T, n_embd * 3(768*3=2304)\n",
    "\n",
    "        q, k, v = qkv.split(self.n_embd, dim=2) # each item gets n_embd size, dimension against two \n",
    "\n",
    "        # b, seq, n_embd -> b, seq, n_heads, head_size -> b, n_heads, seq_len, head_size\n",
    "        q = q.view(B, T, self.n_head, C//self.n_head).transpose(1, 2)\n",
    "        # final-> bs, n_heads, seq_len, mini-n_head_embd\n",
    "\n",
    "        k = k.view(B, T, self.n_head, C//self.n_head).transpose(1, 2)\n",
    "        \n",
    "        v = v.view(B, T, self.n_head, C//self.n_head).transpose(1, 2)\n",
    "        \n",
    "        # # print(f\"shape of q: {q.shape}... shape of k : {k.shape}\")\n",
    "        \n",
    "        # attn = (q @ k.transpose(-2, -1))/(math.sqrt(k.shape[-1]))\n",
    "\n",
    "        # # apply masked fill at places where mask ==0, remember tril is lower triangle\n",
    "        # attn = attn.masked_fill(mask = self.bias[ : , : , :T, :T] == 0, value=float('-inf'))\n",
    "        \n",
    "        # attn = F.softmax(attn, dim=-1)\n",
    "        \n",
    "        # y = attn @ v # B, n_heads, T/seq, T @ B, n_heads, T/Seq, head_size) -> B, n_heads, T, head_size\n",
    "\n",
    "        y = F.scaled_dot_product_attention(q, k, v, is_causal=True) # flash attention\n",
    "        \n",
    "        # transpose y to merge all n_heads. B, n_heads, T, head_size -> transpose B, T, n_heads, head_size -> view B, T, Channel_size/n_emb 768 \n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        \n",
    "        # out projection, B, T, C -> B, T, C\n",
    "        y = self.c_proj(y)\n",
    "        \n",
    "        return y\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc = nn.Linear(config.n_embd, 4 * config.n_embd)\n",
    "        self.gelu = nn.GELU(approximate='tanh')\n",
    "        self.c_proj = nn.Linear(4 * config.n_embd, config.n_embd)\n",
    "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
    "        self.mlp = MLP(config)\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "    \n",
    "        self.transformer = nn.ModuleDict(\n",
    "            dict(\n",
    "                wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "                wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "                h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "                ln_f = nn.LayerNorm(config.n_embd)\n",
    "            ))\n",
    "\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        \n",
    "        # weight sharing\n",
    "        self.transformer.wte.weights = self.lm_head.weight\n",
    "\n",
    "        # weight initialization\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            std = 0.02\n",
    "            if hasattr(module, 'NANOGPT_SCALE_INIT'):\n",
    "                std *= (2 * self.config.n_layer) ** -0.5\n",
    "\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=std)\n",
    "            \n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.normal_(module.bias, mean=0.0, std=std)\n",
    "        \n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.size() # batch , seq_len\n",
    "\n",
    "        # check if incoming seq_len of idx is within limits\n",
    "        assert T <= self.config.block_size, f\"Cannot proceed as your Sequence len : {T} is more than {self.config.block_size}\"\n",
    "\n",
    "        # forward for token and position encodings\n",
    "        # shape (T)\n",
    "        pos = torch.arange(0, T, dtype=torch.int32, device=idx.device)\n",
    "        pos_emb = self.transformer.wpe(pos) # position embds of shape (T, n_embd)\n",
    "        token_emb = self.transformer.wte(idx) # token embds of shape (Batch, T/seq_len, n_embd)\n",
    "\n",
    "        x = pos_emb + token_emb\n",
    "\n",
    "        # now forward through transformer blocks\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        \n",
    "        # pass through final layernorm\n",
    "        x = self.transformer.ln_f(x)\n",
    "\n",
    "        # pass through final LM_HEAD\n",
    "        logits = self.lm_head(x) # shape (Batch_size, T, vocab_size)\n",
    "\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "        \n",
    "        return logits, loss\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_name):\n",
    "        \"\"\"for loading pre-trained GPT model weights from HuggingFace\"\"\"\n",
    "        assert model_name in ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl']\n",
    "\n",
    "        from transformers import GPT2LMHeadModel\n",
    "        \n",
    "        print(f\"Loading weights from pretrained GPT model: {model_name}\")\n",
    "\n",
    "        # n_layer, n_head, n_embd for each model_name\n",
    "        config_args = {\n",
    "            'gpt2':        dict(n_layer=12, n_embd=768, n_head=12), # has 124M params\n",
    "            'gpt2-medium': dict(n_layer=24, n_embd=1024, n_head=16), # 350M params\n",
    "            'gpt2-large':  dict(n_layer=36, n_embd=1280, n_head=20), # 774M params\n",
    "            'gpt2-xl':     dict(n_layer=48, n_embd=1600, n_head=25) # 1558M params\n",
    "            \n",
    "        }[model_name]\n",
    "\n",
    "        config_args['vocab_size'] = 50257 # same for all GPT2 checkpoints\n",
    "        config_args['block_size']= 1024 # max seq len 1024 for all GPT2 checkpoints\n",
    "\n",
    "        config = GPTConfig(**config_args)\n",
    "        model = GPT(config)\n",
    "\n",
    "        sd = model.state_dict()\n",
    "        sd_keys = sd.keys()\n",
    "        sd_keys = [key for key in sd_keys if not key.endswith('.attn.bias')] # discard this mask, not a parameter\n",
    "\n",
    "        # initialize transformer model\n",
    "        model_hf = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "        sd_hf = model_hf.state_dict()\n",
    "        sd_hf_keys = [key for key in sd_hf.keys() if not key.endswith('.attn.masked_bias')] # to discard, not a parameter\n",
    "        sd_hf_keys = [key for key in sd_hf.keys() if not key.endswith('.attn.bias')] # to discard, not a param\n",
    "\n",
    "        # transposing these to match openai's Conv1d usage with Linear layer\n",
    "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
    "\n",
    "        print(\"=======\\nDifference in keys: \", set(sd_keys)- set(sd_hf_keys))\n",
    "        assert len(sd_keys) == len(sd_hf_keys), f\"mismatched keys: sd_keys {len(sd_keys)} != sd_hd_keys {len(sd_hf_keys)}\"\n",
    "\n",
    "        for key in sd_hf_keys:\n",
    "            if any(key.endswith(w) for w in transposed):\n",
    "                assert sd_hf[key].shape[::-1] == sd[key].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[key].copy_(sd_hf[key].t())\n",
    "            else:\n",
    "                # simple copy for other params\n",
    "                assert sd_hf[key].shape == sd[key].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[key].copy_(sd_hf[key])\n",
    "                    \n",
    "        return model            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderLite:\n",
    "    def __init__(self, B, T):\n",
    "        self.B = B \n",
    "        self.T = T \n",
    "\n",
    "        with open('input.txt', 'r') as f:\n",
    "            text = f.read()\n",
    "        enc = tiktoken.get_encoding('gpt2')\n",
    "        tokens = enc.encode(text)\n",
    "        self.tokens = torch.tensor(tokens)\n",
    "        print(f'loaded len : {len(self.tokens)}')\n",
    "        print(f'1 epoch = :{len(self.tokens)}//{B*T} = {len(self.tokens)//(B*T)} batches ')\n",
    "        self.current_position = 0\n",
    "    \n",
    "    def next_batch(self):\n",
    "        B, T = self.B, self.T\n",
    "        buf = self.tokens[self.current_position: self.current_position + (B*T) + 1]\n",
    "        x = buf[:-1].view(B, T)\n",
    "        y = buf[1:].view(B, T)\n",
    "\n",
    "        self.current_position += (B*T)\n",
    "        \n",
    "        if self.current_position + (B*T+1) > len(self.tokens):\n",
    "            self.current_position = 0\n",
    "        return x, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest\n"
     ]
    }
   ],
   "source": [
    "current_precision = torch.get_float32_matmul_precision()\n",
    "print(current_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lr = 6e-4\n",
    "min_lr = 0.1 * max_lr\n",
    "warmup_steps = 10\n",
    "max_steps = 5001\n",
    "\n",
    "def get_lr(iteration):\n",
    "    if iteration < warmup_steps:\n",
    "        return max_lr * (iteration + 1) / warmup_steps\n",
    "    if iteration > max_steps:\n",
    "        return min_lr\n",
    "    \n",
    "    decay_ratio = (iteration - warmup_steps) / (max_steps - warmup_steps)\n",
    "\n",
    "    assert 0<= decay_ratio <= 1\n",
    "\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))\n",
    "    return min_lr + coeff * (max_lr - min_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded len : 338025\n",
      "1 epoch = :338025//6144 = 55 batches \n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "model = GPT(GPTConfig()).to(device=device)\n",
    "\n",
    "model = torch.compile(model)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, betas=(0.9, 0.95), eps=1e-8)\n",
    "\n",
    "train_loader = DataLoaderLite(B=6, T=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "torch.set_default_device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4221/3327562475.py:14: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  norm = torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 1 | loss: 11.10009765625 | dt: 22404.92 ms | tokens/sec: 0.27 | norm: 30.93\n",
      "step : 2 | loss: 9.684245109558105 | dt: 162.48 ms | tokens/sec: 37.81 | norm: 10.44\n",
      "step : 3 | loss: 9.328428268432617 | dt: 160.54 ms | tokens/sec: 38.27 | norm: 10.06\n",
      "step : 4 | loss: 9.752235412597656 | dt: 162.75 ms | tokens/sec: 37.75 | norm: 8.24\n",
      "step : 5 | loss: 9.087626457214355 | dt: 163.51 ms | tokens/sec: 37.58 | norm: 4.45\n",
      "step : 6 | loss: 8.638827323913574 | dt: 161.53 ms | tokens/sec: 38.04 | norm: 3.77\n",
      "step : 7 | loss: 8.41390609741211 | dt: 161.07 ms | tokens/sec: 38.14 | norm: 2.47\n",
      "step : 8 | loss: 8.253558158874512 | dt: 164.26 ms | tokens/sec: 37.41 | norm: 2.76\n",
      "step : 9 | loss: 8.03589153289795 | dt: 165.65 ms | tokens/sec: 37.09 | norm: 1.94\n",
      "step : 10 | loss: 7.661974906921387 | dt: 165.56 ms | tokens/sec: 37.11 | norm: 2.23\n",
      "step : 11 | loss: 7.307131767272949 | dt: 165.59 ms | tokens/sec: 37.10 | norm: 1.84\n",
      "step : 12 | loss: 6.8668317794799805 | dt: 165.55 ms | tokens/sec: 37.11 | norm: 1.39\n",
      "step : 13 | loss: 6.7868194580078125 | dt: 163.28 ms | tokens/sec: 37.63 | norm: 1.38\n",
      "step : 14 | loss: 6.857018947601318 | dt: 163.20 ms | tokens/sec: 37.65 | norm: 1.96\n",
      "step : 15 | loss: 6.691928863525391 | dt: 163.05 ms | tokens/sec: 37.68 | norm: 1.58\n",
      "step : 16 | loss: 6.695217132568359 | dt: 163.89 ms | tokens/sec: 37.49 | norm: 1.27\n",
      "step : 17 | loss: 6.800302505493164 | dt: 164.33 ms | tokens/sec: 37.39 | norm: 1.71\n",
      "step : 18 | loss: 6.646496772766113 | dt: 165.15 ms | tokens/sec: 37.20 | norm: 1.54\n",
      "step : 19 | loss: 6.689803123474121 | dt: 161.93 ms | tokens/sec: 37.94 | norm: 1.04\n",
      "step : 20 | loss: 6.521544456481934 | dt: 161.73 ms | tokens/sec: 37.99 | norm: 1.08\n",
      "step : 21 | loss: 6.355130195617676 | dt: 163.42 ms | tokens/sec: 37.60 | norm: 1.68\n",
      "step : 22 | loss: 6.435065269470215 | dt: 163.46 ms | tokens/sec: 37.59 | norm: 1.41\n",
      "step : 23 | loss: 6.65090274810791 | dt: 161.85 ms | tokens/sec: 37.96 | norm: 1.22\n",
      "step : 24 | loss: 6.5154523849487305 | dt: 162.63 ms | tokens/sec: 37.78 | norm: 1.25\n",
      "step : 25 | loss: 6.4257049560546875 | dt: 163.01 ms | tokens/sec: 37.69 | norm: 0.96\n",
      "step : 26 | loss: 6.495946884155273 | dt: 162.81 ms | tokens/sec: 37.74 | norm: 2.29\n",
      "step : 27 | loss: 6.218103408813477 | dt: 162.83 ms | tokens/sec: 37.73 | norm: 0.96\n",
      "step : 28 | loss: 6.368901252746582 | dt: 162.54 ms | tokens/sec: 37.80 | norm: 1.29\n",
      "step : 29 | loss: 6.214654922485352 | dt: 162.18 ms | tokens/sec: 37.88 | norm: 1.26\n",
      "step : 30 | loss: 6.3561859130859375 | dt: 164.03 ms | tokens/sec: 37.46 | norm: 0.97\n",
      "step : 31 | loss: 6.280693054199219 | dt: 164.97 ms | tokens/sec: 37.24 | norm: 0.98\n",
      "step : 32 | loss: 6.056710243225098 | dt: 162.85 ms | tokens/sec: 37.73 | norm: 1.12\n",
      "step : 33 | loss: 6.107884407043457 | dt: 163.20 ms | tokens/sec: 37.65 | norm: 0.99\n",
      "step : 34 | loss: 6.117105007171631 | dt: 163.00 ms | tokens/sec: 37.69 | norm: 0.83\n",
      "step : 35 | loss: 6.243123531341553 | dt: 163.16 ms | tokens/sec: 37.66 | norm: 0.89\n",
      "step : 36 | loss: 6.522308349609375 | dt: 163.62 ms | tokens/sec: 37.55 | norm: 1.22\n",
      "step : 37 | loss: 6.326089382171631 | dt: 163.29 ms | tokens/sec: 37.63 | norm: 1.17\n",
      "step : 38 | loss: 6.5673322677612305 | dt: 162.44 ms | tokens/sec: 37.82 | norm: 0.91\n",
      "step : 39 | loss: 6.463435173034668 | dt: 163.43 ms | tokens/sec: 37.59 | norm: 1.01\n",
      "step : 40 | loss: 6.363121032714844 | dt: 165.08 ms | tokens/sec: 37.22 | norm: 1.06\n",
      "step : 41 | loss: 6.2580413818359375 | dt: 166.49 ms | tokens/sec: 36.90 | norm: 0.90\n",
      "step : 42 | loss: 6.2939581871032715 | dt: 166.36 ms | tokens/sec: 36.93 | norm: 0.96\n",
      "step : 43 | loss: 6.0875959396362305 | dt: 165.20 ms | tokens/sec: 37.19 | norm: 1.39\n",
      "step : 44 | loss: 6.2136993408203125 | dt: 166.96 ms | tokens/sec: 36.80 | norm: 1.13\n",
      "step : 45 | loss: 6.46212911605835 | dt: 165.85 ms | tokens/sec: 37.05 | norm: 1.47\n",
      "step : 46 | loss: 6.228759765625 | dt: 165.83 ms | tokens/sec: 37.05 | norm: 1.07\n",
      "step : 47 | loss: 6.092523097991943 | dt: 168.23 ms | tokens/sec: 36.52 | norm: 1.10\n",
      "step : 48 | loss: 6.177619934082031 | dt: 166.83 ms | tokens/sec: 36.83 | norm: 1.19\n",
      "step : 49 | loss: 6.230700492858887 | dt: 167.67 ms | tokens/sec: 36.64 | norm: 1.12\n",
      "step : 50 | loss: 6.104436874389648 | dt: 167.01 ms | tokens/sec: 36.79 | norm: 1.13\n",
      "step : 51 | loss: 6.189250946044922 | dt: 167.00 ms | tokens/sec: 36.79 | norm: 0.87\n",
      "step : 52 | loss: 5.847774505615234 | dt: 165.39 ms | tokens/sec: 37.15 | norm: 0.90\n",
      "step : 53 | loss: 5.753443717956543 | dt: 163.54 ms | tokens/sec: 37.57 | norm: 1.07\n",
      "step : 54 | loss: 6.268733024597168 | dt: 164.54 ms | tokens/sec: 37.34 | norm: 1.19\n",
      "step : 55 | loss: 6.230944633483887 | dt: 162.64 ms | tokens/sec: 37.78 | norm: 1.30\n",
      "step : 56 | loss: 6.2223968505859375 | dt: 163.72 ms | tokens/sec: 37.53 | norm: 1.26\n",
      "step : 57 | loss: 6.189853191375732 | dt: 163.13 ms | tokens/sec: 37.66 | norm: 1.24\n",
      "step : 58 | loss: 6.111588954925537 | dt: 164.52 ms | tokens/sec: 37.35 | norm: 1.12\n",
      "step : 59 | loss: 5.863594055175781 | dt: 167.28 ms | tokens/sec: 36.73 | norm: 1.38\n",
      "step : 60 | loss: 5.7707624435424805 | dt: 164.49 ms | tokens/sec: 37.35 | norm: 1.08\n",
      "step : 61 | loss: 5.74588680267334 | dt: 165.51 ms | tokens/sec: 37.12 | norm: 1.13\n",
      "step : 62 | loss: 5.734625816345215 | dt: 164.70 ms | tokens/sec: 37.31 | norm: 0.95\n",
      "step : 63 | loss: 5.873880386352539 | dt: 162.81 ms | tokens/sec: 37.74 | norm: 0.79\n",
      "step : 64 | loss: 6.02418851852417 | dt: 161.78 ms | tokens/sec: 37.98 | norm: 1.54\n",
      "step : 65 | loss: 5.9061279296875 | dt: 163.58 ms | tokens/sec: 37.56 | norm: 1.47\n",
      "step : 66 | loss: 5.796863555908203 | dt: 163.76 ms | tokens/sec: 37.52 | norm: 1.41\n",
      "step : 67 | loss: 5.6203131675720215 | dt: 163.95 ms | tokens/sec: 37.47 | norm: 1.33\n",
      "step : 68 | loss: 5.8532257080078125 | dt: 161.18 ms | tokens/sec: 38.12 | norm: 1.51\n",
      "step : 69 | loss: 5.986993312835693 | dt: 162.89 ms | tokens/sec: 37.72 | norm: 1.32\n",
      "step : 70 | loss: 5.891768455505371 | dt: 163.15 ms | tokens/sec: 37.66 | norm: 1.08\n",
      "step : 71 | loss: 6.014451503753662 | dt: 163.03 ms | tokens/sec: 37.69 | norm: 0.98\n",
      "step : 72 | loss: 6.122903347015381 | dt: 163.23 ms | tokens/sec: 37.64 | norm: 1.07\n",
      "step : 73 | loss: 5.967319488525391 | dt: 164.33 ms | tokens/sec: 37.39 | norm: 1.03\n",
      "step : 74 | loss: 5.994091987609863 | dt: 162.14 ms | tokens/sec: 37.89 | norm: 0.92\n",
      "step : 75 | loss: 5.862301826477051 | dt: 165.51 ms | tokens/sec: 37.12 | norm: 0.82\n",
      "step : 76 | loss: 5.666970252990723 | dt: 163.33 ms | tokens/sec: 37.62 | norm: 1.00\n",
      "step : 77 | loss: 5.8314528465271 | dt: 162.05 ms | tokens/sec: 37.91 | norm: 0.96\n",
      "step : 78 | loss: 6.010867595672607 | dt: 162.96 ms | tokens/sec: 37.70 | norm: 0.92\n",
      "step : 79 | loss: 5.888007164001465 | dt: 161.88 ms | tokens/sec: 37.95 | norm: 0.96\n",
      "step : 80 | loss: 5.79096794128418 | dt: 162.60 ms | tokens/sec: 37.79 | norm: 0.99\n",
      "step : 81 | loss: 5.833209037780762 | dt: 162.00 ms | tokens/sec: 37.93 | norm: 1.17\n",
      "step : 82 | loss: 5.552943706512451 | dt: 163.70 ms | tokens/sec: 37.53 | norm: 0.84\n",
      "step : 83 | loss: 5.735569000244141 | dt: 161.48 ms | tokens/sec: 38.05 | norm: 1.02\n",
      "step : 84 | loss: 5.581080436706543 | dt: 162.98 ms | tokens/sec: 37.70 | norm: 1.15\n",
      "step : 85 | loss: 5.888493537902832 | dt: 162.07 ms | tokens/sec: 37.91 | norm: 1.09\n",
      "step : 86 | loss: 5.775688171386719 | dt: 162.15 ms | tokens/sec: 37.89 | norm: 1.13\n",
      "step : 87 | loss: 5.565017223358154 | dt: 162.21 ms | tokens/sec: 37.88 | norm: 1.13\n",
      "step : 88 | loss: 5.601511001586914 | dt: 165.07 ms | tokens/sec: 37.22 | norm: 0.91\n",
      "step : 89 | loss: 5.597573757171631 | dt: 163.99 ms | tokens/sec: 37.47 | norm: 0.74\n",
      "step : 90 | loss: 5.7119340896606445 | dt: 163.54 ms | tokens/sec: 37.57 | norm: 0.98\n",
      "step : 91 | loss: 5.9791693687438965 | dt: 163.42 ms | tokens/sec: 37.60 | norm: 1.24\n",
      "step : 92 | loss: 5.80098295211792 | dt: 163.19 ms | tokens/sec: 37.65 | norm: 1.23\n",
      "step : 93 | loss: 6.0931854248046875 | dt: 163.33 ms | tokens/sec: 37.62 | norm: 1.05\n",
      "step : 94 | loss: 5.967135429382324 | dt: 164.91 ms | tokens/sec: 37.26 | norm: 0.96\n",
      "step : 95 | loss: 5.810390472412109 | dt: 168.07 ms | tokens/sec: 36.56 | norm: 0.96\n",
      "step : 96 | loss: 5.748361110687256 | dt: 165.97 ms | tokens/sec: 37.02 | norm: 0.86\n",
      "step : 97 | loss: 5.720161437988281 | dt: 167.71 ms | tokens/sec: 36.64 | norm: 1.14\n",
      "step : 98 | loss: 5.5443854331970215 | dt: 167.25 ms | tokens/sec: 36.74 | norm: 1.25\n",
      "step : 99 | loss: 5.663510799407959 | dt: 167.17 ms | tokens/sec: 36.75 | norm: 0.95\n",
      "step : 100 | loss: 5.822196960449219 | dt: 165.78 ms | tokens/sec: 37.06 | norm: 1.47\n",
      "step : 101 | loss: 5.638801574707031 | dt: 167.38 ms | tokens/sec: 36.71 | norm: 1.26\n",
      "step : 102 | loss: 5.451410293579102 | dt: 165.49 ms | tokens/sec: 37.13 | norm: 1.18\n",
      "step : 103 | loss: 5.70349645614624 | dt: 165.49 ms | tokens/sec: 37.13 | norm: 1.06\n",
      "step : 104 | loss: 5.588952541351318 | dt: 165.94 ms | tokens/sec: 37.02 | norm: 1.18\n",
      "step : 105 | loss: 5.504215240478516 | dt: 165.10 ms | tokens/sec: 37.21 | norm: 1.13\n",
      "step : 106 | loss: 5.599501609802246 | dt: 168.14 ms | tokens/sec: 36.54 | norm: 0.80\n",
      "step : 107 | loss: 5.292520523071289 | dt: 167.66 ms | tokens/sec: 36.65 | norm: 1.13\n",
      "step : 108 | loss: 5.11155891418457 | dt: 164.46 ms | tokens/sec: 37.36 | norm: 1.34\n",
      "step : 109 | loss: 5.802077770233154 | dt: 163.95 ms | tokens/sec: 37.47 | norm: 1.20\n",
      "step : 110 | loss: 5.717334270477295 | dt: 163.15 ms | tokens/sec: 37.66 | norm: 1.19\n",
      "step : 111 | loss: 5.757880210876465 | dt: 162.32 ms | tokens/sec: 37.85 | norm: 1.30\n",
      "step : 112 | loss: 5.738889217376709 | dt: 174.35 ms | tokens/sec: 35.24 | norm: 1.13\n",
      "step : 113 | loss: 5.672037124633789 | dt: 166.62 ms | tokens/sec: 36.88 | norm: 1.08\n",
      "step : 114 | loss: 5.438596248626709 | dt: 166.77 ms | tokens/sec: 36.84 | norm: 1.40\n",
      "step : 115 | loss: 5.37153959274292 | dt: 163.42 ms | tokens/sec: 37.60 | norm: 1.15\n",
      "step : 116 | loss: 5.358905792236328 | dt: 165.15 ms | tokens/sec: 37.20 | norm: 1.23\n",
      "step : 117 | loss: 5.383878707885742 | dt: 164.51 ms | tokens/sec: 37.35 | norm: 1.16\n",
      "step : 118 | loss: 5.5146002769470215 | dt: 163.36 ms | tokens/sec: 37.61 | norm: 0.94\n",
      "step : 119 | loss: 5.598870754241943 | dt: 164.48 ms | tokens/sec: 37.35 | norm: 1.22\n",
      "step : 120 | loss: 5.511474132537842 | dt: 165.40 ms | tokens/sec: 37.15 | norm: 1.09\n",
      "step : 121 | loss: 5.3918304443359375 | dt: 164.10 ms | tokens/sec: 37.44 | norm: 1.08\n",
      "step : 122 | loss: 5.205634117126465 | dt: 164.32 ms | tokens/sec: 37.39 | norm: 0.97\n",
      "step : 123 | loss: 5.472499847412109 | dt: 163.59 ms | tokens/sec: 37.56 | norm: 1.16\n",
      "step : 124 | loss: 5.48648738861084 | dt: 162.64 ms | tokens/sec: 37.78 | norm: 1.15\n",
      "step : 125 | loss: 5.398102760314941 | dt: 162.97 ms | tokens/sec: 37.70 | norm: 1.07\n",
      "step : 126 | loss: 5.594508647918701 | dt: 166.52 ms | tokens/sec: 36.90 | norm: 0.90\n",
      "step : 127 | loss: 5.686964988708496 | dt: 164.15 ms | tokens/sec: 37.43 | norm: 0.90\n",
      "step : 128 | loss: 5.551347255706787 | dt: 164.33 ms | tokens/sec: 37.39 | norm: 0.84\n",
      "step : 129 | loss: 5.5940070152282715 | dt: 163.72 ms | tokens/sec: 37.53 | norm: 0.89\n",
      "step : 130 | loss: 5.5057783126831055 | dt: 164.16 ms | tokens/sec: 37.43 | norm: 0.96\n",
      "step : 131 | loss: 5.2717790603637695 | dt: 163.57 ms | tokens/sec: 37.56 | norm: 0.96\n",
      "step : 132 | loss: 5.472630977630615 | dt: 163.90 ms | tokens/sec: 37.49 | norm: 0.90\n",
      "step : 133 | loss: 5.67505407333374 | dt: 164.22 ms | tokens/sec: 37.41 | norm: 0.96\n",
      "step : 134 | loss: 5.545213222503662 | dt: 163.90 ms | tokens/sec: 37.49 | norm: 0.92\n",
      "step : 135 | loss: 5.43907356262207 | dt: 163.21 ms | tokens/sec: 37.65 | norm: 0.98\n",
      "step : 136 | loss: 5.489644527435303 | dt: 164.89 ms | tokens/sec: 37.26 | norm: 1.01\n",
      "step : 137 | loss: 5.210771083831787 | dt: 167.33 ms | tokens/sec: 36.72 | norm: 1.02\n",
      "step : 138 | loss: 5.408148765563965 | dt: 166.52 ms | tokens/sec: 36.90 | norm: 0.95\n",
      "step : 139 | loss: 5.220107555389404 | dt: 165.35 ms | tokens/sec: 37.16 | norm: 1.05\n",
      "step : 140 | loss: 5.5175909996032715 | dt: 162.85 ms | tokens/sec: 37.73 | norm: 0.96\n",
      "step : 141 | loss: 5.4387617111206055 | dt: 163.57 ms | tokens/sec: 37.56 | norm: 0.77\n",
      "step : 142 | loss: 5.1953020095825195 | dt: 163.63 ms | tokens/sec: 37.55 | norm: 1.02\n",
      "step : 143 | loss: 5.242005348205566 | dt: 164.00 ms | tokens/sec: 37.46 | norm: 0.85\n",
      "step : 144 | loss: 5.268470764160156 | dt: 163.30 ms | tokens/sec: 37.62 | norm: 0.76\n",
      "step : 145 | loss: 5.348067760467529 | dt: 164.48 ms | tokens/sec: 37.35 | norm: 0.74\n",
      "step : 146 | loss: 5.633455276489258 | dt: 162.65 ms | tokens/sec: 37.78 | norm: 1.18\n",
      "step : 147 | loss: 5.49118709564209 | dt: 163.73 ms | tokens/sec: 37.53 | norm: 1.11\n",
      "step : 148 | loss: 5.7727203369140625 | dt: 164.31 ms | tokens/sec: 37.39 | norm: 1.07\n",
      "step : 149 | loss: 5.646573066711426 | dt: 163.71 ms | tokens/sec: 37.53 | norm: 0.98\n",
      "step : 150 | loss: 5.4402313232421875 | dt: 162.79 ms | tokens/sec: 37.74 | norm: 0.94\n",
      "step : 151 | loss: 5.4453253746032715 | dt: 164.85 ms | tokens/sec: 37.27 | norm: 0.90\n",
      "step : 152 | loss: 5.370086193084717 | dt: 165.27 ms | tokens/sec: 37.17 | norm: 1.12\n",
      "step : 153 | loss: 5.192399024963379 | dt: 163.00 ms | tokens/sec: 37.69 | norm: 1.44\n",
      "step : 154 | loss: 5.316065311431885 | dt: 163.74 ms | tokens/sec: 37.52 | norm: 1.21\n",
      "step : 155 | loss: 5.4301300048828125 | dt: 164.19 ms | tokens/sec: 37.42 | norm: 1.46\n",
      "step : 156 | loss: 5.226282119750977 | dt: 166.09 ms | tokens/sec: 36.99 | norm: 1.17\n",
      "step : 157 | loss: 5.040551662445068 | dt: 163.52 ms | tokens/sec: 37.57 | norm: 0.91\n",
      "step : 158 | loss: 5.343737602233887 | dt: 164.04 ms | tokens/sec: 37.45 | norm: 0.87\n",
      "step : 159 | loss: 5.218757629394531 | dt: 162.26 ms | tokens/sec: 37.86 | norm: 1.14\n",
      "step : 160 | loss: 5.1088666915893555 | dt: 163.69 ms | tokens/sec: 37.53 | norm: 1.16\n",
      "step : 161 | loss: 5.235440254211426 | dt: 163.89 ms | tokens/sec: 37.49 | norm: 0.87\n",
      "step : 162 | loss: 4.945253372192383 | dt: 165.23 ms | tokens/sec: 37.18 | norm: 0.80\n",
      "step : 163 | loss: 4.7455644607543945 | dt: 164.06 ms | tokens/sec: 37.45 | norm: 1.20\n",
      "step : 164 | loss: 5.518276214599609 | dt: 165.34 ms | tokens/sec: 37.16 | norm: 1.49\n",
      "step : 165 | loss: 5.4151763916015625 | dt: 162.99 ms | tokens/sec: 37.70 | norm: 1.33\n",
      "step : 166 | loss: 5.484303951263428 | dt: 163.31 ms | tokens/sec: 37.62 | norm: 1.07\n",
      "step : 167 | loss: 5.453822135925293 | dt: 163.89 ms | tokens/sec: 37.49 | norm: 1.02\n",
      "step : 168 | loss: 5.407403469085693 | dt: 164.29 ms | tokens/sec: 37.40 | norm: 1.09\n",
      "step : 169 | loss: 5.139895915985107 | dt: 163.73 ms | tokens/sec: 37.53 | norm: 1.28\n",
      "step : 170 | loss: 5.098588466644287 | dt: 162.25 ms | tokens/sec: 37.87 | norm: 1.05\n",
      "step : 171 | loss: 5.070610046386719 | dt: 163.72 ms | tokens/sec: 37.53 | norm: 0.95\n",
      "step : 172 | loss: 5.119809150695801 | dt: 163.80 ms | tokens/sec: 37.51 | norm: 0.75\n",
      "step : 173 | loss: 5.2161712646484375 | dt: 163.92 ms | tokens/sec: 37.48 | norm: 0.89\n",
      "step : 174 | loss: 5.262554168701172 | dt: 164.39 ms | tokens/sec: 37.37 | norm: 1.35\n",
      "step : 175 | loss: 5.220679759979248 | dt: 162.38 ms | tokens/sec: 37.84 | norm: 1.25\n",
      "step : 176 | loss: 5.126997947692871 | dt: 162.10 ms | tokens/sec: 37.90 | norm: 0.92\n",
      "step : 177 | loss: 4.943514347076416 | dt: 164.56 ms | tokens/sec: 37.34 | norm: 0.99\n",
      "step : 178 | loss: 5.224382400512695 | dt: 163.32 ms | tokens/sec: 37.62 | norm: 0.95\n",
      "step : 179 | loss: 5.193009376525879 | dt: 163.00 ms | tokens/sec: 37.69 | norm: 0.94\n",
      "step : 180 | loss: 5.123692989349365 | dt: 163.41 ms | tokens/sec: 37.60 | norm: 0.99\n",
      "step : 181 | loss: 5.332751750946045 | dt: 163.10 ms | tokens/sec: 37.67 | norm: 0.76\n",
      "step : 182 | loss: 5.416444301605225 | dt: 163.60 ms | tokens/sec: 37.56 | norm: 0.78\n",
      "step : 183 | loss: 5.313813209533691 | dt: 164.40 ms | tokens/sec: 37.37 | norm: 0.68\n",
      "step : 184 | loss: 5.337543487548828 | dt: 164.10 ms | tokens/sec: 37.44 | norm: 0.75\n",
      "step : 185 | loss: 5.244372844696045 | dt: 163.19 ms | tokens/sec: 37.65 | norm: 0.90\n",
      "step : 186 | loss: 4.977265357971191 | dt: 162.57 ms | tokens/sec: 37.79 | norm: 0.98\n",
      "step : 187 | loss: 5.217350006103516 | dt: 163.03 ms | tokens/sec: 37.69 | norm: 0.86\n",
      "step : 188 | loss: 5.395930290222168 | dt: 163.96 ms | tokens/sec: 37.47 | norm: 0.96\n",
      "step : 189 | loss: 5.279680252075195 | dt: 163.28 ms | tokens/sec: 37.63 | norm: 0.88\n",
      "step : 190 | loss: 5.192592620849609 | dt: 173.64 ms | tokens/sec: 35.38 | norm: 0.93\n",
      "step : 191 | loss: 5.281192779541016 | dt: 163.57 ms | tokens/sec: 37.56 | norm: 1.09\n",
      "step : 192 | loss: 4.997927665710449 | dt: 164.24 ms | tokens/sec: 37.41 | norm: 0.89\n",
      "step : 193 | loss: 5.202946186065674 | dt: 164.83 ms | tokens/sec: 37.27 | norm: 1.09\n",
      "step : 194 | loss: 5.009853363037109 | dt: 164.02 ms | tokens/sec: 37.46 | norm: 1.04\n",
      "step : 195 | loss: 5.314821243286133 | dt: 163.73 ms | tokens/sec: 37.52 | norm: 0.78\n",
      "step : 196 | loss: 5.232276916503906 | dt: 164.55 ms | tokens/sec: 37.34 | norm: 0.90\n",
      "step : 197 | loss: 4.977268218994141 | dt: 167.17 ms | tokens/sec: 36.75 | norm: 1.11\n",
      "step : 198 | loss: 5.036656856536865 | dt: 167.42 ms | tokens/sec: 36.70 | norm: 0.82\n",
      "step : 199 | loss: 5.064925193786621 | dt: 166.11 ms | tokens/sec: 36.99 | norm: 0.90\n",
      "step : 200 | loss: 5.112695693969727 | dt: 166.26 ms | tokens/sec: 36.95 | norm: 0.74\n",
      "step : 201 | loss: 5.394561767578125 | dt: 166.48 ms | tokens/sec: 36.90 | norm: 1.21\n",
      "step : 202 | loss: 5.244211196899414 | dt: 168.00 ms | tokens/sec: 36.57 | norm: 1.20\n",
      "step : 203 | loss: 5.575984954833984 | dt: 165.87 ms | tokens/sec: 37.04 | norm: 1.13\n",
      "step : 204 | loss: 5.4339728355407715 | dt: 163.98 ms | tokens/sec: 37.47 | norm: 0.92\n",
      "step : 205 | loss: 5.235450744628906 | dt: 165.29 ms | tokens/sec: 37.17 | norm: 0.89\n",
      "step : 206 | loss: 5.247095108032227 | dt: 166.01 ms | tokens/sec: 37.01 | norm: 0.87\n",
      "step : 207 | loss: 5.147462844848633 | dt: 166.27 ms | tokens/sec: 36.95 | norm: 1.06\n",
      "step : 208 | loss: 5.005101203918457 | dt: 165.61 ms | tokens/sec: 37.10 | norm: 1.38\n",
      "step : 209 | loss: 5.098893165588379 | dt: 167.10 ms | tokens/sec: 36.77 | norm: 1.15\n",
      "step : 210 | loss: 5.21911096572876 | dt: 166.27 ms | tokens/sec: 36.95 | norm: 1.35\n",
      "step : 211 | loss: 5.005331039428711 | dt: 166.25 ms | tokens/sec: 36.96 | norm: 1.13\n",
      "step : 212 | loss: 4.825040340423584 | dt: 165.68 ms | tokens/sec: 37.08 | norm: 0.98\n",
      "step : 213 | loss: 5.171107769012451 | dt: 165.94 ms | tokens/sec: 37.03 | norm: 0.95\n",
      "step : 214 | loss: 5.023377895355225 | dt: 166.40 ms | tokens/sec: 36.92 | norm: 1.14\n",
      "step : 215 | loss: 4.900922775268555 | dt: 166.56 ms | tokens/sec: 36.89 | norm: 1.10\n",
      "step : 216 | loss: 5.036955833435059 | dt: 166.39 ms | tokens/sec: 36.93 | norm: 0.93\n",
      "step : 217 | loss: 4.745168685913086 | dt: 165.46 ms | tokens/sec: 37.13 | norm: 0.85\n",
      "step : 218 | loss: 4.540035724639893 | dt: 165.51 ms | tokens/sec: 37.12 | norm: 1.17\n",
      "step : 219 | loss: 5.359654426574707 | dt: 166.83 ms | tokens/sec: 36.83 | norm: 1.40\n",
      "step : 220 | loss: 5.233335018157959 | dt: 166.62 ms | tokens/sec: 36.87 | norm: 1.38\n",
      "step : 221 | loss: 5.266585826873779 | dt: 167.02 ms | tokens/sec: 36.79 | norm: 1.12\n",
      "step : 222 | loss: 5.234198570251465 | dt: 166.31 ms | tokens/sec: 36.94 | norm: 1.05\n",
      "step : 223 | loss: 5.220737457275391 | dt: 166.42 ms | tokens/sec: 36.92 | norm: 1.09\n",
      "step : 224 | loss: 4.909816741943359 | dt: 165.62 ms | tokens/sec: 37.10 | norm: 1.17\n",
      "step : 225 | loss: 4.9135284423828125 | dt: 166.36 ms | tokens/sec: 36.93 | norm: 0.98\n",
      "step : 226 | loss: 4.922303676605225 | dt: 165.66 ms | tokens/sec: 37.09 | norm: 0.97\n",
      "step : 227 | loss: 4.976218223571777 | dt: 166.05 ms | tokens/sec: 37.00 | norm: 0.79\n",
      "step : 228 | loss: 5.105208396911621 | dt: 166.53 ms | tokens/sec: 36.89 | norm: 0.81\n",
      "step : 229 | loss: 5.155007839202881 | dt: 165.40 ms | tokens/sec: 37.15 | norm: 1.43\n",
      "step : 230 | loss: 5.089954376220703 | dt: 164.73 ms | tokens/sec: 37.30 | norm: 1.13\n",
      "step : 231 | loss: 4.957365989685059 | dt: 165.87 ms | tokens/sec: 37.04 | norm: 0.92\n",
      "step : 232 | loss: 4.806048393249512 | dt: 165.79 ms | tokens/sec: 37.06 | norm: 1.10\n",
      "step : 233 | loss: 5.077870845794678 | dt: 166.16 ms | tokens/sec: 36.98 | norm: 1.06\n",
      "step : 234 | loss: 5.006844997406006 | dt: 167.39 ms | tokens/sec: 36.70 | norm: 1.02\n",
      "step : 235 | loss: 4.921344757080078 | dt: 166.18 ms | tokens/sec: 36.97 | norm: 0.96\n",
      "step : 236 | loss: 5.165084362030029 | dt: 165.89 ms | tokens/sec: 37.04 | norm: 0.85\n",
      "step : 237 | loss: 5.251206398010254 | dt: 164.79 ms | tokens/sec: 37.28 | norm: 0.85\n",
      "step : 238 | loss: 5.120423316955566 | dt: 165.46 ms | tokens/sec: 37.13 | norm: 0.71\n",
      "step : 239 | loss: 5.144772529602051 | dt: 166.12 ms | tokens/sec: 36.99 | norm: 0.74\n",
      "step : 240 | loss: 5.0997538566589355 | dt: 167.19 ms | tokens/sec: 36.75 | norm: 0.80\n",
      "step : 241 | loss: 4.82787561416626 | dt: 165.01 ms | tokens/sec: 37.23 | norm: 0.96\n",
      "step : 242 | loss: 5.118681907653809 | dt: 166.86 ms | tokens/sec: 36.82 | norm: 1.00\n",
      "step : 243 | loss: 5.2881317138671875 | dt: 166.56 ms | tokens/sec: 36.89 | norm: 1.05\n",
      "step : 244 | loss: 5.194660186767578 | dt: 166.01 ms | tokens/sec: 37.01 | norm: 0.98\n",
      "step : 245 | loss: 5.082155227661133 | dt: 166.85 ms | tokens/sec: 36.82 | norm: 0.97\n",
      "step : 246 | loss: 5.137542247772217 | dt: 166.54 ms | tokens/sec: 36.89 | norm: 0.87\n",
      "step : 247 | loss: 4.850284576416016 | dt: 166.17 ms | tokens/sec: 36.97 | norm: 1.04\n",
      "step : 248 | loss: 5.085887432098389 | dt: 166.72 ms | tokens/sec: 36.85 | norm: 0.90\n",
      "step : 249 | loss: 4.888602256774902 | dt: 167.05 ms | tokens/sec: 36.78 | norm: 0.96\n",
      "step : 250 | loss: 5.19905948638916 | dt: 166.32 ms | tokens/sec: 36.94 | norm: 0.94\n",
      "step : 251 | loss: 5.118361473083496 | dt: 166.48 ms | tokens/sec: 36.91 | norm: 0.98\n",
      "step : 252 | loss: 4.852702617645264 | dt: 166.41 ms | tokens/sec: 36.92 | norm: 0.94\n",
      "step : 253 | loss: 4.943037986755371 | dt: 166.59 ms | tokens/sec: 36.88 | norm: 0.84\n",
      "step : 254 | loss: 4.958219528198242 | dt: 166.20 ms | tokens/sec: 36.97 | norm: 0.73\n",
      "step : 255 | loss: 5.00743293762207 | dt: 166.29 ms | tokens/sec: 36.95 | norm: 0.74\n",
      "step : 256 | loss: 5.2846879959106445 | dt: 165.84 ms | tokens/sec: 37.05 | norm: 1.12\n",
      "step : 257 | loss: 5.150295257568359 | dt: 166.21 ms | tokens/sec: 36.96 | norm: 1.05\n",
      "step : 258 | loss: 5.462995529174805 | dt: 166.28 ms | tokens/sec: 36.95 | norm: 1.06\n",
      "step : 259 | loss: 5.305695533752441 | dt: 166.27 ms | tokens/sec: 36.95 | norm: 0.96\n",
      "step : 260 | loss: 5.109033107757568 | dt: 166.30 ms | tokens/sec: 36.94 | norm: 0.91\n",
      "step : 261 | loss: 5.147756099700928 | dt: 166.33 ms | tokens/sec: 36.94 | norm: 0.94\n",
      "step : 262 | loss: 5.005577087402344 | dt: 163.84 ms | tokens/sec: 37.50 | norm: 1.02\n",
      "step : 263 | loss: 4.883269309997559 | dt: 163.38 ms | tokens/sec: 37.61 | norm: 1.32\n",
      "step : 264 | loss: 4.984561920166016 | dt: 164.33 ms | tokens/sec: 37.39 | norm: 1.07\n",
      "step : 265 | loss: 5.095156669616699 | dt: 163.82 ms | tokens/sec: 37.50 | norm: 1.34\n",
      "step : 266 | loss: 4.879826545715332 | dt: 164.46 ms | tokens/sec: 37.36 | norm: 1.21\n",
      "step : 267 | loss: 4.687647819519043 | dt: 165.67 ms | tokens/sec: 37.09 | norm: 0.90\n",
      "step : 268 | loss: 5.054536819458008 | dt: 164.48 ms | tokens/sec: 37.35 | norm: 1.00\n",
      "step : 269 | loss: 4.941422462463379 | dt: 163.21 ms | tokens/sec: 37.65 | norm: 1.11\n",
      "step : 270 | loss: 4.807051658630371 | dt: 164.46 ms | tokens/sec: 37.36 | norm: 1.03\n",
      "step : 271 | loss: 4.941728591918945 | dt: 163.30 ms | tokens/sec: 37.62 | norm: 0.94\n",
      "step : 272 | loss: 4.656954765319824 | dt: 167.73 ms | tokens/sec: 36.63 | norm: 0.96\n",
      "step : 273 | loss: 4.450966835021973 | dt: 163.69 ms | tokens/sec: 37.53 | norm: 1.08\n",
      "step : 274 | loss: 5.265641212463379 | dt: 164.40 ms | tokens/sec: 37.37 | norm: 1.26\n",
      "step : 275 | loss: 5.128253936767578 | dt: 165.04 ms | tokens/sec: 37.23 | norm: 1.36\n",
      "step : 276 | loss: 5.178762435913086 | dt: 164.96 ms | tokens/sec: 37.25 | norm: 1.19\n",
      "step : 277 | loss: 5.1403303146362305 | dt: 163.46 ms | tokens/sec: 37.59 | norm: 1.18\n",
      "step : 278 | loss: 5.073192596435547 | dt: 165.25 ms | tokens/sec: 37.18 | norm: 1.10\n",
      "step : 279 | loss: 4.762635707855225 | dt: 164.08 ms | tokens/sec: 37.45 | norm: 1.19\n",
      "step : 280 | loss: 4.732245445251465 | dt: 163.22 ms | tokens/sec: 37.64 | norm: 0.98\n",
      "step : 281 | loss: 4.754846572875977 | dt: 166.02 ms | tokens/sec: 37.01 | norm: 0.99\n",
      "step : 282 | loss: 4.859282493591309 | dt: 164.64 ms | tokens/sec: 37.32 | norm: 0.77\n",
      "step : 283 | loss: 4.977231025695801 | dt: 163.66 ms | tokens/sec: 37.54 | norm: 0.72\n",
      "step : 284 | loss: 5.025421142578125 | dt: 166.76 ms | tokens/sec: 36.84 | norm: 1.46\n",
      "step : 285 | loss: 4.947359561920166 | dt: 165.19 ms | tokens/sec: 37.19 | norm: 1.30\n",
      "step : 286 | loss: 4.861807823181152 | dt: 163.34 ms | tokens/sec: 37.62 | norm: 1.15\n",
      "step : 287 | loss: 4.6993632316589355 | dt: 164.24 ms | tokens/sec: 37.41 | norm: 0.99\n",
      "step : 288 | loss: 4.946539878845215 | dt: 162.77 ms | tokens/sec: 37.75 | norm: 1.00\n",
      "step : 289 | loss: 4.872840881347656 | dt: 163.77 ms | tokens/sec: 37.52 | norm: 1.12\n",
      "step : 290 | loss: 4.811230659484863 | dt: 165.87 ms | tokens/sec: 37.04 | norm: 1.14\n",
      "step : 291 | loss: 5.080418586730957 | dt: 165.41 ms | tokens/sec: 37.14 | norm: 0.92\n",
      "step : 292 | loss: 5.166790008544922 | dt: 163.91 ms | tokens/sec: 37.48 | norm: 0.82\n",
      "step : 293 | loss: 5.0370097160339355 | dt: 165.03 ms | tokens/sec: 37.23 | norm: 0.74\n",
      "step : 294 | loss: 5.067571640014648 | dt: 163.99 ms | tokens/sec: 37.47 | norm: 0.84\n",
      "step : 295 | loss: 4.988251686096191 | dt: 166.24 ms | tokens/sec: 36.96 | norm: 0.69\n",
      "step : 296 | loss: 4.699499130249023 | dt: 163.61 ms | tokens/sec: 37.55 | norm: 0.83\n",
      "step : 297 | loss: 5.002503395080566 | dt: 164.48 ms | tokens/sec: 37.36 | norm: 0.78\n",
      "step : 298 | loss: 5.197659492492676 | dt: 164.49 ms | tokens/sec: 37.35 | norm: 0.85\n",
      "step : 299 | loss: 5.125240325927734 | dt: 164.54 ms | tokens/sec: 37.34 | norm: 1.05\n",
      "step : 300 | loss: 5.031767845153809 | dt: 163.92 ms | tokens/sec: 37.48 | norm: 1.06\n",
      "step : 301 | loss: 5.054233074188232 | dt: 165.12 ms | tokens/sec: 37.21 | norm: 0.91\n",
      "step : 302 | loss: 4.751346111297607 | dt: 163.74 ms | tokens/sec: 37.52 | norm: 0.96\n",
      "step : 303 | loss: 4.986384391784668 | dt: 163.59 ms | tokens/sec: 37.56 | norm: 0.86\n",
      "step : 304 | loss: 4.772210121154785 | dt: 164.87 ms | tokens/sec: 37.27 | norm: 1.14\n",
      "step : 305 | loss: 5.067692756652832 | dt: 163.54 ms | tokens/sec: 37.57 | norm: 0.90\n",
      "step : 306 | loss: 4.9887285232543945 | dt: 164.05 ms | tokens/sec: 37.45 | norm: 0.70\n",
      "step : 307 | loss: 4.760978698730469 | dt: 165.20 ms | tokens/sec: 37.19 | norm: 1.02\n",
      "step : 308 | loss: 4.843031406402588 | dt: 163.92 ms | tokens/sec: 37.48 | norm: 0.95\n",
      "step : 309 | loss: 4.857483386993408 | dt: 165.41 ms | tokens/sec: 37.15 | norm: 1.13\n",
      "step : 310 | loss: 4.922230243682861 | dt: 165.23 ms | tokens/sec: 37.18 | norm: 0.76\n",
      "step : 311 | loss: 5.184001922607422 | dt: 163.49 ms | tokens/sec: 37.58 | norm: 1.02\n",
      "step : 312 | loss: 5.086250305175781 | dt: 164.56 ms | tokens/sec: 37.34 | norm: 1.03\n",
      "step : 313 | loss: 5.377535820007324 | dt: 164.15 ms | tokens/sec: 37.43 | norm: 0.99\n",
      "step : 314 | loss: 5.201351165771484 | dt: 163.87 ms | tokens/sec: 37.49 | norm: 0.95\n",
      "step : 315 | loss: 5.010340690612793 | dt: 166.51 ms | tokens/sec: 36.90 | norm: 0.85\n",
      "step : 316 | loss: 5.062162399291992 | dt: 165.25 ms | tokens/sec: 37.18 | norm: 0.84\n",
      "step : 317 | loss: 4.899625301361084 | dt: 163.22 ms | tokens/sec: 37.64 | norm: 0.91\n",
      "step : 318 | loss: 4.754576683044434 | dt: 164.20 ms | tokens/sec: 37.42 | norm: 1.20\n",
      "step : 319 | loss: 4.862160682678223 | dt: 163.14 ms | tokens/sec: 37.66 | norm: 0.96\n",
      "step : 320 | loss: 4.9540605545043945 | dt: 163.65 ms | tokens/sec: 37.54 | norm: 1.09\n",
      "step : 321 | loss: 4.7465105056762695 | dt: 165.21 ms | tokens/sec: 37.19 | norm: 0.91\n",
      "step : 322 | loss: 4.560308933258057 | dt: 163.82 ms | tokens/sec: 37.51 | norm: 0.83\n",
      "step : 323 | loss: 4.952561378479004 | dt: 165.70 ms | tokens/sec: 37.08 | norm: 0.84\n",
      "step : 324 | loss: 4.819270610809326 | dt: 165.22 ms | tokens/sec: 37.19 | norm: 1.00\n",
      "step : 325 | loss: 4.679265975952148 | dt: 163.64 ms | tokens/sec: 37.55 | norm: 1.01\n",
      "step : 326 | loss: 4.807201385498047 | dt: 164.07 ms | tokens/sec: 37.45 | norm: 0.78\n",
      "step : 327 | loss: 4.549785614013672 | dt: 163.55 ms | tokens/sec: 37.57 | norm: 0.90\n",
      "step : 328 | loss: 4.316201686859131 | dt: 164.44 ms | tokens/sec: 37.36 | norm: 1.19\n",
      "step : 329 | loss: 5.168463230133057 | dt: 166.39 ms | tokens/sec: 36.93 | norm: 1.29\n",
      "step : 330 | loss: 5.016881465911865 | dt: 164.76 ms | tokens/sec: 37.29 | norm: 1.37\n",
      "step : 331 | loss: 5.098413467407227 | dt: 163.90 ms | tokens/sec: 37.49 | norm: 1.14\n",
      "step : 332 | loss: 5.046481609344482 | dt: 164.87 ms | tokens/sec: 37.26 | norm: 1.15\n",
      "step : 333 | loss: 4.996299743652344 | dt: 162.92 ms | tokens/sec: 37.71 | norm: 1.21\n",
      "step : 334 | loss: 4.683267116546631 | dt: 163.63 ms | tokens/sec: 37.55 | norm: 1.31\n",
      "step : 335 | loss: 4.6373443603515625 | dt: 165.82 ms | tokens/sec: 37.05 | norm: 0.98\n",
      "step : 336 | loss: 4.64026403427124 | dt: 163.96 ms | tokens/sec: 37.47 | norm: 0.93\n",
      "step : 337 | loss: 4.767637252807617 | dt: 165.49 ms | tokens/sec: 37.13 | norm: 0.89\n",
      "step : 338 | loss: 4.863134384155273 | dt: 164.61 ms | tokens/sec: 37.33 | norm: 0.75\n",
      "step : 339 | loss: 4.854819297790527 | dt: 164.09 ms | tokens/sec: 37.44 | norm: 1.21\n",
      "step : 340 | loss: 4.794523239135742 | dt: 164.09 ms | tokens/sec: 37.44 | norm: 1.14\n",
      "step : 341 | loss: 4.776061534881592 | dt: 164.07 ms | tokens/sec: 37.45 | norm: 1.15\n",
      "step : 342 | loss: 4.587070465087891 | dt: 163.89 ms | tokens/sec: 37.49 | norm: 1.05\n",
      "step : 343 | loss: 4.8166961669921875 | dt: 166.35 ms | tokens/sec: 36.93 | norm: 0.83\n",
      "step : 344 | loss: 4.742607593536377 | dt: 164.64 ms | tokens/sec: 37.32 | norm: 0.96\n",
      "step : 345 | loss: 4.679470062255859 | dt: 164.64 ms | tokens/sec: 37.32 | norm: 1.08\n",
      "step : 346 | loss: 4.962924003601074 | dt: 166.71 ms | tokens/sec: 36.85 | norm: 0.94\n",
      "step : 347 | loss: 5.0566325187683105 | dt: 164.75 ms | tokens/sec: 37.29 | norm: 0.85\n",
      "step : 348 | loss: 4.955448150634766 | dt: 169.38 ms | tokens/sec: 36.27 | norm: 0.79\n",
      "step : 349 | loss: 4.973269462585449 | dt: 165.72 ms | tokens/sec: 37.07 | norm: 0.78\n",
      "step : 350 | loss: 4.904750823974609 | dt: 165.70 ms | tokens/sec: 37.08 | norm: 0.73\n",
      "step : 351 | loss: 4.628503799438477 | dt: 164.40 ms | tokens/sec: 37.37 | norm: 0.84\n",
      "step : 352 | loss: 4.886033535003662 | dt: 166.01 ms | tokens/sec: 37.01 | norm: 0.69\n",
      "step : 353 | loss: 5.093300819396973 | dt: 165.08 ms | tokens/sec: 37.22 | norm: 0.82\n",
      "step : 354 | loss: 5.027963638305664 | dt: 167.00 ms | tokens/sec: 36.79 | norm: 0.97\n",
      "step : 355 | loss: 4.910923004150391 | dt: 165.97 ms | tokens/sec: 37.02 | norm: 1.04\n",
      "step : 356 | loss: 4.991215705871582 | dt: 164.28 ms | tokens/sec: 37.40 | norm: 0.92\n",
      "step : 357 | loss: 4.730348110198975 | dt: 164.43 ms | tokens/sec: 37.37 | norm: 1.05\n",
      "step : 358 | loss: 4.949956893920898 | dt: 165.75 ms | tokens/sec: 37.07 | norm: 0.86\n",
      "step : 359 | loss: 4.7533464431762695 | dt: 163.44 ms | tokens/sec: 37.59 | norm: 1.16\n",
      "step : 360 | loss: 5.0314130783081055 | dt: 164.67 ms | tokens/sec: 37.31 | norm: 1.02\n",
      "step : 361 | loss: 4.940823078155518 | dt: 166.65 ms | tokens/sec: 36.87 | norm: 0.81\n",
      "step : 362 | loss: 4.655503749847412 | dt: 165.27 ms | tokens/sec: 37.18 | norm: 0.86\n",
      "step : 363 | loss: 4.765499114990234 | dt: 166.40 ms | tokens/sec: 36.92 | norm: 0.92\n",
      "step : 364 | loss: 4.819204807281494 | dt: 165.66 ms | tokens/sec: 37.09 | norm: 1.18\n",
      "step : 365 | loss: 4.8586835861206055 | dt: 164.82 ms | tokens/sec: 37.28 | norm: 1.01\n",
      "step : 366 | loss: 5.116049289703369 | dt: 164.75 ms | tokens/sec: 37.29 | norm: 1.23\n",
      "step : 367 | loss: 4.979714393615723 | dt: 167.38 ms | tokens/sec: 36.71 | norm: 0.94\n",
      "step : 368 | loss: 5.27344274520874 | dt: 163.96 ms | tokens/sec: 37.47 | norm: 0.92\n",
      "step : 369 | loss: 5.085726737976074 | dt: 166.55 ms | tokens/sec: 36.89 | norm: 0.97\n",
      "step : 370 | loss: 4.912900447845459 | dt: 166.20 ms | tokens/sec: 36.97 | norm: 1.00\n",
      "step : 371 | loss: 4.982440948486328 | dt: 164.39 ms | tokens/sec: 37.38 | norm: 0.92\n",
      "step : 372 | loss: 4.812714576721191 | dt: 166.67 ms | tokens/sec: 36.86 | norm: 0.87\n",
      "step : 373 | loss: 4.634098052978516 | dt: 167.06 ms | tokens/sec: 36.78 | norm: 1.15\n",
      "step : 374 | loss: 4.758829116821289 | dt: 166.05 ms | tokens/sec: 37.00 | norm: 0.99\n",
      "step : 375 | loss: 4.831789970397949 | dt: 166.76 ms | tokens/sec: 36.84 | norm: 1.20\n",
      "step : 376 | loss: 4.649986267089844 | dt: 164.95 ms | tokens/sec: 37.25 | norm: 1.11\n",
      "step : 377 | loss: 4.479136943817139 | dt: 164.43 ms | tokens/sec: 37.36 | norm: 0.90\n",
      "step : 378 | loss: 4.89640998840332 | dt: 167.90 ms | tokens/sec: 36.59 | norm: 0.91\n",
      "step : 379 | loss: 4.741591453552246 | dt: 167.08 ms | tokens/sec: 36.77 | norm: 1.04\n",
      "step : 380 | loss: 4.59766960144043 | dt: 165.27 ms | tokens/sec: 37.18 | norm: 1.07\n",
      "step : 381 | loss: 4.726898193359375 | dt: 166.05 ms | tokens/sec: 37.00 | norm: 0.94\n",
      "step : 382 | loss: 4.488190174102783 | dt: 164.86 ms | tokens/sec: 37.27 | norm: 0.81\n",
      "step : 383 | loss: 4.256752967834473 | dt: 165.07 ms | tokens/sec: 37.22 | norm: 0.97\n",
      "step : 384 | loss: 5.069316864013672 | dt: 166.35 ms | tokens/sec: 36.93 | norm: 1.21\n",
      "step : 385 | loss: 4.934143543243408 | dt: 165.82 ms | tokens/sec: 37.05 | norm: 1.35\n",
      "step : 386 | loss: 4.9953508377075195 | dt: 167.47 ms | tokens/sec: 36.69 | norm: 1.06\n",
      "step : 387 | loss: 4.957928657531738 | dt: 165.97 ms | tokens/sec: 37.02 | norm: 1.02\n",
      "step : 388 | loss: 4.9174604415893555 | dt: 165.41 ms | tokens/sec: 37.14 | norm: 1.10\n",
      "step : 389 | loss: 4.568647384643555 | dt: 164.95 ms | tokens/sec: 37.25 | norm: 1.22\n",
      "step : 390 | loss: 4.546141624450684 | dt: 166.36 ms | tokens/sec: 36.93 | norm: 0.92\n",
      "step : 391 | loss: 4.562594890594482 | dt: 164.37 ms | tokens/sec: 37.38 | norm: 1.60\n",
      "step : 392 | loss: 4.708317756652832 | dt: 166.24 ms | tokens/sec: 36.96 | norm: 0.96\n",
      "step : 393 | loss: 4.809886932373047 | dt: 166.29 ms | tokens/sec: 36.95 | norm: 0.90\n",
      "step : 394 | loss: 4.805697441101074 | dt: 163.88 ms | tokens/sec: 37.49 | norm: 1.38\n",
      "step : 395 | loss: 4.727972030639648 | dt: 164.95 ms | tokens/sec: 37.25 | norm: 0.99\n",
      "step : 396 | loss: 4.67768669128418 | dt: 165.91 ms | tokens/sec: 37.03 | norm: 0.94\n",
      "step : 397 | loss: 4.498707294464111 | dt: 164.14 ms | tokens/sec: 37.43 | norm: 1.10\n",
      "step : 398 | loss: 4.764399528503418 | dt: 166.13 ms | tokens/sec: 36.98 | norm: 0.91\n",
      "step : 399 | loss: 4.661520957946777 | dt: 166.15 ms | tokens/sec: 36.98 | norm: 1.02\n",
      "step : 400 | loss: 4.605400085449219 | dt: 165.15 ms | tokens/sec: 37.20 | norm: 0.99\n",
      "step : 401 | loss: 4.902115821838379 | dt: 166.39 ms | tokens/sec: 36.92 | norm: 0.93\n",
      "step : 402 | loss: 4.990922927856445 | dt: 165.91 ms | tokens/sec: 37.03 | norm: 0.88\n",
      "step : 403 | loss: 4.904020309448242 | dt: 164.78 ms | tokens/sec: 37.29 | norm: 0.88\n",
      "step : 404 | loss: 4.9385528564453125 | dt: 164.90 ms | tokens/sec: 37.26 | norm: 0.86\n",
      "step : 405 | loss: 4.860105991363525 | dt: 166.20 ms | tokens/sec: 36.97 | norm: 0.82\n",
      "step : 406 | loss: 4.531904220581055 | dt: 164.16 ms | tokens/sec: 37.43 | norm: 0.85\n",
      "step : 407 | loss: 4.824312210083008 | dt: 166.59 ms | tokens/sec: 36.88 | norm: 0.76\n",
      "step : 408 | loss: 5.009280681610107 | dt: 164.75 ms | tokens/sec: 37.29 | norm: 0.94\n",
      "step : 409 | loss: 4.917604446411133 | dt: 164.15 ms | tokens/sec: 37.43 | norm: 0.92\n",
      "step : 410 | loss: 4.806542873382568 | dt: 165.42 ms | tokens/sec: 37.14 | norm: 0.97\n",
      "step : 411 | loss: 4.929927825927734 | dt: 165.09 ms | tokens/sec: 37.22 | norm: 0.80\n",
      "step : 412 | loss: 4.6313276290893555 | dt: 165.23 ms | tokens/sec: 37.18 | norm: 0.88\n",
      "step : 413 | loss: 4.872106075286865 | dt: 166.72 ms | tokens/sec: 36.85 | norm: 0.84\n",
      "step : 414 | loss: 4.685433387756348 | dt: 165.36 ms | tokens/sec: 37.15 | norm: 1.04\n",
      "step : 415 | loss: 4.988431453704834 | dt: 164.88 ms | tokens/sec: 37.26 | norm: 0.92\n",
      "step : 416 | loss: 4.908268928527832 | dt: 166.01 ms | tokens/sec: 37.01 | norm: 0.81\n",
      "step : 417 | loss: 4.61182165145874 | dt: 166.06 ms | tokens/sec: 37.00 | norm: 0.85\n",
      "step : 418 | loss: 4.715322494506836 | dt: 164.78 ms | tokens/sec: 37.29 | norm: 0.78\n",
      "step : 419 | loss: 4.753135681152344 | dt: 165.26 ms | tokens/sec: 37.18 | norm: 0.92\n",
      "step : 420 | loss: 4.788326263427734 | dt: 163.78 ms | tokens/sec: 37.51 | norm: 0.80\n",
      "step : 421 | loss: 5.080101013183594 | dt: 164.69 ms | tokens/sec: 37.31 | norm: 1.12\n",
      "step : 422 | loss: 4.938920021057129 | dt: 165.61 ms | tokens/sec: 37.10 | norm: 0.94\n",
      "step : 423 | loss: 5.228557586669922 | dt: 164.43 ms | tokens/sec: 37.37 | norm: 0.94\n",
      "step : 424 | loss: 5.036103248596191 | dt: 165.05 ms | tokens/sec: 37.23 | norm: 0.84\n",
      "step : 425 | loss: 4.865062713623047 | dt: 165.38 ms | tokens/sec: 37.15 | norm: 0.86\n",
      "step : 426 | loss: 4.924273490905762 | dt: 164.26 ms | tokens/sec: 37.40 | norm: 0.83\n",
      "step : 427 | loss: 4.760753631591797 | dt: 166.47 ms | tokens/sec: 36.91 | norm: 0.96\n",
      "step : 428 | loss: 4.599919319152832 | dt: 165.68 ms | tokens/sec: 37.08 | norm: 1.25\n",
      "step : 429 | loss: 4.710666656494141 | dt: 164.27 ms | tokens/sec: 37.40 | norm: 1.05\n",
      "step : 430 | loss: 4.734681606292725 | dt: 169.13 ms | tokens/sec: 36.33 | norm: 1.04\n",
      "step : 431 | loss: 4.540910243988037 | dt: 165.65 ms | tokens/sec: 37.09 | norm: 0.91\n",
      "step : 432 | loss: 4.411167144775391 | dt: 163.99 ms | tokens/sec: 37.47 | norm: 0.86\n",
      "step : 433 | loss: 4.820750713348389 | dt: 166.56 ms | tokens/sec: 36.89 | norm: 0.94\n",
      "step : 434 | loss: 4.66754674911499 | dt: 164.56 ms | tokens/sec: 37.34 | norm: 1.02\n",
      "step : 435 | loss: 4.521021366119385 | dt: 163.78 ms | tokens/sec: 37.51 | norm: 1.03\n",
      "step : 436 | loss: 4.652578353881836 | dt: 166.24 ms | tokens/sec: 36.96 | norm: 0.90\n",
      "step : 437 | loss: 4.442246913909912 | dt: 164.66 ms | tokens/sec: 37.31 | norm: 0.96\n",
      "step : 438 | loss: 4.182650566101074 | dt: 165.32 ms | tokens/sec: 37.16 | norm: 0.93\n",
      "step : 439 | loss: 5.035623550415039 | dt: 168.99 ms | tokens/sec: 36.36 | norm: 1.19\n",
      "step : 440 | loss: 4.904293537139893 | dt: 165.09 ms | tokens/sec: 37.22 | norm: 1.39\n",
      "step : 441 | loss: 5.019265174865723 | dt: 165.20 ms | tokens/sec: 37.19 | norm: 1.20\n",
      "step : 442 | loss: 4.969808578491211 | dt: 165.87 ms | tokens/sec: 37.04 | norm: 1.19\n",
      "step : 443 | loss: 4.9189629554748535 | dt: 166.49 ms | tokens/sec: 36.90 | norm: 1.18\n",
      "step : 444 | loss: 4.575815200805664 | dt: 164.83 ms | tokens/sec: 37.27 | norm: 1.28\n",
      "step : 445 | loss: 4.530458450317383 | dt: 166.84 ms | tokens/sec: 36.83 | norm: 1.04\n",
      "step : 446 | loss: 4.588543891906738 | dt: 164.81 ms | tokens/sec: 37.28 | norm: 0.86\n",
      "step : 447 | loss: 4.675759315490723 | dt: 164.24 ms | tokens/sec: 37.41 | norm: 0.86\n",
      "step : 448 | loss: 4.75340461730957 | dt: 165.61 ms | tokens/sec: 37.10 | norm: 0.86\n",
      "step : 449 | loss: 4.734073162078857 | dt: 165.14 ms | tokens/sec: 37.20 | norm: 1.34\n",
      "step : 450 | loss: 4.689810276031494 | dt: 163.89 ms | tokens/sec: 37.49 | norm: 1.01\n",
      "step : 451 | loss: 4.612945556640625 | dt: 164.48 ms | tokens/sec: 37.35 | norm: 0.85\n",
      "step : 452 | loss: 4.415494918823242 | dt: 164.59 ms | tokens/sec: 37.33 | norm: 0.91\n",
      "step : 453 | loss: 4.7000579833984375 | dt: 165.99 ms | tokens/sec: 37.01 | norm: 0.87\n",
      "step : 454 | loss: 4.584671974182129 | dt: 165.80 ms | tokens/sec: 37.06 | norm: 0.92\n",
      "step : 455 | loss: 4.520312309265137 | dt: 166.02 ms | tokens/sec: 37.01 | norm: 0.98\n",
      "step : 456 | loss: 4.843906402587891 | dt: 164.96 ms | tokens/sec: 37.25 | norm: 0.79\n",
      "step : 457 | loss: 4.930604934692383 | dt: 165.47 ms | tokens/sec: 37.13 | norm: 0.81\n",
      "step : 458 | loss: 4.833408355712891 | dt: 164.54 ms | tokens/sec: 37.34 | norm: 0.74\n",
      "step : 459 | loss: 4.844757080078125 | dt: 166.33 ms | tokens/sec: 36.94 | norm: 0.81\n",
      "step : 460 | loss: 4.789252281188965 | dt: 164.96 ms | tokens/sec: 37.25 | norm: 0.69\n",
      "step : 461 | loss: 4.500540733337402 | dt: 162.94 ms | tokens/sec: 37.71 | norm: 0.87\n",
      "step : 462 | loss: 4.8252410888671875 | dt: 165.10 ms | tokens/sec: 37.21 | norm: 0.85\n",
      "step : 463 | loss: 5.031038284301758 | dt: 164.64 ms | tokens/sec: 37.32 | norm: 0.95\n",
      "step : 464 | loss: 4.911256313323975 | dt: 164.89 ms | tokens/sec: 37.26 | norm: 0.96\n",
      "step : 465 | loss: 4.7791619300842285 | dt: 166.46 ms | tokens/sec: 36.91 | norm: 0.98\n",
      "step : 466 | loss: 4.896871566772461 | dt: 164.86 ms | tokens/sec: 37.27 | norm: 1.08\n",
      "step : 467 | loss: 4.590200424194336 | dt: 164.43 ms | tokens/sec: 37.36 | norm: 0.87\n",
      "step : 468 | loss: 4.834630966186523 | dt: 166.29 ms | tokens/sec: 36.95 | norm: 0.79\n",
      "step : 469 | loss: 4.647249698638916 | dt: 163.82 ms | tokens/sec: 37.50 | norm: 1.18\n",
      "step : 470 | loss: 4.962854385375977 | dt: 163.56 ms | tokens/sec: 37.56 | norm: 0.99\n",
      "step : 471 | loss: 4.863679885864258 | dt: 164.37 ms | tokens/sec: 37.38 | norm: 0.84\n",
      "step : 472 | loss: 4.545949935913086 | dt: 164.25 ms | tokens/sec: 37.41 | norm: 0.84\n",
      "step : 473 | loss: 4.677406311035156 | dt: 165.96 ms | tokens/sec: 37.02 | norm: 0.78\n",
      "step : 474 | loss: 4.707920074462891 | dt: 166.66 ms | tokens/sec: 36.87 | norm: 0.93\n",
      "step : 475 | loss: 4.771337032318115 | dt: 164.74 ms | tokens/sec: 37.30 | norm: 0.90\n",
      "step : 476 | loss: 5.091296672821045 | dt: 164.71 ms | tokens/sec: 37.30 | norm: 1.23\n",
      "step : 477 | loss: 4.948762893676758 | dt: 165.20 ms | tokens/sec: 37.19 | norm: 1.06\n",
      "step : 478 | loss: 5.238953590393066 | dt: 163.83 ms | tokens/sec: 37.50 | norm: 1.13\n",
      "step : 479 | loss: 5.025554180145264 | dt: 166.32 ms | tokens/sec: 36.94 | norm: 0.92\n",
      "step : 480 | loss: 4.8478522300720215 | dt: 164.34 ms | tokens/sec: 37.39 | norm: 0.97\n",
      "step : 481 | loss: 4.9208502769470215 | dt: 164.29 ms | tokens/sec: 37.40 | norm: 1.01\n",
      "step : 482 | loss: 4.757256984710693 | dt: 164.42 ms | tokens/sec: 37.37 | norm: 1.08\n",
      "step : 483 | loss: 4.5880889892578125 | dt: 164.83 ms | tokens/sec: 37.28 | norm: 1.33\n",
      "step : 484 | loss: 4.688353061676025 | dt: 164.01 ms | tokens/sec: 37.46 | norm: 1.08\n",
      "step : 485 | loss: 4.7056732177734375 | dt: 166.25 ms | tokens/sec: 36.96 | norm: 1.19\n",
      "step : 486 | loss: 4.515555381774902 | dt: 164.67 ms | tokens/sec: 37.31 | norm: 1.13\n",
      "step : 487 | loss: 4.36376953125 | dt: 166.01 ms | tokens/sec: 37.01 | norm: 0.99\n",
      "step : 488 | loss: 4.797076225280762 | dt: 164.50 ms | tokens/sec: 37.35 | norm: 0.95\n",
      "step : 489 | loss: 4.643872261047363 | dt: 163.92 ms | tokens/sec: 37.48 | norm: 0.96\n",
      "step : 490 | loss: 4.521925926208496 | dt: 164.55 ms | tokens/sec: 37.34 | norm: 0.98\n",
      "step : 491 | loss: 4.612709999084473 | dt: 165.00 ms | tokens/sec: 37.24 | norm: 0.81\n",
      "step : 492 | loss: 4.384120464324951 | dt: 164.13 ms | tokens/sec: 37.43 | norm: 0.79\n",
      "step : 493 | loss: 4.151334762573242 | dt: 166.57 ms | tokens/sec: 36.89 | norm: 0.85\n",
      "step : 494 | loss: 4.960993766784668 | dt: 165.32 ms | tokens/sec: 37.16 | norm: 0.90\n",
      "step : 495 | loss: 4.816226005554199 | dt: 164.50 ms | tokens/sec: 37.35 | norm: 1.05\n",
      "step : 496 | loss: 4.902261734008789 | dt: 164.57 ms | tokens/sec: 37.33 | norm: 0.94\n",
      "step : 497 | loss: 4.847748756408691 | dt: 163.77 ms | tokens/sec: 37.52 | norm: 0.91\n",
      "step : 498 | loss: 4.8252387046813965 | dt: 163.21 ms | tokens/sec: 37.64 | norm: 1.09\n",
      "step : 499 | loss: 4.487321376800537 | dt: 165.15 ms | tokens/sec: 37.20 | norm: 1.18\n",
      "step : 500 | loss: 4.459851264953613 | dt: 166.49 ms | tokens/sec: 36.90 | norm: 0.90\n",
      "step : 501 | loss: 4.4914422035217285 | dt: 163.26 ms | tokens/sec: 37.63 | norm: 0.92\n",
      "step : 502 | loss: 4.609955787658691 | dt: 165.62 ms | tokens/sec: 37.10 | norm: 0.82\n",
      "step : 503 | loss: 4.667263984680176 | dt: 164.72 ms | tokens/sec: 37.30 | norm: 0.72\n",
      "step : 504 | loss: 4.641882419586182 | dt: 164.20 ms | tokens/sec: 37.42 | norm: 1.24\n",
      "step : 505 | loss: 4.582921504974365 | dt: 165.83 ms | tokens/sec: 37.05 | norm: 0.94\n",
      "step : 506 | loss: 4.536136627197266 | dt: 163.75 ms | tokens/sec: 37.52 | norm: 0.84\n",
      "step : 507 | loss: 4.355732440948486 | dt: 164.02 ms | tokens/sec: 37.46 | norm: 0.89\n",
      "step : 508 | loss: 4.634658336639404 | dt: 164.26 ms | tokens/sec: 37.40 | norm: 0.85\n",
      "step : 509 | loss: 4.514227867126465 | dt: 163.69 ms | tokens/sec: 37.54 | norm: 0.98\n",
      "step : 510 | loss: 4.451130390167236 | dt: 164.70 ms | tokens/sec: 37.30 | norm: 1.08\n",
      "step : 511 | loss: 4.7781267166137695 | dt: 165.20 ms | tokens/sec: 37.19 | norm: 0.86\n",
      "step : 512 | loss: 4.865243911743164 | dt: 165.77 ms | tokens/sec: 37.06 | norm: 0.80\n",
      "step : 513 | loss: 4.771512031555176 | dt: 165.44 ms | tokens/sec: 37.14 | norm: 0.73\n",
      "step : 514 | loss: 4.7767486572265625 | dt: 164.69 ms | tokens/sec: 37.31 | norm: 0.77\n",
      "step : 515 | loss: 4.718947410583496 | dt: 163.58 ms | tokens/sec: 37.56 | norm: 0.69\n",
      "step : 516 | loss: 4.423705577850342 | dt: 164.47 ms | tokens/sec: 37.36 | norm: 0.79\n",
      "step : 517 | loss: 4.72210693359375 | dt: 163.86 ms | tokens/sec: 37.49 | norm: 0.75\n",
      "step : 518 | loss: 4.915210723876953 | dt: 164.40 ms | tokens/sec: 37.37 | norm: 0.86\n",
      "step : 519 | loss: 4.837621688842773 | dt: 166.92 ms | tokens/sec: 36.81 | norm: 0.94\n",
      "step : 520 | loss: 4.707121849060059 | dt: 165.11 ms | tokens/sec: 37.21 | norm: 0.98\n",
      "step : 521 | loss: 4.853908061981201 | dt: 164.43 ms | tokens/sec: 37.37 | norm: 1.16\n",
      "step : 522 | loss: 4.552426338195801 | dt: 165.69 ms | tokens/sec: 37.08 | norm: 0.88\n",
      "step : 523 | loss: 4.760138511657715 | dt: 163.36 ms | tokens/sec: 37.61 | norm: 0.77\n",
      "step : 524 | loss: 4.54100227355957 | dt: 163.51 ms | tokens/sec: 37.57 | norm: 1.02\n",
      "step : 525 | loss: 4.886876583099365 | dt: 165.65 ms | tokens/sec: 37.09 | norm: 0.84\n",
      "step : 526 | loss: 4.764011383056641 | dt: 163.11 ms | tokens/sec: 37.67 | norm: 0.76\n",
      "step : 527 | loss: 4.463623046875 | dt: 165.44 ms | tokens/sec: 37.14 | norm: 0.88\n",
      "step : 528 | loss: 4.571234703063965 | dt: 165.24 ms | tokens/sec: 37.18 | norm: 0.78\n",
      "step : 529 | loss: 4.607636451721191 | dt: 163.96 ms | tokens/sec: 37.47 | norm: 0.82\n",
      "step : 530 | loss: 4.683959484100342 | dt: 164.54 ms | tokens/sec: 37.34 | norm: 0.81\n",
      "step : 531 | loss: 5.0239973068237305 | dt: 165.59 ms | tokens/sec: 37.10 | norm: 1.24\n",
      "step : 532 | loss: 4.868539810180664 | dt: 164.42 ms | tokens/sec: 37.37 | norm: 1.13\n",
      "step : 533 | loss: 5.18747615814209 | dt: 165.59 ms | tokens/sec: 37.10 | norm: 1.17\n",
      "step : 534 | loss: 4.96776819229126 | dt: 163.51 ms | tokens/sec: 37.57 | norm: 0.94\n",
      "step : 535 | loss: 4.8226318359375 | dt: 163.48 ms | tokens/sec: 37.58 | norm: 1.00\n",
      "step : 536 | loss: 4.887973308563232 | dt: 164.55 ms | tokens/sec: 37.34 | norm: 1.07\n",
      "step : 537 | loss: 4.720605850219727 | dt: 164.56 ms | tokens/sec: 37.34 | norm: 0.97\n",
      "step : 538 | loss: 4.573740005493164 | dt: 165.55 ms | tokens/sec: 37.11 | norm: 1.29\n",
      "step : 539 | loss: 4.645809173583984 | dt: 165.70 ms | tokens/sec: 37.08 | norm: 1.06\n",
      "step : 540 | loss: 4.691763401031494 | dt: 163.80 ms | tokens/sec: 37.51 | norm: 0.99\n",
      "step : 541 | loss: 4.509502410888672 | dt: 163.78 ms | tokens/sec: 37.51 | norm: 0.95\n",
      "step : 542 | loss: 4.316633224487305 | dt: 163.95 ms | tokens/sec: 37.48 | norm: 0.96\n",
      "step : 543 | loss: 4.743145942687988 | dt: 164.31 ms | tokens/sec: 37.39 | norm: 1.03\n",
      "step : 544 | loss: 4.562185287475586 | dt: 165.33 ms | tokens/sec: 37.16 | norm: 1.14\n",
      "step : 545 | loss: 4.434741020202637 | dt: 165.05 ms | tokens/sec: 37.23 | norm: 1.03\n",
      "step : 546 | loss: 4.557689189910889 | dt: 164.34 ms | tokens/sec: 37.39 | norm: 0.80\n",
      "step : 547 | loss: 4.343270778656006 | dt: 165.28 ms | tokens/sec: 37.17 | norm: 0.94\n",
      "step : 548 | loss: 4.080728054046631 | dt: 164.75 ms | tokens/sec: 37.29 | norm: 0.84\n",
      "step : 549 | loss: 4.922388553619385 | dt: 163.40 ms | tokens/sec: 37.60 | norm: 1.10\n",
      "step : 550 | loss: 4.779864311218262 | dt: 164.82 ms | tokens/sec: 37.28 | norm: 1.10\n",
      "step : 551 | loss: 4.8459858894348145 | dt: 164.26 ms | tokens/sec: 37.40 | norm: 1.01\n",
      "step : 552 | loss: 4.781050682067871 | dt: 164.30 ms | tokens/sec: 37.40 | norm: 0.98\n",
      "step : 553 | loss: 4.728097915649414 | dt: 165.93 ms | tokens/sec: 37.03 | norm: 0.95\n",
      "step : 554 | loss: 4.4083123207092285 | dt: 163.93 ms | tokens/sec: 37.48 | norm: 1.07\n",
      "step : 555 | loss: 4.409762382507324 | dt: 163.39 ms | tokens/sec: 37.60 | norm: 0.87\n",
      "step : 556 | loss: 4.436108112335205 | dt: 164.36 ms | tokens/sec: 37.38 | norm: 0.89\n",
      "step : 557 | loss: 4.5655341148376465 | dt: 166.86 ms | tokens/sec: 36.82 | norm: 0.72\n",
      "step : 558 | loss: 4.641477584838867 | dt: 163.67 ms | tokens/sec: 37.54 | norm: 0.77\n",
      "step : 559 | loss: 4.624400615692139 | dt: 164.42 ms | tokens/sec: 37.37 | norm: 1.30\n",
      "step : 560 | loss: 4.562963008880615 | dt: 164.58 ms | tokens/sec: 37.33 | norm: 1.03\n",
      "step : 561 | loss: 4.500531196594238 | dt: 165.47 ms | tokens/sec: 37.13 | norm: 0.96\n",
      "step : 562 | loss: 4.322315216064453 | dt: 165.08 ms | tokens/sec: 37.22 | norm: 0.92\n",
      "step : 563 | loss: 4.593642234802246 | dt: 164.35 ms | tokens/sec: 37.38 | norm: 0.86\n",
      "step : 564 | loss: 4.449649333953857 | dt: 164.29 ms | tokens/sec: 37.40 | norm: 0.95\n",
      "step : 565 | loss: 4.382616996765137 | dt: 164.02 ms | tokens/sec: 37.46 | norm: 1.02\n",
      "step : 566 | loss: 4.713131904602051 | dt: 162.92 ms | tokens/sec: 37.71 | norm: 0.92\n",
      "step : 567 | loss: 4.797541618347168 | dt: 164.60 ms | tokens/sec: 37.33 | norm: 0.89\n",
      "step : 568 | loss: 4.720992565155029 | dt: 165.02 ms | tokens/sec: 37.23 | norm: 0.74\n",
      "step : 569 | loss: 4.7350568771362305 | dt: 165.56 ms | tokens/sec: 37.11 | norm: 0.83\n",
      "step : 570 | loss: 4.66609001159668 | dt: 164.74 ms | tokens/sec: 37.30 | norm: 0.77\n",
      "step : 571 | loss: 4.358128547668457 | dt: 163.98 ms | tokens/sec: 37.47 | norm: 0.85\n",
      "step : 572 | loss: 4.658452987670898 | dt: 162.82 ms | tokens/sec: 37.74 | norm: 0.77\n",
      "step : 573 | loss: 4.842772483825684 | dt: 163.92 ms | tokens/sec: 37.48 | norm: 0.83\n",
      "step : 574 | loss: 4.743661403656006 | dt: 163.63 ms | tokens/sec: 37.55 | norm: 0.98\n",
      "step : 575 | loss: 4.6225080490112305 | dt: 165.21 ms | tokens/sec: 37.19 | norm: 1.02\n",
      "step : 576 | loss: 4.785432815551758 | dt: 165.26 ms | tokens/sec: 37.18 | norm: 0.96\n",
      "step : 577 | loss: 4.464572906494141 | dt: 163.87 ms | tokens/sec: 37.49 | norm: 1.00\n",
      "step : 578 | loss: 4.702800750732422 | dt: 164.01 ms | tokens/sec: 37.46 | norm: 0.87\n",
      "step : 579 | loss: 4.511294364929199 | dt: 163.60 ms | tokens/sec: 37.55 | norm: 0.95\n",
      "step : 580 | loss: 4.836128234863281 | dt: 163.08 ms | tokens/sec: 37.67 | norm: 0.77\n",
      "step : 581 | loss: 4.745854377746582 | dt: 164.94 ms | tokens/sec: 37.25 | norm: 0.74\n",
      "step : 582 | loss: 4.48375940322876 | dt: 165.57 ms | tokens/sec: 37.11 | norm: 0.93\n",
      "step : 583 | loss: 4.594418048858643 | dt: 164.22 ms | tokens/sec: 37.41 | norm: 0.82\n",
      "step : 584 | loss: 4.592547416687012 | dt: 165.35 ms | tokens/sec: 37.16 | norm: 0.76\n",
      "step : 585 | loss: 4.6659440994262695 | dt: 164.66 ms | tokens/sec: 37.31 | norm: 0.77\n",
      "step : 586 | loss: 4.9701738357543945 | dt: 163.53 ms | tokens/sec: 37.57 | norm: 1.16\n",
      "step : 587 | loss: 4.835034370422363 | dt: 164.89 ms | tokens/sec: 37.26 | norm: 1.04\n",
      "step : 588 | loss: 5.128194332122803 | dt: 162.99 ms | tokens/sec: 37.70 | norm: 1.09\n",
      "step : 589 | loss: 4.891334533691406 | dt: 164.43 ms | tokens/sec: 37.36 | norm: 0.90\n",
      "step : 590 | loss: 4.7241339683532715 | dt: 165.34 ms | tokens/sec: 37.16 | norm: 0.95\n",
      "step : 591 | loss: 4.843835830688477 | dt: 164.39 ms | tokens/sec: 37.37 | norm: 0.99\n",
      "step : 592 | loss: 4.624110698699951 | dt: 164.53 ms | tokens/sec: 37.34 | norm: 0.87\n",
      "step : 593 | loss: 4.483702659606934 | dt: 165.35 ms | tokens/sec: 37.16 | norm: 1.15\n",
      "step : 594 | loss: 4.581357955932617 | dt: 162.79 ms | tokens/sec: 37.74 | norm: 1.01\n",
      "step : 595 | loss: 4.6053996086120605 | dt: 167.49 ms | tokens/sec: 36.68 | norm: 1.00\n",
      "step : 596 | loss: 4.440051078796387 | dt: 164.25 ms | tokens/sec: 37.41 | norm: 0.95\n",
      "step : 597 | loss: 4.291831970214844 | dt: 162.49 ms | tokens/sec: 37.81 | norm: 0.92\n",
      "step : 598 | loss: 4.708617210388184 | dt: 164.72 ms | tokens/sec: 37.30 | norm: 0.85\n",
      "step : 599 | loss: 4.54024076461792 | dt: 164.51 ms | tokens/sec: 37.35 | norm: 0.94\n",
      "step : 600 | loss: 4.425968647003174 | dt: 163.50 ms | tokens/sec: 37.58 | norm: 1.00\n",
      "step : 601 | loss: 4.528939247131348 | dt: 166.84 ms | tokens/sec: 36.83 | norm: 0.84\n",
      "step : 602 | loss: 4.290841102600098 | dt: 163.55 ms | tokens/sec: 37.57 | norm: 0.90\n",
      "step : 603 | loss: 4.060696601867676 | dt: 163.68 ms | tokens/sec: 37.54 | norm: 1.08\n",
      "step : 604 | loss: 4.81516170501709 | dt: 163.83 ms | tokens/sec: 37.50 | norm: 0.93\n",
      "step : 605 | loss: 4.671906471252441 | dt: 163.92 ms | tokens/sec: 37.48 | norm: 1.13\n",
      "step : 606 | loss: 4.78510856628418 | dt: 164.24 ms | tokens/sec: 37.41 | norm: 1.06\n",
      "step : 607 | loss: 4.762361526489258 | dt: 164.96 ms | tokens/sec: 37.25 | norm: 1.17\n",
      "step : 608 | loss: 4.728557109832764 | dt: 163.77 ms | tokens/sec: 37.52 | norm: 1.13\n",
      "step : 609 | loss: 4.356837272644043 | dt: 165.68 ms | tokens/sec: 37.08 | norm: 1.13\n",
      "step : 610 | loss: 4.379206657409668 | dt: 163.39 ms | tokens/sec: 37.60 | norm: 0.88\n",
      "step : 611 | loss: 4.4065961837768555 | dt: 162.39 ms | tokens/sec: 37.83 | norm: 0.85\n",
      "step : 612 | loss: 4.569138526916504 | dt: 164.86 ms | tokens/sec: 37.27 | norm: 0.79\n",
      "step : 613 | loss: 4.613389492034912 | dt: 164.38 ms | tokens/sec: 37.38 | norm: 0.86\n",
      "step : 614 | loss: 4.578145980834961 | dt: 166.41 ms | tokens/sec: 36.92 | norm: 1.24\n",
      "step : 615 | loss: 4.50886344909668 | dt: 165.66 ms | tokens/sec: 37.09 | norm: 1.02\n",
      "step : 616 | loss: 4.463263511657715 | dt: 164.29 ms | tokens/sec: 37.40 | norm: 0.83\n",
      "step : 617 | loss: 4.275619029998779 | dt: 162.43 ms | tokens/sec: 37.83 | norm: 0.97\n",
      "step : 618 | loss: 4.535608768463135 | dt: 163.57 ms | tokens/sec: 37.56 | norm: 0.91\n",
      "step : 619 | loss: 4.4057745933532715 | dt: 163.29 ms | tokens/sec: 37.63 | norm: 0.93\n",
      "step : 620 | loss: 4.306583404541016 | dt: 164.92 ms | tokens/sec: 37.25 | norm: 1.03\n",
      "step : 621 | loss: 4.656255722045898 | dt: 164.66 ms | tokens/sec: 37.31 | norm: 0.93\n",
      "step : 622 | loss: 4.736939430236816 | dt: 164.25 ms | tokens/sec: 37.41 | norm: 0.77\n",
      "step : 623 | loss: 4.6736650466918945 | dt: 165.21 ms | tokens/sec: 37.19 | norm: 0.73\n",
      "step : 624 | loss: 4.7050371170043945 | dt: 163.78 ms | tokens/sec: 37.51 | norm: 0.86\n",
      "step : 625 | loss: 4.663534641265869 | dt: 162.73 ms | tokens/sec: 37.76 | norm: 0.73\n",
      "step : 626 | loss: 4.3343000411987305 | dt: 164.72 ms | tokens/sec: 37.30 | norm: 0.86\n",
      "step : 627 | loss: 4.651725769042969 | dt: 166.19 ms | tokens/sec: 36.97 | norm: 0.91\n",
      "step : 628 | loss: 4.852458953857422 | dt: 164.81 ms | tokens/sec: 37.28 | norm: 1.20\n",
      "step : 629 | loss: 4.726256370544434 | dt: 166.23 ms | tokens/sec: 36.96 | norm: 0.93\n",
      "step : 630 | loss: 4.5860490798950195 | dt: 165.70 ms | tokens/sec: 37.08 | norm: 0.97\n",
      "step : 631 | loss: 4.698258399963379 | dt: 164.36 ms | tokens/sec: 37.38 | norm: 0.87\n",
      "step : 632 | loss: 4.425323009490967 | dt: 164.14 ms | tokens/sec: 37.43 | norm: 1.01\n",
      "step : 633 | loss: 4.706349849700928 | dt: 164.39 ms | tokens/sec: 37.37 | norm: 0.83\n",
      "step : 634 | loss: 4.583770751953125 | dt: 162.91 ms | tokens/sec: 37.71 | norm: 1.15\n",
      "step : 635 | loss: 4.888667583465576 | dt: 164.54 ms | tokens/sec: 37.34 | norm: 0.85\n",
      "step : 636 | loss: 4.762435436248779 | dt: 164.44 ms | tokens/sec: 37.36 | norm: 0.75\n",
      "step : 637 | loss: 4.47932243347168 | dt: 164.19 ms | tokens/sec: 37.42 | norm: 0.82\n",
      "step : 638 | loss: 4.573868751525879 | dt: 164.86 ms | tokens/sec: 37.27 | norm: 0.76\n",
      "step : 639 | loss: 4.6038689613342285 | dt: 165.84 ms | tokens/sec: 37.05 | norm: 0.89\n",
      "step : 640 | loss: 4.672199249267578 | dt: 164.75 ms | tokens/sec: 37.29 | norm: 0.81\n",
      "step : 641 | loss: 5.034163475036621 | dt: 165.69 ms | tokens/sec: 37.08 | norm: 1.24\n",
      "step : 642 | loss: 4.884811878204346 | dt: 162.87 ms | tokens/sec: 37.72 | norm: 1.08\n",
      "step : 643 | loss: 5.193530082702637 | dt: 163.39 ms | tokens/sec: 37.60 | norm: 1.20\n",
      "step : 644 | loss: 4.991388320922852 | dt: 164.92 ms | tokens/sec: 37.25 | norm: 1.05\n",
      "step : 645 | loss: 4.783349514007568 | dt: 163.37 ms | tokens/sec: 37.61 | norm: 1.05\n",
      "step : 646 | loss: 4.855925559997559 | dt: 165.99 ms | tokens/sec: 37.01 | norm: 0.88\n",
      "step : 647 | loss: 4.638690948486328 | dt: 165.27 ms | tokens/sec: 37.18 | norm: 0.85\n",
      "step : 648 | loss: 4.455080986022949 | dt: 166.69 ms | tokens/sec: 36.86 | norm: 1.11\n",
      "step : 649 | loss: 4.587377071380615 | dt: 165.87 ms | tokens/sec: 37.04 | norm: 1.07\n",
      "step : 650 | loss: 4.587225437164307 | dt: 165.58 ms | tokens/sec: 37.11 | norm: 0.92\n",
      "step : 651 | loss: 4.419598579406738 | dt: 163.20 ms | tokens/sec: 37.65 | norm: 0.93\n",
      "step : 652 | loss: 4.265678405761719 | dt: 165.09 ms | tokens/sec: 37.22 | norm: 0.95\n",
      "step : 653 | loss: 4.667628288269043 | dt: 162.94 ms | tokens/sec: 37.71 | norm: 0.87\n",
      "step : 654 | loss: 4.467561721801758 | dt: 165.00 ms | tokens/sec: 37.24 | norm: 1.00\n",
      "step : 655 | loss: 4.3515095710754395 | dt: 165.40 ms | tokens/sec: 37.15 | norm: 0.99\n",
      "step : 656 | loss: 4.458510398864746 | dt: 165.25 ms | tokens/sec: 37.18 | norm: 0.78\n",
      "step : 657 | loss: 4.235671520233154 | dt: 164.19 ms | tokens/sec: 37.42 | norm: 0.82\n",
      "step : 658 | loss: 4.0064191818237305 | dt: 164.92 ms | tokens/sec: 37.25 | norm: 1.03\n",
      "step : 659 | loss: 4.798076629638672 | dt: 163.45 ms | tokens/sec: 37.59 | norm: 0.97\n",
      "step : 660 | loss: 4.667840480804443 | dt: 165.80 ms | tokens/sec: 37.06 | norm: 1.17\n",
      "step : 661 | loss: 4.749983787536621 | dt: 164.50 ms | tokens/sec: 37.35 | norm: 0.99\n",
      "step : 662 | loss: 4.740991115570068 | dt: 164.20 ms | tokens/sec: 37.42 | norm: 1.06\n",
      "step : 663 | loss: 4.6970319747924805 | dt: 165.64 ms | tokens/sec: 37.09 | norm: 1.20\n",
      "step : 664 | loss: 4.358467102050781 | dt: 166.48 ms | tokens/sec: 36.91 | norm: 1.33\n",
      "step : 665 | loss: 4.353618621826172 | dt: 165.51 ms | tokens/sec: 37.12 | norm: 1.04\n",
      "step : 666 | loss: 4.3419294357299805 | dt: 165.22 ms | tokens/sec: 37.19 | norm: 0.83\n",
      "step : 667 | loss: 4.506113052368164 | dt: 166.44 ms | tokens/sec: 36.92 | norm: 0.91\n",
      "step : 668 | loss: 4.547992706298828 | dt: 164.81 ms | tokens/sec: 37.28 | norm: 0.67\n",
      "step : 669 | loss: 4.504540920257568 | dt: 165.46 ms | tokens/sec: 37.13 | norm: 1.18\n",
      "step : 670 | loss: 4.450836181640625 | dt: 165.58 ms | tokens/sec: 37.11 | norm: 0.97\n",
      "step : 671 | loss: 4.374869346618652 | dt: 164.50 ms | tokens/sec: 37.35 | norm: 0.81\n",
      "step : 672 | loss: 4.209447860717773 | dt: 164.46 ms | tokens/sec: 37.36 | norm: 1.15\n",
      "step : 673 | loss: 4.484494209289551 | dt: 162.89 ms | tokens/sec: 37.72 | norm: 0.87\n",
      "step : 674 | loss: 4.329635143280029 | dt: 163.80 ms | tokens/sec: 37.51 | norm: 0.86\n",
      "step : 675 | loss: 4.282284736633301 | dt: 165.55 ms | tokens/sec: 37.11 | norm: 0.84\n",
      "step : 676 | loss: 4.6259002685546875 | dt: 163.79 ms | tokens/sec: 37.51 | norm: 0.84\n",
      "step : 677 | loss: 4.692157745361328 | dt: 163.30 ms | tokens/sec: 37.62 | norm: 0.88\n",
      "step : 678 | loss: 4.630521297454834 | dt: 163.88 ms | tokens/sec: 37.49 | norm: 0.86\n",
      "step : 679 | loss: 4.620984077453613 | dt: 162.12 ms | tokens/sec: 37.90 | norm: 0.75\n",
      "step : 680 | loss: 4.596994400024414 | dt: 164.58 ms | tokens/sec: 37.33 | norm: 0.69\n",
      "step : 681 | loss: 4.258940696716309 | dt: 164.93 ms | tokens/sec: 37.25 | norm: 0.71\n",
      "step : 682 | loss: 4.59440803527832 | dt: 163.80 ms | tokens/sec: 37.51 | norm: 0.75\n",
      "step : 683 | loss: 4.823735237121582 | dt: 165.45 ms | tokens/sec: 37.13 | norm: 0.99\n",
      "step : 684 | loss: 4.719847679138184 | dt: 164.46 ms | tokens/sec: 37.36 | norm: 0.89\n",
      "step : 685 | loss: 4.6142425537109375 | dt: 162.68 ms | tokens/sec: 37.77 | norm: 0.95\n",
      "step : 686 | loss: 4.7195634841918945 | dt: 163.64 ms | tokens/sec: 37.55 | norm: 0.83\n",
      "step : 687 | loss: 4.402377605438232 | dt: 164.21 ms | tokens/sec: 37.42 | norm: 0.80\n",
      "step : 688 | loss: 4.615307331085205 | dt: 164.35 ms | tokens/sec: 37.38 | norm: 0.66\n",
      "step : 689 | loss: 4.4291276931762695 | dt: 165.78 ms | tokens/sec: 37.06 | norm: 0.90\n",
      "step : 690 | loss: 4.77092981338501 | dt: 164.93 ms | tokens/sec: 37.25 | norm: 0.77\n",
      "step : 691 | loss: 4.679468154907227 | dt: 162.42 ms | tokens/sec: 37.83 | norm: 0.73\n",
      "step : 692 | loss: 4.402927398681641 | dt: 163.89 ms | tokens/sec: 37.49 | norm: 0.88\n",
      "step : 693 | loss: 4.498089790344238 | dt: 163.01 ms | tokens/sec: 37.69 | norm: 0.73\n",
      "step : 694 | loss: 4.518019676208496 | dt: 164.04 ms | tokens/sec: 37.45 | norm: 0.81\n",
      "step : 695 | loss: 4.572016716003418 | dt: 164.64 ms | tokens/sec: 37.32 | norm: 0.75\n",
      "step : 696 | loss: 4.910125255584717 | dt: 164.03 ms | tokens/sec: 37.46 | norm: 1.10\n",
      "step : 697 | loss: 4.773875713348389 | dt: 165.79 ms | tokens/sec: 37.06 | norm: 0.99\n",
      "step : 698 | loss: 5.070855140686035 | dt: 165.65 ms | tokens/sec: 37.09 | norm: 0.97\n",
      "step : 699 | loss: 4.869606018066406 | dt: 162.99 ms | tokens/sec: 37.70 | norm: 0.98\n",
      "step : 700 | loss: 4.684595108032227 | dt: 165.09 ms | tokens/sec: 37.22 | norm: 1.08\n",
      "step : 701 | loss: 4.780098915100098 | dt: 163.74 ms | tokens/sec: 37.52 | norm: 0.90\n",
      "step : 702 | loss: 4.588212966918945 | dt: 164.12 ms | tokens/sec: 37.44 | norm: 0.86\n",
      "step : 703 | loss: 4.36693000793457 | dt: 166.47 ms | tokens/sec: 36.91 | norm: 1.05\n",
      "step : 704 | loss: 4.522073745727539 | dt: 164.10 ms | tokens/sec: 37.44 | norm: 1.08\n",
      "step : 705 | loss: 4.5394134521484375 | dt: 162.95 ms | tokens/sec: 37.71 | norm: 0.95\n",
      "step : 706 | loss: 4.372572898864746 | dt: 164.30 ms | tokens/sec: 37.40 | norm: 0.90\n",
      "step : 707 | loss: 4.219649314880371 | dt: 162.85 ms | tokens/sec: 37.73 | norm: 1.06\n",
      "step : 708 | loss: 4.627743721008301 | dt: 164.48 ms | tokens/sec: 37.35 | norm: 0.86\n",
      "step : 709 | loss: 4.432523727416992 | dt: 167.25 ms | tokens/sec: 36.73 | norm: 1.00\n",
      "step : 710 | loss: 4.319312572479248 | dt: 164.33 ms | tokens/sec: 37.39 | norm: 1.06\n",
      "step : 711 | loss: 4.41176176071167 | dt: 164.92 ms | tokens/sec: 37.25 | norm: 0.87\n",
      "step : 712 | loss: 4.212751388549805 | dt: 164.39 ms | tokens/sec: 37.37 | norm: 0.87\n",
      "step : 713 | loss: 3.9842355251312256 | dt: 163.73 ms | tokens/sec: 37.53 | norm: 1.02\n",
      "step : 714 | loss: 4.741103649139404 | dt: 164.89 ms | tokens/sec: 37.26 | norm: 1.05\n",
      "step : 715 | loss: 4.625042915344238 | dt: 163.88 ms | tokens/sec: 37.49 | norm: 1.25\n",
      "step : 716 | loss: 4.6658196449279785 | dt: 163.75 ms | tokens/sec: 37.52 | norm: 1.03\n",
      "step : 717 | loss: 4.64534854888916 | dt: 165.83 ms | tokens/sec: 37.05 | norm: 1.04\n",
      "step : 718 | loss: 4.59920597076416 | dt: 165.93 ms | tokens/sec: 37.03 | norm: 1.03\n",
      "step : 719 | loss: 4.273160934448242 | dt: 165.74 ms | tokens/sec: 37.07 | norm: 1.21\n",
      "step : 720 | loss: 4.2855119705200195 | dt: 166.74 ms | tokens/sec: 36.85 | norm: 1.12\n",
      "step : 721 | loss: 4.299630165100098 | dt: 165.13 ms | tokens/sec: 37.21 | norm: 0.97\n",
      "step : 722 | loss: 4.4711012840271 | dt: 165.75 ms | tokens/sec: 37.07 | norm: 0.88\n",
      "step : 723 | loss: 4.525960922241211 | dt: 166.55 ms | tokens/sec: 36.89 | norm: 0.93\n",
      "step : 724 | loss: 4.4524993896484375 | dt: 164.35 ms | tokens/sec: 37.38 | norm: 1.31\n",
      "step : 725 | loss: 4.39424467086792 | dt: 163.66 ms | tokens/sec: 37.54 | norm: 1.04\n",
      "step : 726 | loss: 4.362645149230957 | dt: 164.35 ms | tokens/sec: 37.38 | norm: 1.14\n",
      "step : 727 | loss: 4.190913677215576 | dt: 163.31 ms | tokens/sec: 37.62 | norm: 0.98\n",
      "step : 728 | loss: 4.463868141174316 | dt: 165.55 ms | tokens/sec: 37.11 | norm: 0.73\n",
      "step : 729 | loss: 4.277746677398682 | dt: 165.14 ms | tokens/sec: 37.21 | norm: 0.89\n",
      "step : 730 | loss: 4.204926013946533 | dt: 164.87 ms | tokens/sec: 37.27 | norm: 0.93\n",
      "step : 731 | loss: 4.565672874450684 | dt: 166.51 ms | tokens/sec: 36.90 | norm: 0.87\n",
      "step : 732 | loss: 4.65669059753418 | dt: 164.87 ms | tokens/sec: 37.27 | norm: 0.87\n",
      "step : 733 | loss: 4.589183330535889 | dt: 164.43 ms | tokens/sec: 37.37 | norm: 0.80\n",
      "step : 734 | loss: 4.580018997192383 | dt: 165.00 ms | tokens/sec: 37.24 | norm: 0.76\n",
      "step : 735 | loss: 4.559097766876221 | dt: 164.54 ms | tokens/sec: 37.34 | norm: 0.74\n",
      "step : 736 | loss: 4.222292900085449 | dt: 163.22 ms | tokens/sec: 37.64 | norm: 0.70\n",
      "step : 737 | loss: 4.519769668579102 | dt: 165.68 ms | tokens/sec: 37.08 | norm: 0.77\n",
      "step : 738 | loss: 4.706313610076904 | dt: 164.16 ms | tokens/sec: 37.43 | norm: 0.84\n",
      "step : 739 | loss: 4.613002300262451 | dt: 164.67 ms | tokens/sec: 37.31 | norm: 1.00\n",
      "step : 740 | loss: 4.4970598220825195 | dt: 165.88 ms | tokens/sec: 37.04 | norm: 1.00\n",
      "step : 741 | loss: 4.61903715133667 | dt: 168.10 ms | tokens/sec: 36.55 | norm: 0.93\n",
      "step : 742 | loss: 4.345478057861328 | dt: 166.19 ms | tokens/sec: 36.97 | norm: 0.95\n",
      "step : 743 | loss: 4.5836591720581055 | dt: 167.14 ms | tokens/sec: 36.76 | norm: 0.76\n",
      "step : 744 | loss: 4.388534069061279 | dt: 165.18 ms | tokens/sec: 37.20 | norm: 1.08\n",
      "step : 745 | loss: 4.718161582946777 | dt: 164.92 ms | tokens/sec: 37.25 | norm: 0.92\n",
      "step : 746 | loss: 4.603269577026367 | dt: 165.43 ms | tokens/sec: 37.14 | norm: 0.74\n",
      "step : 747 | loss: 4.364116668701172 | dt: 165.96 ms | tokens/sec: 37.02 | norm: 0.89\n",
      "step : 748 | loss: 4.467926025390625 | dt: 165.01 ms | tokens/sec: 37.23 | norm: 0.76\n",
      "step : 749 | loss: 4.483002185821533 | dt: 165.88 ms | tokens/sec: 37.04 | norm: 0.90\n",
      "step : 750 | loss: 4.557333946228027 | dt: 163.12 ms | tokens/sec: 37.67 | norm: 0.87\n",
      "step : 751 | loss: 4.879662990570068 | dt: 164.45 ms | tokens/sec: 37.36 | norm: 1.23\n",
      "step : 752 | loss: 4.725655555725098 | dt: 164.50 ms | tokens/sec: 37.35 | norm: 1.04\n",
      "step : 753 | loss: 5.025086402893066 | dt: 165.93 ms | tokens/sec: 37.03 | norm: 1.05\n",
      "step : 754 | loss: 4.825527191162109 | dt: 165.53 ms | tokens/sec: 37.12 | norm: 0.94\n",
      "step : 755 | loss: 4.654192924499512 | dt: 164.82 ms | tokens/sec: 37.28 | norm: 1.00\n",
      "step : 756 | loss: 4.730941295623779 | dt: 164.21 ms | tokens/sec: 37.42 | norm: 1.05\n",
      "step : 757 | loss: 4.523068904876709 | dt: 165.81 ms | tokens/sec: 37.05 | norm: 0.98\n",
      "step : 758 | loss: 4.274813175201416 | dt: 164.65 ms | tokens/sec: 37.32 | norm: 0.97\n",
      "step : 759 | loss: 4.468852996826172 | dt: 164.20 ms | tokens/sec: 37.42 | norm: 0.87\n",
      "step : 760 | loss: 4.4786834716796875 | dt: 165.04 ms | tokens/sec: 37.23 | norm: 0.91\n",
      "step : 761 | loss: 4.301506996154785 | dt: 163.62 ms | tokens/sec: 37.55 | norm: 0.90\n",
      "step : 762 | loss: 4.169450283050537 | dt: 164.80 ms | tokens/sec: 37.28 | norm: 1.02\n",
      "step : 763 | loss: 4.579311847686768 | dt: 166.65 ms | tokens/sec: 36.87 | norm: 0.88\n",
      "step : 764 | loss: 4.397502899169922 | dt: 164.99 ms | tokens/sec: 37.24 | norm: 1.09\n",
      "step : 765 | loss: 4.2661004066467285 | dt: 164.41 ms | tokens/sec: 37.37 | norm: 1.04\n",
      "step : 766 | loss: 4.386673927307129 | dt: 167.98 ms | tokens/sec: 36.58 | norm: 0.86\n",
      "step : 767 | loss: 4.157627582550049 | dt: 165.13 ms | tokens/sec: 37.21 | norm: 0.82\n",
      "step : 768 | loss: 3.9007949829101562 | dt: 164.88 ms | tokens/sec: 37.26 | norm: 0.88\n",
      "step : 769 | loss: 4.6605682373046875 | dt: 166.17 ms | tokens/sec: 36.97 | norm: 0.90\n",
      "step : 770 | loss: 4.545159816741943 | dt: 165.59 ms | tokens/sec: 37.10 | norm: 1.21\n",
      "step : 771 | loss: 4.620647430419922 | dt: 164.76 ms | tokens/sec: 37.29 | norm: 1.11\n",
      "step : 772 | loss: 4.594971656799316 | dt: 165.03 ms | tokens/sec: 37.23 | norm: 1.17\n",
      "step : 773 | loss: 4.5524702072143555 | dt: 164.30 ms | tokens/sec: 37.40 | norm: 1.09\n",
      "step : 774 | loss: 4.236682415008545 | dt: 164.94 ms | tokens/sec: 37.25 | norm: 1.02\n",
      "step : 775 | loss: 4.251411437988281 | dt: 164.40 ms | tokens/sec: 37.37 | norm: 0.87\n",
      "step : 776 | loss: 4.257744789123535 | dt: 164.62 ms | tokens/sec: 37.32 | norm: 0.90\n",
      "step : 777 | loss: 4.413869380950928 | dt: 165.99 ms | tokens/sec: 37.02 | norm: 0.76\n",
      "step : 778 | loss: 4.475210189819336 | dt: 165.61 ms | tokens/sec: 37.10 | norm: 0.77\n",
      "step : 779 | loss: 4.352263450622559 | dt: 165.97 ms | tokens/sec: 37.02 | norm: 1.17\n",
      "step : 780 | loss: 4.3363261222839355 | dt: 165.78 ms | tokens/sec: 37.06 | norm: 1.06\n",
      "step : 781 | loss: 4.296462059020996 | dt: 163.99 ms | tokens/sec: 37.47 | norm: 0.87\n",
      "step : 782 | loss: 4.1349053382873535 | dt: 163.65 ms | tokens/sec: 37.54 | norm: 0.89\n",
      "step : 783 | loss: 4.40972375869751 | dt: 165.38 ms | tokens/sec: 37.15 | norm: 0.79\n",
      "step : 784 | loss: 4.207550525665283 | dt: 163.39 ms | tokens/sec: 37.60 | norm: 0.79\n",
      "step : 785 | loss: 4.134156227111816 | dt: 166.69 ms | tokens/sec: 36.86 | norm: 0.80\n",
      "step : 786 | loss: 4.49854850769043 | dt: 165.25 ms | tokens/sec: 37.18 | norm: 0.84\n",
      "step : 787 | loss: 4.593313217163086 | dt: 166.20 ms | tokens/sec: 36.97 | norm: 0.78\n",
      "step : 788 | loss: 4.5396528244018555 | dt: 164.40 ms | tokens/sec: 37.37 | norm: 0.84\n",
      "step : 789 | loss: 4.519691467285156 | dt: 166.32 ms | tokens/sec: 36.94 | norm: 0.78\n",
      "step : 790 | loss: 4.5157084465026855 | dt: 165.18 ms | tokens/sec: 37.20 | norm: 0.75\n",
      "step : 791 | loss: 4.190713405609131 | dt: 167.03 ms | tokens/sec: 36.78 | norm: 0.74\n",
      "step : 792 | loss: 4.475162506103516 | dt: 166.12 ms | tokens/sec: 36.98 | norm: 0.86\n",
      "step : 793 | loss: 4.6553192138671875 | dt: 165.66 ms | tokens/sec: 37.09 | norm: 0.85\n",
      "step : 794 | loss: 4.517075538635254 | dt: 166.05 ms | tokens/sec: 37.00 | norm: 0.81\n",
      "step : 795 | loss: 4.416552543640137 | dt: 165.76 ms | tokens/sec: 37.07 | norm: 0.90\n",
      "step : 796 | loss: 4.566339492797852 | dt: 164.49 ms | tokens/sec: 37.35 | norm: 0.98\n",
      "step : 797 | loss: 4.270144939422607 | dt: 166.66 ms | tokens/sec: 36.86 | norm: 0.96\n",
      "step : 798 | loss: 4.5185089111328125 | dt: 165.15 ms | tokens/sec: 37.20 | norm: 0.86\n",
      "step : 799 | loss: 4.344549179077148 | dt: 164.30 ms | tokens/sec: 37.40 | norm: 1.12\n",
      "step : 800 | loss: 4.679534912109375 | dt: 165.18 ms | tokens/sec: 37.19 | norm: 1.00\n",
      "step : 801 | loss: 4.552466869354248 | dt: 165.08 ms | tokens/sec: 37.22 | norm: 0.84\n",
      "step : 802 | loss: 4.31550407409668 | dt: 165.01 ms | tokens/sec: 37.23 | norm: 0.91\n",
      "step : 803 | loss: 4.420772552490234 | dt: 166.37 ms | tokens/sec: 36.93 | norm: 0.78\n",
      "step : 804 | loss: 4.42753791809082 | dt: 166.14 ms | tokens/sec: 36.98 | norm: 0.85\n",
      "step : 805 | loss: 4.490708827972412 | dt: 164.93 ms | tokens/sec: 37.25 | norm: 0.78\n",
      "step : 806 | loss: 4.8490705490112305 | dt: 166.38 ms | tokens/sec: 36.93 | norm: 1.31\n",
      "step : 807 | loss: 4.709981918334961 | dt: 165.17 ms | tokens/sec: 37.20 | norm: 1.08\n",
      "step : 808 | loss: 5.006387233734131 | dt: 165.61 ms | tokens/sec: 37.10 | norm: 1.13\n",
      "step : 809 | loss: 4.816010475158691 | dt: 166.62 ms | tokens/sec: 36.87 | norm: 0.96\n",
      "step : 810 | loss: 4.613255500793457 | dt: 166.60 ms | tokens/sec: 36.88 | norm: 0.95\n",
      "step : 811 | loss: 4.694139003753662 | dt: 165.26 ms | tokens/sec: 37.18 | norm: 0.96\n",
      "step : 812 | loss: 4.479789733886719 | dt: 165.30 ms | tokens/sec: 37.17 | norm: 1.06\n",
      "step : 813 | loss: 4.254570960998535 | dt: 165.50 ms | tokens/sec: 37.12 | norm: 1.07\n",
      "step : 814 | loss: 4.4076337814331055 | dt: 167.02 ms | tokens/sec: 36.79 | norm: 0.91\n",
      "step : 815 | loss: 4.39487886428833 | dt: 166.18 ms | tokens/sec: 36.97 | norm: 0.92\n",
      "step : 816 | loss: 4.236196517944336 | dt: 165.12 ms | tokens/sec: 37.21 | norm: 0.83\n",
      "step : 817 | loss: 4.100076198577881 | dt: 168.39 ms | tokens/sec: 36.49 | norm: 0.83\n",
      "step : 818 | loss: 4.514028072357178 | dt: 165.23 ms | tokens/sec: 37.18 | norm: 0.81\n",
      "step : 819 | loss: 4.311662197113037 | dt: 163.80 ms | tokens/sec: 37.51 | norm: 1.08\n",
      "step : 820 | loss: 4.1927995681762695 | dt: 166.89 ms | tokens/sec: 36.81 | norm: 1.10\n",
      "step : 821 | loss: 4.289682388305664 | dt: 165.38 ms | tokens/sec: 37.15 | norm: 0.92\n",
      "step : 822 | loss: 4.0961384773254395 | dt: 165.40 ms | tokens/sec: 37.15 | norm: 0.83\n",
      "step : 823 | loss: 3.856133460998535 | dt: 165.30 ms | tokens/sec: 37.17 | norm: 0.96\n",
      "step : 824 | loss: 4.579310417175293 | dt: 164.94 ms | tokens/sec: 37.25 | norm: 1.02\n",
      "step : 825 | loss: 4.4636640548706055 | dt: 165.98 ms | tokens/sec: 37.02 | norm: 1.20\n",
      "step : 826 | loss: 4.555854797363281 | dt: 165.23 ms | tokens/sec: 37.18 | norm: 1.00\n",
      "step : 827 | loss: 4.540572643280029 | dt: 165.56 ms | tokens/sec: 37.11 | norm: 0.96\n",
      "step : 828 | loss: 4.479910850524902 | dt: 166.40 ms | tokens/sec: 36.92 | norm: 1.07\n",
      "step : 829 | loss: 4.154951095581055 | dt: 164.78 ms | tokens/sec: 37.29 | norm: 1.10\n",
      "step : 830 | loss: 4.172087669372559 | dt: 165.51 ms | tokens/sec: 37.12 | norm: 0.88\n",
      "step : 831 | loss: 4.1885528564453125 | dt: 164.96 ms | tokens/sec: 37.25 | norm: 0.73\n",
      "step : 832 | loss: 4.34625768661499 | dt: 165.28 ms | tokens/sec: 37.17 | norm: 0.74\n",
      "step : 833 | loss: 4.416736125946045 | dt: 164.37 ms | tokens/sec: 37.38 | norm: 0.80\n",
      "step : 834 | loss: 4.299777984619141 | dt: 165.71 ms | tokens/sec: 37.08 | norm: 1.05\n",
      "step : 835 | loss: 4.318698406219482 | dt: 165.12 ms | tokens/sec: 37.21 | norm: 0.98\n",
      "step : 836 | loss: 4.297597408294678 | dt: 165.31 ms | tokens/sec: 37.17 | norm: 1.25\n",
      "step : 837 | loss: 4.129887580871582 | dt: 165.63 ms | tokens/sec: 37.09 | norm: 1.23\n",
      "step : 838 | loss: 4.367509841918945 | dt: 165.90 ms | tokens/sec: 37.03 | norm: 0.89\n",
      "step : 839 | loss: 4.186418056488037 | dt: 165.33 ms | tokens/sec: 37.16 | norm: 0.95\n",
      "step : 840 | loss: 4.105198383331299 | dt: 165.80 ms | tokens/sec: 37.06 | norm: 0.85\n",
      "step : 841 | loss: 4.453393936157227 | dt: 167.08 ms | tokens/sec: 36.77 | norm: 0.78\n",
      "step : 842 | loss: 4.558966159820557 | dt: 167.07 ms | tokens/sec: 36.78 | norm: 0.83\n",
      "step : 843 | loss: 4.523894309997559 | dt: 164.64 ms | tokens/sec: 37.32 | norm: 1.15\n",
      "step : 844 | loss: 4.48781681060791 | dt: 165.98 ms | tokens/sec: 37.02 | norm: 0.84\n",
      "step : 845 | loss: 4.478390693664551 | dt: 165.28 ms | tokens/sec: 37.17 | norm: 0.88\n",
      "step : 846 | loss: 4.146392822265625 | dt: 165.47 ms | tokens/sec: 37.13 | norm: 0.72\n",
      "step : 847 | loss: 4.450399875640869 | dt: 166.47 ms | tokens/sec: 36.91 | norm: 0.81\n",
      "step : 848 | loss: 4.660023212432861 | dt: 167.76 ms | tokens/sec: 36.62 | norm: 0.93\n",
      "step : 849 | loss: 4.521975040435791 | dt: 164.99 ms | tokens/sec: 37.24 | norm: 0.90\n",
      "step : 850 | loss: 4.410516738891602 | dt: 164.49 ms | tokens/sec: 37.35 | norm: 0.93\n",
      "step : 851 | loss: 4.526860237121582 | dt: 166.17 ms | tokens/sec: 36.97 | norm: 0.97\n",
      "step : 852 | loss: 4.238225936889648 | dt: 164.41 ms | tokens/sec: 37.37 | norm: 0.95\n",
      "step : 853 | loss: 4.459814548492432 | dt: 164.79 ms | tokens/sec: 37.28 | norm: 0.84\n",
      "step : 854 | loss: 4.326354026794434 | dt: 165.79 ms | tokens/sec: 37.06 | norm: 1.14\n",
      "step : 855 | loss: 4.645388603210449 | dt: 164.88 ms | tokens/sec: 37.26 | norm: 0.96\n",
      "step : 856 | loss: 4.560243606567383 | dt: 165.89 ms | tokens/sec: 37.04 | norm: 0.99\n",
      "step : 857 | loss: 4.311244487762451 | dt: 166.07 ms | tokens/sec: 37.00 | norm: 0.96\n",
      "step : 858 | loss: 4.424580097198486 | dt: 166.34 ms | tokens/sec: 36.94 | norm: 0.92\n",
      "step : 859 | loss: 4.412443161010742 | dt: 165.62 ms | tokens/sec: 37.10 | norm: 0.74\n",
      "step : 860 | loss: 4.450244426727295 | dt: 165.58 ms | tokens/sec: 37.11 | norm: 0.76\n",
      "step : 861 | loss: 4.811929225921631 | dt: 167.12 ms | tokens/sec: 36.76 | norm: 1.08\n",
      "step : 862 | loss: 4.695281982421875 | dt: 165.67 ms | tokens/sec: 37.09 | norm: 1.05\n",
      "step : 863 | loss: 5.02006721496582 | dt: 166.49 ms | tokens/sec: 36.90 | norm: 1.26\n",
      "step : 864 | loss: 4.842642784118652 | dt: 165.67 ms | tokens/sec: 37.08 | norm: 1.08\n",
      "step : 865 | loss: 4.654068946838379 | dt: 165.60 ms | tokens/sec: 37.10 | norm: 0.92\n",
      "step : 866 | loss: 4.701991558074951 | dt: 166.68 ms | tokens/sec: 36.86 | norm: 0.76\n",
      "step : 867 | loss: 4.542627334594727 | dt: 166.53 ms | tokens/sec: 36.89 | norm: 0.98\n",
      "step : 868 | loss: 4.344481468200684 | dt: 164.67 ms | tokens/sec: 37.31 | norm: 1.23\n",
      "step : 869 | loss: 4.395959377288818 | dt: 166.97 ms | tokens/sec: 36.80 | norm: 1.10\n",
      "step : 870 | loss: 4.416954040527344 | dt: 165.59 ms | tokens/sec: 37.10 | norm: 0.94\n",
      "step : 871 | loss: 4.236209869384766 | dt: 167.52 ms | tokens/sec: 36.68 | norm: 0.83\n",
      "step : 872 | loss: 4.109927654266357 | dt: 165.24 ms | tokens/sec: 37.18 | norm: 0.84\n",
      "step : 873 | loss: 4.523065090179443 | dt: 167.73 ms | tokens/sec: 36.63 | norm: 0.91\n",
      "step : 874 | loss: 4.320679664611816 | dt: 165.90 ms | tokens/sec: 37.03 | norm: 1.08\n",
      "step : 875 | loss: 4.198916435241699 | dt: 165.95 ms | tokens/sec: 37.02 | norm: 1.10\n",
      "step : 876 | loss: 4.274084091186523 | dt: 165.47 ms | tokens/sec: 37.13 | norm: 1.02\n",
      "step : 877 | loss: 4.0777411460876465 | dt: 164.89 ms | tokens/sec: 37.26 | norm: 1.01\n",
      "step : 878 | loss: 3.8323256969451904 | dt: 166.26 ms | tokens/sec: 36.95 | norm: 1.01\n",
      "step : 879 | loss: 4.5454535484313965 | dt: 164.27 ms | tokens/sec: 37.40 | norm: 0.88\n",
      "step : 880 | loss: 4.44683837890625 | dt: 166.70 ms | tokens/sec: 36.86 | norm: 1.21\n",
      "step : 881 | loss: 4.502281665802002 | dt: 165.59 ms | tokens/sec: 37.10 | norm: 1.22\n",
      "step : 882 | loss: 4.495189189910889 | dt: 165.41 ms | tokens/sec: 37.14 | norm: 1.12\n",
      "step : 883 | loss: 4.457739353179932 | dt: 165.84 ms | tokens/sec: 37.05 | norm: 1.05\n",
      "step : 884 | loss: 4.157270431518555 | dt: 166.63 ms | tokens/sec: 36.87 | norm: 1.13\n",
      "step : 885 | loss: 4.174131870269775 | dt: 166.34 ms | tokens/sec: 36.94 | norm: 1.04\n",
      "step : 886 | loss: 4.188581466674805 | dt: 168.56 ms | tokens/sec: 36.45 | norm: 0.94\n",
      "step : 887 | loss: 4.333376407623291 | dt: 165.52 ms | tokens/sec: 37.12 | norm: 0.84\n",
      "step : 888 | loss: 4.390674591064453 | dt: 166.10 ms | tokens/sec: 36.99 | norm: 0.73\n",
      "step : 889 | loss: 4.295413017272949 | dt: 165.94 ms | tokens/sec: 37.02 | norm: 0.97\n",
      "step : 890 | loss: 4.315626621246338 | dt: 166.58 ms | tokens/sec: 36.88 | norm: 0.91\n",
      "step : 891 | loss: 4.286808967590332 | dt: 165.53 ms | tokens/sec: 37.12 | norm: 0.85\n",
      "step : 892 | loss: 4.07879638671875 | dt: 167.48 ms | tokens/sec: 36.69 | norm: 0.98\n",
      "step : 893 | loss: 4.323028564453125 | dt: 165.82 ms | tokens/sec: 37.05 | norm: 0.89\n",
      "step : 894 | loss: 4.135558605194092 | dt: 165.94 ms | tokens/sec: 37.03 | norm: 1.17\n",
      "step : 895 | loss: 4.052502632141113 | dt: 166.79 ms | tokens/sec: 36.84 | norm: 0.84\n",
      "step : 896 | loss: 4.401346206665039 | dt: 167.49 ms | tokens/sec: 36.68 | norm: 0.78\n",
      "step : 897 | loss: 4.50391149520874 | dt: 165.56 ms | tokens/sec: 37.11 | norm: 0.81\n",
      "step : 898 | loss: 4.490340232849121 | dt: 167.73 ms | tokens/sec: 36.63 | norm: 0.75\n",
      "step : 899 | loss: 4.4169745445251465 | dt: 165.71 ms | tokens/sec: 37.08 | norm: 0.75\n",
      "step : 900 | loss: 4.389902114868164 | dt: 165.87 ms | tokens/sec: 37.04 | norm: 0.70\n",
      "step : 901 | loss: 4.0697760581970215 | dt: 166.98 ms | tokens/sec: 36.80 | norm: 0.70\n",
      "step : 902 | loss: 4.374746322631836 | dt: 166.94 ms | tokens/sec: 36.80 | norm: 0.77\n",
      "step : 903 | loss: 4.5751519203186035 | dt: 166.18 ms | tokens/sec: 36.97 | norm: 0.80\n",
      "step : 904 | loss: 4.480607032775879 | dt: 166.05 ms | tokens/sec: 37.00 | norm: 0.83\n",
      "step : 905 | loss: 4.394244194030762 | dt: 167.69 ms | tokens/sec: 36.64 | norm: 0.91\n",
      "step : 906 | loss: 4.4881086349487305 | dt: 166.06 ms | tokens/sec: 37.00 | norm: 0.95\n",
      "step : 907 | loss: 4.216333389282227 | dt: 168.30 ms | tokens/sec: 36.51 | norm: 0.83\n",
      "step : 908 | loss: 4.437700271606445 | dt: 165.74 ms | tokens/sec: 37.07 | norm: 0.74\n",
      "step : 909 | loss: 4.239626884460449 | dt: 165.98 ms | tokens/sec: 37.02 | norm: 0.93\n",
      "step : 910 | loss: 4.549190998077393 | dt: 167.57 ms | tokens/sec: 36.67 | norm: 0.81\n",
      "step : 911 | loss: 4.451395511627197 | dt: 167.57 ms | tokens/sec: 36.67 | norm: 0.78\n",
      "step : 912 | loss: 4.215320587158203 | dt: 166.42 ms | tokens/sec: 36.92 | norm: 0.87\n",
      "step : 913 | loss: 4.334889888763428 | dt: 167.50 ms | tokens/sec: 36.68 | norm: 0.86\n",
      "step : 914 | loss: 4.342473983764648 | dt: 165.81 ms | tokens/sec: 37.06 | norm: 0.72\n",
      "step : 915 | loss: 4.358643054962158 | dt: 166.07 ms | tokens/sec: 37.00 | norm: 0.76\n",
      "step : 916 | loss: 4.675667762756348 | dt: 167.10 ms | tokens/sec: 36.77 | norm: 0.99\n",
      "step : 917 | loss: 4.604114055633545 | dt: 166.82 ms | tokens/sec: 36.83 | norm: 1.00\n",
      "step : 918 | loss: 4.929603576660156 | dt: 165.75 ms | tokens/sec: 37.07 | norm: 1.13\n",
      "step : 919 | loss: 4.739152908325195 | dt: 167.32 ms | tokens/sec: 36.72 | norm: 1.06\n",
      "step : 920 | loss: 4.571969985961914 | dt: 166.00 ms | tokens/sec: 37.01 | norm: 0.92\n",
      "step : 921 | loss: 4.643006801605225 | dt: 166.26 ms | tokens/sec: 36.95 | norm: 0.84\n",
      "step : 922 | loss: 4.452520370483398 | dt: 167.11 ms | tokens/sec: 36.77 | norm: 0.98\n",
      "step : 923 | loss: 4.283294200897217 | dt: 166.19 ms | tokens/sec: 36.97 | norm: 1.21\n",
      "step : 924 | loss: 4.352681636810303 | dt: 165.02 ms | tokens/sec: 37.23 | norm: 1.00\n",
      "step : 925 | loss: 4.389258861541748 | dt: 167.47 ms | tokens/sec: 36.69 | norm: 0.89\n",
      "step : 926 | loss: 4.208074569702148 | dt: 166.13 ms | tokens/sec: 36.98 | norm: 0.82\n",
      "step : 927 | loss: 4.057673454284668 | dt: 166.01 ms | tokens/sec: 37.01 | norm: 0.79\n",
      "step : 928 | loss: 4.456758499145508 | dt: 167.42 ms | tokens/sec: 36.70 | norm: 0.80\n",
      "step : 929 | loss: 4.310187339782715 | dt: 165.95 ms | tokens/sec: 37.02 | norm: 1.03\n",
      "step : 930 | loss: 4.194087505340576 | dt: 167.69 ms | tokens/sec: 36.64 | norm: 1.03\n",
      "step : 931 | loss: 4.2428717613220215 | dt: 167.16 ms | tokens/sec: 36.75 | norm: 0.93\n",
      "step : 932 | loss: 4.034843921661377 | dt: 165.44 ms | tokens/sec: 37.14 | norm: 0.81\n",
      "step : 933 | loss: 3.7798240184783936 | dt: 166.14 ms | tokens/sec: 36.98 | norm: 0.83\n",
      "step : 934 | loss: 4.497295379638672 | dt: 166.36 ms | tokens/sec: 36.93 | norm: 0.81\n",
      "step : 935 | loss: 4.37119197845459 | dt: 166.64 ms | tokens/sec: 36.87 | norm: 1.01\n",
      "step : 936 | loss: 4.469182014465332 | dt: 166.66 ms | tokens/sec: 36.87 | norm: 0.98\n",
      "step : 937 | loss: 4.444741249084473 | dt: 167.19 ms | tokens/sec: 36.75 | norm: 0.98\n",
      "step : 938 | loss: 4.38886833190918 | dt: 166.22 ms | tokens/sec: 36.96 | norm: 0.97\n",
      "step : 939 | loss: 4.07809591293335 | dt: 166.16 ms | tokens/sec: 36.98 | norm: 0.87\n",
      "step : 940 | loss: 4.10748815536499 | dt: 167.34 ms | tokens/sec: 36.72 | norm: 0.80\n",
      "step : 941 | loss: 4.092806816101074 | dt: 166.38 ms | tokens/sec: 36.93 | norm: 0.77\n",
      "step : 942 | loss: 4.298375129699707 | dt: 166.40 ms | tokens/sec: 36.92 | norm: 0.82\n",
      "step : 943 | loss: 4.319324016571045 | dt: 167.46 ms | tokens/sec: 36.69 | norm: 0.75\n",
      "step : 944 | loss: 4.211877822875977 | dt: 165.80 ms | tokens/sec: 37.06 | norm: 1.00\n",
      "step : 945 | loss: 4.2173051834106445 | dt: 165.96 ms | tokens/sec: 37.02 | norm: 0.91\n",
      "step : 946 | loss: 4.214927673339844 | dt: 167.60 ms | tokens/sec: 36.66 | norm: 0.87\n",
      "step : 947 | loss: 4.039163589477539 | dt: 165.67 ms | tokens/sec: 37.09 | norm: 1.00\n",
      "step : 948 | loss: 4.300056457519531 | dt: 166.17 ms | tokens/sec: 36.97 | norm: 1.01\n",
      "step : 949 | loss: 4.148696422576904 | dt: 168.01 ms | tokens/sec: 36.57 | norm: 1.22\n",
      "step : 950 | loss: 4.033048629760742 | dt: 166.13 ms | tokens/sec: 36.98 | norm: 0.95\n",
      "step : 951 | loss: 4.375528812408447 | dt: 166.05 ms | tokens/sec: 37.00 | norm: 0.92\n",
      "step : 952 | loss: 4.429433822631836 | dt: 167.27 ms | tokens/sec: 36.73 | norm: 0.81\n",
      "step : 953 | loss: 4.361316204071045 | dt: 165.65 ms | tokens/sec: 37.09 | norm: 0.67\n",
      "step : 954 | loss: 4.326582908630371 | dt: 165.93 ms | tokens/sec: 37.03 | norm: 0.75\n",
      "step : 955 | loss: 4.3182220458984375 | dt: 168.75 ms | tokens/sec: 36.41 | norm: 0.65\n",
      "step : 956 | loss: 4.007699012756348 | dt: 166.27 ms | tokens/sec: 36.95 | norm: 0.62\n",
      "step : 957 | loss: 4.303586483001709 | dt: 165.90 ms | tokens/sec: 37.03 | norm: 0.73\n",
      "step : 958 | loss: 4.490131378173828 | dt: 167.28 ms | tokens/sec: 36.73 | norm: 0.74\n",
      "step : 959 | loss: 4.415783882141113 | dt: 165.86 ms | tokens/sec: 37.04 | norm: 0.84\n",
      "step : 960 | loss: 4.2962751388549805 | dt: 165.96 ms | tokens/sec: 37.02 | norm: 0.88\n",
      "step : 961 | loss: 4.424984455108643 | dt: 168.27 ms | tokens/sec: 36.51 | norm: 0.95\n",
      "step : 962 | loss: 4.16815185546875 | dt: 166.38 ms | tokens/sec: 36.93 | norm: 0.74\n",
      "step : 963 | loss: 4.4007720947265625 | dt: 165.81 ms | tokens/sec: 37.05 | norm: 0.74\n",
      "step : 964 | loss: 4.203862190246582 | dt: 167.28 ms | tokens/sec: 36.73 | norm: 0.91\n",
      "step : 965 | loss: 4.527490139007568 | dt: 165.98 ms | tokens/sec: 37.02 | norm: 0.84\n",
      "step : 966 | loss: 4.41966438293457 | dt: 165.89 ms | tokens/sec: 37.04 | norm: 0.83\n",
      "step : 967 | loss: 4.155123710632324 | dt: 168.34 ms | tokens/sec: 36.50 | norm: 0.87\n",
      "step : 968 | loss: 4.265535354614258 | dt: 166.07 ms | tokens/sec: 37.00 | norm: 0.77\n",
      "step : 969 | loss: 4.280127048492432 | dt: 166.13 ms | tokens/sec: 36.98 | norm: 0.77\n",
      "step : 970 | loss: 4.300538539886475 | dt: 167.63 ms | tokens/sec: 36.65 | norm: 0.78\n",
      "step : 971 | loss: 4.598484992980957 | dt: 165.61 ms | tokens/sec: 37.10 | norm: 1.00\n",
      "step : 972 | loss: 4.52681827545166 | dt: 165.82 ms | tokens/sec: 37.05 | norm: 0.99\n",
      "step : 973 | loss: 4.8437676429748535 | dt: 167.14 ms | tokens/sec: 36.76 | norm: 1.06\n",
      "step : 974 | loss: 4.646231651306152 | dt: 168.14 ms | tokens/sec: 36.54 | norm: 0.97\n",
      "step : 975 | loss: 4.463771343231201 | dt: 166.10 ms | tokens/sec: 36.99 | norm: 0.86\n",
      "step : 976 | loss: 4.56033992767334 | dt: 166.85 ms | tokens/sec: 36.82 | norm: 0.77\n",
      "step : 977 | loss: 4.35727596282959 | dt: 166.06 ms | tokens/sec: 37.00 | norm: 0.96\n",
      "step : 978 | loss: 4.19609260559082 | dt: 165.97 ms | tokens/sec: 37.02 | norm: 1.23\n",
      "step : 979 | loss: 4.288337230682373 | dt: 166.91 ms | tokens/sec: 36.81 | norm: 1.01\n",
      "step : 980 | loss: 4.311795234680176 | dt: 166.59 ms | tokens/sec: 36.88 | norm: 0.82\n",
      "step : 981 | loss: 4.138592720031738 | dt: 165.91 ms | tokens/sec: 37.03 | norm: 0.76\n",
      "step : 982 | loss: 4.012916564941406 | dt: 167.10 ms | tokens/sec: 36.77 | norm: 0.82\n",
      "step : 983 | loss: 4.395586967468262 | dt: 165.69 ms | tokens/sec: 37.08 | norm: 0.87\n",
      "step : 984 | loss: 4.229496002197266 | dt: 165.88 ms | tokens/sec: 37.04 | norm: 1.17\n",
      "step : 985 | loss: 4.094701766967773 | dt: 167.15 ms | tokens/sec: 36.76 | norm: 1.18\n",
      "step : 986 | loss: 4.151673793792725 | dt: 167.21 ms | tokens/sec: 36.74 | norm: 0.90\n",
      "step : 987 | loss: 3.9736783504486084 | dt: 166.44 ms | tokens/sec: 36.91 | norm: 0.84\n",
      "step : 988 | loss: 3.7077841758728027 | dt: 167.37 ms | tokens/sec: 36.71 | norm: 0.90\n",
      "step : 989 | loss: 4.427989959716797 | dt: 165.87 ms | tokens/sec: 37.04 | norm: 0.80\n",
      "step : 990 | loss: 4.28961706161499 | dt: 166.37 ms | tokens/sec: 36.93 | norm: 1.10\n",
      "step : 991 | loss: 4.383103370666504 | dt: 168.11 ms | tokens/sec: 36.55 | norm: 1.10\n",
      "step : 992 | loss: 4.3891377449035645 | dt: 166.39 ms | tokens/sec: 36.93 | norm: 1.03\n",
      "step : 993 | loss: 4.354054927825928 | dt: 165.94 ms | tokens/sec: 37.02 | norm: 0.94\n",
      "step : 994 | loss: 4.032539367675781 | dt: 167.18 ms | tokens/sec: 36.75 | norm: 0.88\n",
      "step : 995 | loss: 4.085442066192627 | dt: 165.72 ms | tokens/sec: 37.07 | norm: 0.83\n",
      "step : 996 | loss: 4.080020427703857 | dt: 166.43 ms | tokens/sec: 36.92 | norm: 0.86\n",
      "step : 997 | loss: 4.264890670776367 | dt: 168.91 ms | tokens/sec: 36.37 | norm: 0.78\n",
      "step : 998 | loss: 4.275157928466797 | dt: 166.29 ms | tokens/sec: 36.95 | norm: 0.77\n",
      "step : 999 | loss: 4.1362104415893555 | dt: 168.28 ms | tokens/sec: 36.51 | norm: 0.94\n",
      "step : 1000 | loss: 4.119754791259766 | dt: 167.16 ms | tokens/sec: 36.75 | norm: 0.88\n",
      "step : 1001 | loss: 4.105222702026367 | dt: 165.95 ms | tokens/sec: 37.02 | norm: 0.77\n",
      "step : 1002 | loss: 3.9590468406677246 | dt: 165.82 ms | tokens/sec: 37.05 | norm: 0.87\n",
      "step : 1003 | loss: 4.216093063354492 | dt: 167.23 ms | tokens/sec: 36.74 | norm: 0.74\n",
      "step : 1004 | loss: 4.0576863288879395 | dt: 165.86 ms | tokens/sec: 37.04 | norm: 0.83\n",
      "step : 1005 | loss: 3.9702014923095703 | dt: 167.38 ms | tokens/sec: 36.71 | norm: 0.87\n",
      "step : 1006 | loss: 4.2814249992370605 | dt: 167.45 ms | tokens/sec: 36.69 | norm: 0.82\n",
      "step : 1007 | loss: 4.3867340087890625 | dt: 166.84 ms | tokens/sec: 36.83 | norm: 0.82\n",
      "step : 1008 | loss: 4.308612823486328 | dt: 167.96 ms | tokens/sec: 36.58 | norm: 0.76\n",
      "step : 1009 | loss: 4.302214622497559 | dt: 167.17 ms | tokens/sec: 36.75 | norm: 0.83\n",
      "step : 1010 | loss: 4.2960734367370605 | dt: 167.73 ms | tokens/sec: 36.63 | norm: 0.78\n",
      "step : 1011 | loss: 3.9652411937713623 | dt: 168.71 ms | tokens/sec: 36.42 | norm: 0.75\n",
      "step : 1012 | loss: 4.229928493499756 | dt: 167.64 ms | tokens/sec: 36.65 | norm: 0.76\n",
      "step : 1013 | loss: 4.404290199279785 | dt: 169.02 ms | tokens/sec: 36.35 | norm: 0.81\n",
      "step : 1014 | loss: 4.332536697387695 | dt: 168.49 ms | tokens/sec: 36.47 | norm: 0.89\n",
      "step : 1015 | loss: 4.208759307861328 | dt: 168.06 ms | tokens/sec: 36.56 | norm: 0.82\n",
      "step : 1016 | loss: 4.330169677734375 | dt: 168.32 ms | tokens/sec: 36.50 | norm: 0.87\n",
      "step : 1017 | loss: 4.10970401763916 | dt: 169.48 ms | tokens/sec: 36.25 | norm: 0.80\n",
      "step : 1018 | loss: 4.327293395996094 | dt: 167.71 ms | tokens/sec: 36.63 | norm: 0.77\n",
      "step : 1019 | loss: 4.139368057250977 | dt: 167.64 ms | tokens/sec: 36.65 | norm: 0.91\n",
      "step : 1020 | loss: 4.474734783172607 | dt: 167.65 ms | tokens/sec: 36.65 | norm: 0.86\n",
      "step : 1021 | loss: 4.367249488830566 | dt: 167.85 ms | tokens/sec: 36.60 | norm: 0.84\n",
      "step : 1022 | loss: 4.1129984855651855 | dt: 167.70 ms | tokens/sec: 36.64 | norm: 0.86\n",
      "step : 1023 | loss: 4.233496189117432 | dt: 167.12 ms | tokens/sec: 36.76 | norm: 0.81\n",
      "step : 1024 | loss: 4.2428741455078125 | dt: 170.10 ms | tokens/sec: 36.12 | norm: 0.83\n",
      "step : 1025 | loss: 4.257931232452393 | dt: 166.91 ms | tokens/sec: 36.81 | norm: 0.87\n",
      "step : 1026 | loss: 4.536745548248291 | dt: 168.14 ms | tokens/sec: 36.54 | norm: 1.06\n",
      "step : 1027 | loss: 4.466586589813232 | dt: 168.39 ms | tokens/sec: 36.49 | norm: 1.00\n",
      "step : 1028 | loss: 4.768403053283691 | dt: 168.39 ms | tokens/sec: 36.49 | norm: 1.16\n",
      "step : 1029 | loss: 4.5370588302612305 | dt: 168.24 ms | tokens/sec: 36.52 | norm: 0.97\n",
      "step : 1030 | loss: 4.369132995605469 | dt: 168.03 ms | tokens/sec: 36.56 | norm: 0.83\n",
      "step : 1031 | loss: 4.480751037597656 | dt: 167.01 ms | tokens/sec: 36.79 | norm: 0.77\n",
      "step : 1032 | loss: 4.264216423034668 | dt: 167.76 ms | tokens/sec: 36.62 | norm: 0.80\n",
      "step : 1033 | loss: 4.121273040771484 | dt: 167.45 ms | tokens/sec: 36.69 | norm: 1.18\n",
      "step : 1034 | loss: 4.210434913635254 | dt: 167.73 ms | tokens/sec: 36.63 | norm: 1.02\n",
      "step : 1035 | loss: 4.20411491394043 | dt: 168.08 ms | tokens/sec: 36.55 | norm: 0.88\n",
      "step : 1036 | loss: 4.035998344421387 | dt: 171.76 ms | tokens/sec: 35.77 | norm: 0.78\n",
      "step : 1037 | loss: 3.9393138885498047 | dt: 168.04 ms | tokens/sec: 36.56 | norm: 0.97\n",
      "step : 1038 | loss: 4.342517375946045 | dt: 167.93 ms | tokens/sec: 36.59 | norm: 0.88\n",
      "step : 1039 | loss: 4.170907020568848 | dt: 168.52 ms | tokens/sec: 36.46 | norm: 1.21\n",
      "step : 1040 | loss: 4.040533065795898 | dt: 167.68 ms | tokens/sec: 36.64 | norm: 1.08\n",
      "step : 1041 | loss: 4.090599536895752 | dt: 167.08 ms | tokens/sec: 36.77 | norm: 0.94\n",
      "step : 1042 | loss: 3.949361801147461 | dt: 168.18 ms | tokens/sec: 36.53 | norm: 1.23\n",
      "step : 1043 | loss: 3.668220043182373 | dt: 167.30 ms | tokens/sec: 36.72 | norm: 0.92\n",
      "step : 1044 | loss: 4.367978096008301 | dt: 167.90 ms | tokens/sec: 36.59 | norm: 1.02\n",
      "step : 1045 | loss: 4.237039089202881 | dt: 167.65 ms | tokens/sec: 36.65 | norm: 0.99\n",
      "step : 1046 | loss: 4.3404388427734375 | dt: 170.42 ms | tokens/sec: 36.05 | norm: 0.94\n",
      "step : 1047 | loss: 4.339189529418945 | dt: 166.76 ms | tokens/sec: 36.84 | norm: 0.93\n",
      "step : 1048 | loss: 4.2882843017578125 | dt: 169.55 ms | tokens/sec: 36.24 | norm: 0.94\n",
      "step : 1049 | loss: 3.9626102447509766 | dt: 168.08 ms | tokens/sec: 36.55 | norm: 0.84\n",
      "step : 1050 | loss: 4.010646820068359 | dt: 168.74 ms | tokens/sec: 36.41 | norm: 0.79\n",
      "step : 1051 | loss: 4.011007785797119 | dt: 167.83 ms | tokens/sec: 36.61 | norm: 0.84\n",
      "step : 1052 | loss: 4.21721076965332 | dt: 167.68 ms | tokens/sec: 36.64 | norm: 0.81\n",
      "step : 1053 | loss: 4.2371673583984375 | dt: 166.73 ms | tokens/sec: 36.85 | norm: 1.11\n",
      "step : 1054 | loss: 4.131248474121094 | dt: 168.16 ms | tokens/sec: 36.54 | norm: 1.29\n",
      "step : 1055 | loss: 4.089107513427734 | dt: 168.51 ms | tokens/sec: 36.46 | norm: 1.01\n",
      "step : 1056 | loss: 4.073141098022461 | dt: 166.84 ms | tokens/sec: 36.83 | norm: 0.94\n",
      "step : 1057 | loss: 3.919398069381714 | dt: 168.00 ms | tokens/sec: 36.57 | norm: 0.90\n",
      "step : 1058 | loss: 4.1504926681518555 | dt: 168.38 ms | tokens/sec: 36.49 | norm: 0.75\n",
      "step : 1059 | loss: 3.9872655868530273 | dt: 168.59 ms | tokens/sec: 36.44 | norm: 0.80\n",
      "step : 1060 | loss: 3.9435977935791016 | dt: 168.05 ms | tokens/sec: 36.56 | norm: 0.89\n",
      "step : 1061 | loss: 4.262901306152344 | dt: 168.39 ms | tokens/sec: 36.49 | norm: 0.85\n",
      "step : 1062 | loss: 4.320413589477539 | dt: 168.33 ms | tokens/sec: 36.50 | norm: 0.84\n",
      "step : 1063 | loss: 4.261363506317139 | dt: 167.89 ms | tokens/sec: 36.59 | norm: 0.78\n",
      "step : 1064 | loss: 4.266582012176514 | dt: 167.69 ms | tokens/sec: 36.64 | norm: 0.78\n",
      "step : 1065 | loss: 4.242339134216309 | dt: 167.44 ms | tokens/sec: 36.69 | norm: 0.76\n",
      "step : 1066 | loss: 3.9154632091522217 | dt: 167.28 ms | tokens/sec: 36.73 | norm: 0.75\n",
      "step : 1067 | loss: 4.192625045776367 | dt: 168.42 ms | tokens/sec: 36.48 | norm: 0.84\n",
      "step : 1068 | loss: 4.373290061950684 | dt: 168.07 ms | tokens/sec: 36.56 | norm: 0.77\n",
      "step : 1069 | loss: 4.281552314758301 | dt: 169.33 ms | tokens/sec: 36.28 | norm: 0.82\n",
      "step : 1070 | loss: 4.191536903381348 | dt: 168.56 ms | tokens/sec: 36.45 | norm: 0.85\n",
      "step : 1071 | loss: 4.304526329040527 | dt: 166.33 ms | tokens/sec: 36.94 | norm: 1.02\n",
      "step : 1072 | loss: 4.059048175811768 | dt: 167.12 ms | tokens/sec: 36.76 | norm: 0.85\n",
      "step : 1073 | loss: 4.306917190551758 | dt: 167.24 ms | tokens/sec: 36.74 | norm: 0.80\n",
      "step : 1074 | loss: 4.091860771179199 | dt: 166.13 ms | tokens/sec: 36.98 | norm: 0.96\n",
      "step : 1075 | loss: 4.4028215408325195 | dt: 167.37 ms | tokens/sec: 36.71 | norm: 0.90\n",
      "step : 1076 | loss: 4.309904098510742 | dt: 165.72 ms | tokens/sec: 37.07 | norm: 0.93\n",
      "step : 1077 | loss: 4.039018630981445 | dt: 166.51 ms | tokens/sec: 36.90 | norm: 0.90\n",
      "step : 1078 | loss: 4.163670539855957 | dt: 166.66 ms | tokens/sec: 36.87 | norm: 0.89\n",
      "step : 1079 | loss: 4.157573223114014 | dt: 165.75 ms | tokens/sec: 37.07 | norm: 0.72\n",
      "step : 1080 | loss: 4.181463718414307 | dt: 167.53 ms | tokens/sec: 36.67 | norm: 0.77\n",
      "step : 1081 | loss: 4.451409339904785 | dt: 166.81 ms | tokens/sec: 36.83 | norm: 1.05\n",
      "step : 1082 | loss: 4.379022121429443 | dt: 165.82 ms | tokens/sec: 37.05 | norm: 1.01\n",
      "step : 1083 | loss: 4.686019420623779 | dt: 165.46 ms | tokens/sec: 37.13 | norm: 1.16\n",
      "step : 1084 | loss: 4.456038475036621 | dt: 167.60 ms | tokens/sec: 36.66 | norm: 1.06\n",
      "step : 1085 | loss: 4.2907538414001465 | dt: 165.70 ms | tokens/sec: 37.08 | norm: 0.87\n",
      "step : 1086 | loss: 4.424853801727295 | dt: 167.23 ms | tokens/sec: 36.74 | norm: 0.86\n",
      "step : 1087 | loss: 4.210050106048584 | dt: 166.99 ms | tokens/sec: 36.79 | norm: 0.79\n",
      "step : 1088 | loss: 4.041013717651367 | dt: 165.27 ms | tokens/sec: 37.17 | norm: 1.13\n",
      "step : 1089 | loss: 4.149191856384277 | dt: 166.29 ms | tokens/sec: 36.95 | norm: 0.94\n",
      "step : 1090 | loss: 4.168638229370117 | dt: 166.61 ms | tokens/sec: 36.88 | norm: 0.90\n",
      "step : 1091 | loss: 4.0345282554626465 | dt: 165.87 ms | tokens/sec: 37.04 | norm: 0.91\n",
      "step : 1092 | loss: 3.912914991378784 | dt: 165.87 ms | tokens/sec: 37.04 | norm: 0.90\n",
      "step : 1093 | loss: 4.302733421325684 | dt: 166.87 ms | tokens/sec: 36.82 | norm: 0.87\n",
      "step : 1094 | loss: 4.123908996582031 | dt: 165.01 ms | tokens/sec: 37.23 | norm: 0.97\n",
      "step : 1095 | loss: 3.979032278060913 | dt: 165.45 ms | tokens/sec: 37.13 | norm: 0.96\n",
      "step : 1096 | loss: 4.068790435791016 | dt: 166.23 ms | tokens/sec: 36.96 | norm: 0.96\n",
      "step : 1097 | loss: 3.9051902294158936 | dt: 164.86 ms | tokens/sec: 37.27 | norm: 0.93\n",
      "step : 1098 | loss: 3.6180312633514404 | dt: 166.83 ms | tokens/sec: 36.83 | norm: 0.89\n",
      "step : 1099 | loss: 4.298083782196045 | dt: 166.28 ms | tokens/sec: 36.95 | norm: 0.90\n",
      "step : 1100 | loss: 4.162106990814209 | dt: 165.11 ms | tokens/sec: 37.21 | norm: 1.03\n",
      "step : 1101 | loss: 4.2487359046936035 | dt: 166.42 ms | tokens/sec: 36.92 | norm: 1.03\n",
      "step : 1102 | loss: 4.251920700073242 | dt: 166.04 ms | tokens/sec: 37.00 | norm: 1.56\n",
      "step : 1103 | loss: 4.222373962402344 | dt: 165.70 ms | tokens/sec: 37.08 | norm: 1.11\n",
      "step : 1104 | loss: 3.905025005340576 | dt: 165.66 ms | tokens/sec: 37.09 | norm: 0.97\n",
      "step : 1105 | loss: 3.983135223388672 | dt: 167.44 ms | tokens/sec: 36.69 | norm: 0.84\n",
      "step : 1106 | loss: 3.997572660446167 | dt: 165.92 ms | tokens/sec: 37.03 | norm: 0.94\n",
      "step : 1107 | loss: 4.17331075668335 | dt: 166.58 ms | tokens/sec: 36.88 | norm: 0.77\n",
      "step : 1108 | loss: 4.183974742889404 | dt: 167.41 ms | tokens/sec: 36.70 | norm: 0.85\n",
      "step : 1109 | loss: 4.037367820739746 | dt: 166.07 ms | tokens/sec: 37.00 | norm: 0.91\n",
      "step : 1110 | loss: 4.053177356719971 | dt: 166.04 ms | tokens/sec: 37.00 | norm: 1.09\n",
      "step : 1111 | loss: 4.037600040435791 | dt: 169.55 ms | tokens/sec: 36.24 | norm: 0.98\n",
      "step : 1112 | loss: 3.8404879570007324 | dt: 165.24 ms | tokens/sec: 37.18 | norm: 0.87\n",
      "step : 1113 | loss: 4.100666046142578 | dt: 166.91 ms | tokens/sec: 36.81 | norm: 0.80\n",
      "step : 1114 | loss: 3.919938564300537 | dt: 166.72 ms | tokens/sec: 36.85 | norm: 0.98\n",
      "step : 1115 | loss: 3.8515119552612305 | dt: 166.09 ms | tokens/sec: 36.99 | norm: 0.86\n",
      "step : 1116 | loss: 4.165853023529053 | dt: 166.48 ms | tokens/sec: 36.90 | norm: 0.74\n",
      "step : 1117 | loss: 4.227398872375488 | dt: 168.56 ms | tokens/sec: 36.45 | norm: 0.82\n",
      "step : 1118 | loss: 4.185084342956543 | dt: 165.94 ms | tokens/sec: 37.03 | norm: 0.80\n",
      "step : 1119 | loss: 4.2021307945251465 | dt: 167.29 ms | tokens/sec: 36.73 | norm: 0.79\n",
      "step : 1120 | loss: 4.2083940505981445 | dt: 166.67 ms | tokens/sec: 36.86 | norm: 0.73\n",
      "step : 1121 | loss: 3.8853843212127686 | dt: 164.66 ms | tokens/sec: 37.31 | norm: 0.73\n",
      "step : 1122 | loss: 4.138188362121582 | dt: 165.28 ms | tokens/sec: 37.17 | norm: 0.87\n",
      "step : 1123 | loss: 4.314053058624268 | dt: 167.64 ms | tokens/sec: 36.65 | norm: 0.89\n",
      "step : 1124 | loss: 4.22012186050415 | dt: 166.60 ms | tokens/sec: 36.88 | norm: 0.83\n",
      "step : 1125 | loss: 4.121034622192383 | dt: 168.04 ms | tokens/sec: 36.56 | norm: 0.85\n",
      "step : 1126 | loss: 4.236368179321289 | dt: 165.67 ms | tokens/sec: 37.09 | norm: 0.95\n",
      "step : 1127 | loss: 3.995382308959961 | dt: 165.96 ms | tokens/sec: 37.02 | norm: 0.88\n",
      "step : 1128 | loss: 4.215941429138184 | dt: 167.33 ms | tokens/sec: 36.72 | norm: 0.81\n",
      "step : 1129 | loss: 3.9934864044189453 | dt: 167.57 ms | tokens/sec: 36.67 | norm: 0.91\n",
      "step : 1130 | loss: 4.326313018798828 | dt: 171.06 ms | tokens/sec: 35.92 | norm: 0.90\n",
      "step : 1131 | loss: 4.2279510498046875 | dt: 169.06 ms | tokens/sec: 36.34 | norm: 0.87\n",
      "step : 1132 | loss: 4.015501976013184 | dt: 168.04 ms | tokens/sec: 36.56 | norm: 0.96\n",
      "step : 1133 | loss: 4.132448196411133 | dt: 168.09 ms | tokens/sec: 36.55 | norm: 1.02\n",
      "step : 1134 | loss: 4.112807273864746 | dt: 168.24 ms | tokens/sec: 36.52 | norm: 0.78\n",
      "step : 1135 | loss: 4.116599082946777 | dt: 168.08 ms | tokens/sec: 36.55 | norm: 0.77\n",
      "step : 1136 | loss: 4.379406452178955 | dt: 168.66 ms | tokens/sec: 36.43 | norm: 1.03\n",
      "step : 1137 | loss: 4.294486045837402 | dt: 167.63 ms | tokens/sec: 36.65 | norm: 1.03\n",
      "step : 1138 | loss: 4.607048034667969 | dt: 167.40 ms | tokens/sec: 36.70 | norm: 1.21\n",
      "step : 1139 | loss: 4.40938663482666 | dt: 166.88 ms | tokens/sec: 36.82 | norm: 1.14\n",
      "step : 1140 | loss: 4.235724925994873 | dt: 167.12 ms | tokens/sec: 36.76 | norm: 0.93\n",
      "step : 1141 | loss: 4.370713233947754 | dt: 168.90 ms | tokens/sec: 36.38 | norm: 0.92\n",
      "step : 1142 | loss: 4.172394275665283 | dt: 169.87 ms | tokens/sec: 36.17 | norm: 0.92\n",
      "step : 1143 | loss: 3.9783034324645996 | dt: 168.00 ms | tokens/sec: 36.57 | norm: 1.08\n",
      "step : 1144 | loss: 4.102104187011719 | dt: 167.91 ms | tokens/sec: 36.59 | norm: 0.81\n",
      "step : 1145 | loss: 4.116109848022461 | dt: 167.79 ms | tokens/sec: 36.62 | norm: 1.01\n",
      "step : 1146 | loss: 3.9636359214782715 | dt: 167.90 ms | tokens/sec: 36.59 | norm: 0.93\n",
      "step : 1147 | loss: 3.868028163909912 | dt: 168.77 ms | tokens/sec: 36.41 | norm: 0.90\n",
      "step : 1148 | loss: 4.299651622772217 | dt: 168.48 ms | tokens/sec: 36.47 | norm: 1.12\n",
      "step : 1149 | loss: 4.135271072387695 | dt: 167.46 ms | tokens/sec: 36.69 | norm: 1.18\n",
      "step : 1150 | loss: 4.000123977661133 | dt: 167.40 ms | tokens/sec: 36.70 | norm: 1.03\n",
      "step : 1151 | loss: 4.058810710906982 | dt: 167.11 ms | tokens/sec: 36.77 | norm: 1.06\n",
      "step : 1152 | loss: 3.8731088638305664 | dt: 167.83 ms | tokens/sec: 36.61 | norm: 0.97\n",
      "step : 1153 | loss: 3.6180577278137207 | dt: 168.11 ms | tokens/sec: 36.55 | norm: 1.09\n",
      "step : 1154 | loss: 4.285574913024902 | dt: 168.67 ms | tokens/sec: 36.43 | norm: 0.97\n",
      "step : 1155 | loss: 4.122737407684326 | dt: 168.73 ms | tokens/sec: 36.41 | norm: 1.06\n",
      "step : 1156 | loss: 4.270480632781982 | dt: 168.02 ms | tokens/sec: 36.57 | norm: 1.34\n",
      "step : 1157 | loss: 4.305706024169922 | dt: 168.33 ms | tokens/sec: 36.50 | norm: 1.09\n",
      "step : 1158 | loss: 4.188230514526367 | dt: 168.38 ms | tokens/sec: 36.49 | norm: 1.14\n",
      "step : 1159 | loss: 3.844982147216797 | dt: 168.41 ms | tokens/sec: 36.48 | norm: 0.96\n",
      "step : 1160 | loss: 3.9114131927490234 | dt: 167.96 ms | tokens/sec: 36.58 | norm: 0.84\n",
      "step : 1161 | loss: 3.9050960540771484 | dt: 169.00 ms | tokens/sec: 36.35 | norm: 0.85\n",
      "step : 1162 | loss: 4.124965190887451 | dt: 168.07 ms | tokens/sec: 36.56 | norm: 0.77\n",
      "step : 1163 | loss: 4.2050604820251465 | dt: 168.26 ms | tokens/sec: 36.52 | norm: 0.86\n",
      "step : 1164 | loss: 4.128767013549805 | dt: 168.52 ms | tokens/sec: 36.46 | norm: 1.12\n",
      "step : 1165 | loss: 4.097853660583496 | dt: 168.74 ms | tokens/sec: 36.41 | norm: 1.12\n",
      "step : 1166 | loss: 4.057535171508789 | dt: 168.08 ms | tokens/sec: 36.55 | norm: 1.09\n",
      "step : 1167 | loss: 3.856356143951416 | dt: 168.89 ms | tokens/sec: 36.38 | norm: 0.96\n",
      "step : 1168 | loss: 4.100497245788574 | dt: 168.25 ms | tokens/sec: 36.52 | norm: 1.25\n",
      "step : 1169 | loss: 3.956439971923828 | dt: 167.82 ms | tokens/sec: 36.61 | norm: 1.00\n",
      "step : 1170 | loss: 3.90598201751709 | dt: 167.05 ms | tokens/sec: 36.78 | norm: 1.03\n",
      "step : 1171 | loss: 4.154469966888428 | dt: 167.36 ms | tokens/sec: 36.71 | norm: 0.94\n",
      "step : 1172 | loss: 4.189366817474365 | dt: 167.31 ms | tokens/sec: 36.72 | norm: 0.85\n",
      "step : 1173 | loss: 4.17018985748291 | dt: 174.62 ms | tokens/sec: 35.18 | norm: 0.85\n",
      "step : 1174 | loss: 4.178248882293701 | dt: 171.68 ms | tokens/sec: 35.79 | norm: 0.76\n",
      "step : 1175 | loss: 4.192856788635254 | dt: 170.97 ms | tokens/sec: 35.94 | norm: 0.77\n",
      "step : 1176 | loss: 3.8955962657928467 | dt: 171.69 ms | tokens/sec: 35.78 | norm: 0.75\n",
      "step : 1177 | loss: 4.186564922332764 | dt: 171.27 ms | tokens/sec: 35.87 | norm: 0.86\n",
      "step : 1178 | loss: 4.379743576049805 | dt: 170.19 ms | tokens/sec: 36.10 | norm: 0.97\n",
      "step : 1179 | loss: 4.255376815795898 | dt: 171.67 ms | tokens/sec: 35.79 | norm: 0.94\n",
      "step : 1180 | loss: 4.137148857116699 | dt: 171.01 ms | tokens/sec: 35.93 | norm: 0.97\n",
      "step : 1181 | loss: 4.214984893798828 | dt: 171.14 ms | tokens/sec: 35.90 | norm: 0.88\n",
      "step : 1182 | loss: 3.9715919494628906 | dt: 169.50 ms | tokens/sec: 36.25 | norm: 0.90\n",
      "step : 1183 | loss: 4.183076858520508 | dt: 170.43 ms | tokens/sec: 36.05 | norm: 0.82\n",
      "step : 1184 | loss: 3.9360079765319824 | dt: 171.35 ms | tokens/sec: 35.86 | norm: 0.88\n",
      "step : 1185 | loss: 4.255993366241455 | dt: 171.30 ms | tokens/sec: 35.87 | norm: 0.77\n",
      "step : 1186 | loss: 4.168573379516602 | dt: 169.95 ms | tokens/sec: 36.15 | norm: 0.79\n",
      "step : 1187 | loss: 3.949929714202881 | dt: 170.50 ms | tokens/sec: 36.03 | norm: 0.89\n",
      "step : 1188 | loss: 4.113126277923584 | dt: 171.26 ms | tokens/sec: 35.88 | norm: 1.03\n",
      "step : 1189 | loss: 4.061306953430176 | dt: 170.96 ms | tokens/sec: 35.94 | norm: 0.89\n",
      "step : 1190 | loss: 4.105132102966309 | dt: 170.38 ms | tokens/sec: 36.06 | norm: 0.82\n",
      "step : 1191 | loss: 4.344378471374512 | dt: 170.36 ms | tokens/sec: 36.07 | norm: 0.89\n",
      "step : 1192 | loss: 4.27234411239624 | dt: 172.30 ms | tokens/sec: 35.66 | norm: 0.86\n",
      "step : 1193 | loss: 4.586503982543945 | dt: 170.68 ms | tokens/sec: 36.00 | norm: 1.13\n",
      "step : 1194 | loss: 4.422426700592041 | dt: 169.85 ms | tokens/sec: 36.17 | norm: 1.13\n",
      "step : 1195 | loss: 4.217950820922852 | dt: 170.54 ms | tokens/sec: 36.03 | norm: 0.97\n",
      "step : 1196 | loss: 4.341252326965332 | dt: 171.01 ms | tokens/sec: 35.93 | norm: 1.03\n",
      "step : 1197 | loss: 4.129626750946045 | dt: 171.28 ms | tokens/sec: 35.87 | norm: 0.97\n",
      "step : 1198 | loss: 3.929513931274414 | dt: 171.13 ms | tokens/sec: 35.90 | norm: 1.09\n",
      "step : 1199 | loss: 4.054773807525635 | dt: 170.75 ms | tokens/sec: 35.98 | norm: 0.85\n",
      "step : 1200 | loss: 4.075411796569824 | dt: 170.25 ms | tokens/sec: 36.09 | norm: 0.88\n",
      "step : 1201 | loss: 3.914003849029541 | dt: 170.90 ms | tokens/sec: 35.95 | norm: 0.88\n",
      "step : 1202 | loss: 3.8148486614227295 | dt: 169.93 ms | tokens/sec: 36.16 | norm: 0.89\n",
      "step : 1203 | loss: 4.264126777648926 | dt: 170.11 ms | tokens/sec: 36.12 | norm: 0.92\n",
      "step : 1204 | loss: 4.101511001586914 | dt: 171.43 ms | tokens/sec: 35.84 | norm: 0.97\n",
      "step : 1205 | loss: 3.92964243888855 | dt: 171.13 ms | tokens/sec: 35.90 | norm: 0.89\n",
      "step : 1206 | loss: 3.970132350921631 | dt: 170.14 ms | tokens/sec: 36.11 | norm: 0.84\n",
      "step : 1207 | loss: 3.7969987392425537 | dt: 170.27 ms | tokens/sec: 36.08 | norm: 0.77\n",
      "step : 1208 | loss: 3.584409475326538 | dt: 170.52 ms | tokens/sec: 36.03 | norm: 0.93\n",
      "step : 1209 | loss: 4.235955715179443 | dt: 170.65 ms | tokens/sec: 36.00 | norm: 0.93\n",
      "step : 1210 | loss: 4.094966888427734 | dt: 171.35 ms | tokens/sec: 35.86 | norm: 1.07\n",
      "step : 1211 | loss: 4.211616516113281 | dt: 170.84 ms | tokens/sec: 35.96 | norm: 1.00\n",
      "step : 1212 | loss: 4.2399373054504395 | dt: 170.37 ms | tokens/sec: 36.06 | norm: 0.91\n",
      "step : 1213 | loss: 4.161197662353516 | dt: 170.45 ms | tokens/sec: 36.05 | norm: 1.08\n",
      "step : 1214 | loss: 3.8440256118774414 | dt: 171.39 ms | tokens/sec: 35.85 | norm: 0.93\n",
      "step : 1215 | loss: 3.906984806060791 | dt: 170.01 ms | tokens/sec: 36.14 | norm: 0.77\n",
      "step : 1216 | loss: 3.878596305847168 | dt: 172.37 ms | tokens/sec: 35.64 | norm: 0.90\n",
      "step : 1217 | loss: 4.072925090789795 | dt: 170.63 ms | tokens/sec: 36.01 | norm: 0.76\n",
      "step : 1218 | loss: 4.1148481369018555 | dt: 170.41 ms | tokens/sec: 36.05 | norm: 1.37\n",
      "step : 1219 | loss: 4.0258684158325195 | dt: 170.23 ms | tokens/sec: 36.09 | norm: 1.12\n",
      "step : 1220 | loss: 4.002856254577637 | dt: 170.65 ms | tokens/sec: 36.00 | norm: 1.00\n",
      "step : 1221 | loss: 4.00267219543457 | dt: 169.86 ms | tokens/sec: 36.17 | norm: 0.94\n",
      "step : 1222 | loss: 3.8129451274871826 | dt: 171.38 ms | tokens/sec: 35.85 | norm: 1.01\n",
      "step : 1223 | loss: 4.07749080657959 | dt: 169.81 ms | tokens/sec: 36.18 | norm: 0.91\n",
      "step : 1224 | loss: 3.8399808406829834 | dt: 170.44 ms | tokens/sec: 36.05 | norm: 0.88\n",
      "step : 1225 | loss: 3.8259105682373047 | dt: 170.69 ms | tokens/sec: 36.00 | norm: 0.91\n",
      "step : 1226 | loss: 4.095750331878662 | dt: 169.90 ms | tokens/sec: 36.16 | norm: 1.02\n",
      "step : 1227 | loss: 4.130171298980713 | dt: 169.82 ms | tokens/sec: 36.18 | norm: 0.97\n",
      "step : 1228 | loss: 4.114163398742676 | dt: 171.73 ms | tokens/sec: 35.78 | norm: 0.99\n",
      "step : 1229 | loss: 4.108632564544678 | dt: 170.39 ms | tokens/sec: 36.06 | norm: 0.87\n",
      "step : 1230 | loss: 4.111709117889404 | dt: 170.60 ms | tokens/sec: 36.01 | norm: 0.78\n",
      "step : 1231 | loss: 3.8016772270202637 | dt: 170.62 ms | tokens/sec: 36.01 | norm: 0.82\n",
      "step : 1232 | loss: 4.070412635803223 | dt: 170.33 ms | tokens/sec: 36.07 | norm: 0.91\n",
      "step : 1233 | loss: 4.262221336364746 | dt: 170.23 ms | tokens/sec: 36.09 | norm: 0.91\n",
      "step : 1234 | loss: 4.157092094421387 | dt: 171.24 ms | tokens/sec: 35.88 | norm: 0.95\n",
      "step : 1235 | loss: 4.069999694824219 | dt: 170.78 ms | tokens/sec: 35.98 | norm: 1.00\n",
      "step : 1236 | loss: 4.169580459594727 | dt: 170.13 ms | tokens/sec: 36.11 | norm: 0.95\n",
      "step : 1237 | loss: 3.917595863342285 | dt: 170.88 ms | tokens/sec: 35.96 | norm: 0.96\n",
      "step : 1238 | loss: 4.108908653259277 | dt: 170.69 ms | tokens/sec: 35.99 | norm: 0.83\n",
      "step : 1239 | loss: 3.8815486431121826 | dt: 171.07 ms | tokens/sec: 35.92 | norm: 1.02\n",
      "step : 1240 | loss: 4.200447082519531 | dt: 170.24 ms | tokens/sec: 36.09 | norm: 1.33\n",
      "step : 1241 | loss: 4.11489200592041 | dt: 171.79 ms | tokens/sec: 35.76 | norm: 0.91\n",
      "step : 1242 | loss: 3.903052806854248 | dt: 170.42 ms | tokens/sec: 36.05 | norm: 1.04\n",
      "step : 1243 | loss: 4.061100006103516 | dt: 170.67 ms | tokens/sec: 36.00 | norm: 1.03\n",
      "step : 1244 | loss: 4.020043849945068 | dt: 170.03 ms | tokens/sec: 36.13 | norm: 0.87\n",
      "step : 1245 | loss: 4.019615650177002 | dt: 171.23 ms | tokens/sec: 35.88 | norm: 0.87\n",
      "step : 1246 | loss: 4.244234085083008 | dt: 170.08 ms | tokens/sec: 36.12 | norm: 1.04\n",
      "step : 1247 | loss: 4.196916103363037 | dt: 171.51 ms | tokens/sec: 35.82 | norm: 0.98\n",
      "step : 1248 | loss: 4.4993815422058105 | dt: 170.61 ms | tokens/sec: 36.01 | norm: 1.05\n",
      "step : 1249 | loss: 4.308437347412109 | dt: 170.73 ms | tokens/sec: 35.99 | norm: 1.21\n",
      "step : 1250 | loss: 4.144616603851318 | dt: 170.49 ms | tokens/sec: 36.04 | norm: 0.89\n",
      "step : 1251 | loss: 4.27433967590332 | dt: 170.48 ms | tokens/sec: 36.04 | norm: 0.98\n",
      "step : 1252 | loss: 4.062281608581543 | dt: 170.06 ms | tokens/sec: 36.13 | norm: 1.06\n",
      "step : 1253 | loss: 3.8891825675964355 | dt: 170.76 ms | tokens/sec: 35.98 | norm: 1.13\n",
      "step : 1254 | loss: 4.008533477783203 | dt: 169.38 ms | tokens/sec: 36.27 | norm: 0.93\n",
      "step : 1255 | loss: 4.007352828979492 | dt: 170.89 ms | tokens/sec: 35.95 | norm: 1.00\n",
      "step : 1256 | loss: 3.8608908653259277 | dt: 169.79 ms | tokens/sec: 36.19 | norm: 0.97\n",
      "step : 1257 | loss: 3.742436170578003 | dt: 169.98 ms | tokens/sec: 36.15 | norm: 0.87\n",
      "step : 1258 | loss: 4.144083023071289 | dt: 171.52 ms | tokens/sec: 35.82 | norm: 0.90\n",
      "step : 1259 | loss: 3.984135627746582 | dt: 170.96 ms | tokens/sec: 35.94 | norm: 1.29\n",
      "step : 1260 | loss: 3.8507297039031982 | dt: 169.73 ms | tokens/sec: 36.20 | norm: 1.02\n",
      "step : 1261 | loss: 3.905728816986084 | dt: 169.55 ms | tokens/sec: 36.24 | norm: 0.99\n",
      "step : 1262 | loss: 3.758263349533081 | dt: 170.16 ms | tokens/sec: 36.11 | norm: 0.97\n",
      "step : 1263 | loss: 3.518723964691162 | dt: 169.74 ms | tokens/sec: 36.20 | norm: 0.85\n",
      "step : 1264 | loss: 4.181833267211914 | dt: 170.41 ms | tokens/sec: 36.05 | norm: 0.93\n",
      "step : 1265 | loss: 4.032989978790283 | dt: 171.57 ms | tokens/sec: 35.81 | norm: 1.15\n",
      "step : 1266 | loss: 4.099791526794434 | dt: 170.64 ms | tokens/sec: 36.01 | norm: 1.13\n",
      "step : 1267 | loss: 4.110801696777344 | dt: 169.49 ms | tokens/sec: 36.25 | norm: 1.03\n",
      "step : 1268 | loss: 4.060209274291992 | dt: 170.02 ms | tokens/sec: 36.14 | norm: 0.93\n",
      "step : 1269 | loss: 3.7303454875946045 | dt: 171.01 ms | tokens/sec: 35.93 | norm: 1.00\n",
      "step : 1270 | loss: 3.819241523742676 | dt: 170.83 ms | tokens/sec: 35.97 | norm: 0.86\n",
      "step : 1271 | loss: 3.804762840270996 | dt: 170.99 ms | tokens/sec: 35.93 | norm: 0.95\n",
      "step : 1272 | loss: 4.007393836975098 | dt: 170.16 ms | tokens/sec: 36.11 | norm: 0.90\n",
      "step : 1273 | loss: 4.087706565856934 | dt: 171.21 ms | tokens/sec: 35.89 | norm: 0.88\n",
      "step : 1274 | loss: 4.000390529632568 | dt: 169.73 ms | tokens/sec: 36.20 | norm: 1.19\n",
      "step : 1275 | loss: 3.9397170543670654 | dt: 170.31 ms | tokens/sec: 36.08 | norm: 0.96\n",
      "step : 1276 | loss: 3.936501979827881 | dt: 169.47 ms | tokens/sec: 36.25 | norm: 0.89\n",
      "step : 1277 | loss: 3.759760618209839 | dt: 171.06 ms | tokens/sec: 35.92 | norm: 0.97\n",
      "step : 1278 | loss: 4.005725383758545 | dt: 169.86 ms | tokens/sec: 36.17 | norm: 0.93\n",
      "step : 1279 | loss: 3.8411147594451904 | dt: 168.69 ms | tokens/sec: 36.42 | norm: 1.11\n",
      "step : 1280 | loss: 3.785278081893921 | dt: 170.09 ms | tokens/sec: 36.12 | norm: 1.10\n",
      "step : 1281 | loss: 4.045578479766846 | dt: 170.29 ms | tokens/sec: 36.08 | norm: 0.95\n",
      "step : 1282 | loss: 4.089460372924805 | dt: 169.48 ms | tokens/sec: 36.25 | norm: 0.98\n",
      "step : 1283 | loss: 4.0815534591674805 | dt: 171.69 ms | tokens/sec: 35.78 | norm: 1.07\n",
      "step : 1284 | loss: 4.075048446655273 | dt: 169.15 ms | tokens/sec: 36.32 | norm: 0.96\n",
      "step : 1285 | loss: 4.079406261444092 | dt: 170.01 ms | tokens/sec: 36.14 | norm: 1.01\n",
      "step : 1286 | loss: 3.7816758155822754 | dt: 169.83 ms | tokens/sec: 36.18 | norm: 0.91\n",
      "step : 1287 | loss: 4.024773120880127 | dt: 169.92 ms | tokens/sec: 36.16 | norm: 1.62\n",
      "step : 1288 | loss: 4.209702968597412 | dt: 170.30 ms | tokens/sec: 36.08 | norm: 1.16\n",
      "step : 1289 | loss: 4.091504096984863 | dt: 171.15 ms | tokens/sec: 35.90 | norm: 0.99\n",
      "step : 1290 | loss: 3.969867706298828 | dt: 170.46 ms | tokens/sec: 36.04 | norm: 1.00\n",
      "step : 1291 | loss: 4.124453544616699 | dt: 168.91 ms | tokens/sec: 36.37 | norm: 1.07\n",
      "step : 1292 | loss: 3.8765430450439453 | dt: 168.61 ms | tokens/sec: 36.44 | norm: 0.97\n",
      "step : 1293 | loss: 4.072818756103516 | dt: 169.87 ms | tokens/sec: 36.17 | norm: 0.88\n",
      "step : 1294 | loss: 3.8289008140563965 | dt: 168.48 ms | tokens/sec: 36.47 | norm: 0.87\n",
      "step : 1295 | loss: 4.193641185760498 | dt: 168.89 ms | tokens/sec: 36.38 | norm: 0.87\n",
      "step : 1296 | loss: 4.047283172607422 | dt: 171.15 ms | tokens/sec: 35.90 | norm: 0.79\n",
      "step : 1297 | loss: 3.830925703048706 | dt: 169.15 ms | tokens/sec: 36.32 | norm: 0.95\n",
      "step : 1298 | loss: 3.9907798767089844 | dt: 169.59 ms | tokens/sec: 36.23 | norm: 0.92\n",
      "step : 1299 | loss: 3.9679954051971436 | dt: 169.73 ms | tokens/sec: 36.20 | norm: 0.93\n",
      "step : 1300 | loss: 4.003808498382568 | dt: 169.83 ms | tokens/sec: 36.18 | norm: 0.99\n",
      "step : 1301 | loss: 4.242209434509277 | dt: 169.43 ms | tokens/sec: 36.26 | norm: 1.17\n",
      "step : 1302 | loss: 4.1543097496032715 | dt: 169.27 ms | tokens/sec: 36.30 | norm: 1.14\n",
      "step : 1303 | loss: 4.413197040557861 | dt: 169.52 ms | tokens/sec: 36.24 | norm: 1.22\n",
      "step : 1304 | loss: 4.227499961853027 | dt: 169.89 ms | tokens/sec: 36.16 | norm: 1.08\n",
      "step : 1305 | loss: 4.059138298034668 | dt: 169.66 ms | tokens/sec: 36.21 | norm: 0.95\n",
      "step : 1306 | loss: 4.205461502075195 | dt: 169.91 ms | tokens/sec: 36.16 | norm: 1.15\n",
      "step : 1307 | loss: 3.993281126022339 | dt: 169.89 ms | tokens/sec: 36.16 | norm: 1.20\n",
      "step : 1308 | loss: 3.8243188858032227 | dt: 171.14 ms | tokens/sec: 35.90 | norm: 1.49\n",
      "step : 1309 | loss: 3.979884147644043 | dt: 170.37 ms | tokens/sec: 36.06 | norm: 1.09\n",
      "step : 1310 | loss: 4.0234832763671875 | dt: 168.84 ms | tokens/sec: 36.39 | norm: 1.12\n",
      "step : 1311 | loss: 3.859431743621826 | dt: 170.22 ms | tokens/sec: 36.09 | norm: 1.19\n",
      "step : 1312 | loss: 3.7492644786834717 | dt: 169.83 ms | tokens/sec: 36.18 | norm: 0.97\n",
      "step : 1313 | loss: 4.154332637786865 | dt: 170.00 ms | tokens/sec: 36.14 | norm: 1.32\n",
      "step : 1314 | loss: 3.978480100631714 | dt: 171.28 ms | tokens/sec: 35.87 | norm: 1.27\n",
      "step : 1315 | loss: 3.8033390045166016 | dt: 169.84 ms | tokens/sec: 36.18 | norm: 1.08\n",
      "step : 1316 | loss: 3.858130931854248 | dt: 170.03 ms | tokens/sec: 36.13 | norm: 0.94\n",
      "step : 1317 | loss: 3.697051763534546 | dt: 170.43 ms | tokens/sec: 36.05 | norm: 0.89\n",
      "step : 1318 | loss: 3.4733119010925293 | dt: 170.15 ms | tokens/sec: 36.11 | norm: 0.94\n",
      "step : 1319 | loss: 4.087643623352051 | dt: 169.24 ms | tokens/sec: 36.30 | norm: 1.17\n",
      "step : 1320 | loss: 3.94387149810791 | dt: 170.27 ms | tokens/sec: 36.08 | norm: 1.02\n",
      "step : 1321 | loss: 4.115649223327637 | dt: 169.97 ms | tokens/sec: 36.15 | norm: 1.10\n",
      "step : 1322 | loss: 4.124411582946777 | dt: 169.03 ms | tokens/sec: 36.35 | norm: 0.99\n",
      "step : 1323 | loss: 4.052819728851318 | dt: 169.61 ms | tokens/sec: 36.22 | norm: 1.02\n",
      "step : 1324 | loss: 3.7382922172546387 | dt: 170.23 ms | tokens/sec: 36.09 | norm: 1.01\n",
      "step : 1325 | loss: 3.813447952270508 | dt: 169.92 ms | tokens/sec: 36.16 | norm: 1.17\n",
      "step : 1326 | loss: 3.790722608566284 | dt: 170.02 ms | tokens/sec: 36.14 | norm: 1.15\n",
      "step : 1327 | loss: 3.9748141765594482 | dt: 169.46 ms | tokens/sec: 36.26 | norm: 1.20\n",
      "step : 1328 | loss: 4.016786575317383 | dt: 169.78 ms | tokens/sec: 36.19 | norm: 1.11\n",
      "step : 1329 | loss: 3.921102523803711 | dt: 170.33 ms | tokens/sec: 36.07 | norm: 1.55\n",
      "step : 1330 | loss: 3.911365509033203 | dt: 168.79 ms | tokens/sec: 36.40 | norm: 1.37\n",
      "step : 1331 | loss: 3.945939540863037 | dt: 169.90 ms | tokens/sec: 36.16 | norm: 1.31\n",
      "step : 1332 | loss: 3.739518880844116 | dt: 169.28 ms | tokens/sec: 36.30 | norm: 0.97\n",
      "step : 1333 | loss: 3.9870002269744873 | dt: 170.26 ms | tokens/sec: 36.09 | norm: 0.96\n",
      "step : 1334 | loss: 3.836564540863037 | dt: 171.22 ms | tokens/sec: 35.88 | norm: 1.32\n",
      "step : 1335 | loss: 3.78607439994812 | dt: 169.31 ms | tokens/sec: 36.29 | norm: 1.36\n",
      "step : 1336 | loss: 4.049328804016113 | dt: 170.19 ms | tokens/sec: 36.10 | norm: 1.23\n",
      "step : 1337 | loss: 4.094202041625977 | dt: 169.43 ms | tokens/sec: 36.26 | norm: 1.14\n",
      "step : 1338 | loss: 4.031092643737793 | dt: 169.67 ms | tokens/sec: 36.21 | norm: 1.16\n",
      "step : 1339 | loss: 4.012582302093506 | dt: 171.32 ms | tokens/sec: 35.86 | norm: 0.97\n",
      "step : 1340 | loss: 4.021204948425293 | dt: 168.51 ms | tokens/sec: 36.46 | norm: 1.00\n",
      "step : 1341 | loss: 3.726774215698242 | dt: 170.05 ms | tokens/sec: 36.13 | norm: 1.06\n",
      "step : 1342 | loss: 4.051909446716309 | dt: 170.04 ms | tokens/sec: 36.13 | norm: 1.19\n",
      "step : 1343 | loss: 4.19690465927124 | dt: 170.03 ms | tokens/sec: 36.13 | norm: 1.38\n",
      "step : 1344 | loss: 4.089365005493164 | dt: 170.27 ms | tokens/sec: 36.08 | norm: 1.23\n",
      "step : 1345 | loss: 3.9497122764587402 | dt: 170.44 ms | tokens/sec: 36.05 | norm: 1.07\n",
      "step : 1346 | loss: 4.104131698608398 | dt: 169.17 ms | tokens/sec: 36.32 | norm: 0.96\n",
      "step : 1347 | loss: 3.8520545959472656 | dt: 168.22 ms | tokens/sec: 36.52 | norm: 0.82\n",
      "step : 1348 | loss: 4.069887161254883 | dt: 170.20 ms | tokens/sec: 36.10 | norm: 1.61\n",
      "step : 1349 | loss: 3.8433310985565186 | dt: 170.10 ms | tokens/sec: 36.12 | norm: 1.25\n",
      "step : 1350 | loss: 4.156200408935547 | dt: 169.35 ms | tokens/sec: 36.28 | norm: 1.04\n",
      "step : 1351 | loss: 4.061128616333008 | dt: 170.71 ms | tokens/sec: 35.99 | norm: 1.02\n",
      "step : 1352 | loss: 3.814626455307007 | dt: 170.09 ms | tokens/sec: 36.12 | norm: 0.95\n",
      "step : 1353 | loss: 3.95833683013916 | dt: 170.22 ms | tokens/sec: 36.09 | norm: 0.88\n",
      "step : 1354 | loss: 3.9370906352996826 | dt: 170.03 ms | tokens/sec: 36.14 | norm: 0.97\n",
      "step : 1355 | loss: 3.927004814147949 | dt: 169.14 ms | tokens/sec: 36.32 | norm: 0.96\n",
      "step : 1356 | loss: 4.160208702087402 | dt: 169.93 ms | tokens/sec: 36.16 | norm: 1.21\n",
      "step : 1357 | loss: 4.08723258972168 | dt: 169.57 ms | tokens/sec: 36.23 | norm: 1.09\n",
      "step : 1358 | loss: 4.362800598144531 | dt: 169.50 ms | tokens/sec: 36.25 | norm: 1.09\n",
      "step : 1359 | loss: 4.171473979949951 | dt: 170.46 ms | tokens/sec: 36.04 | norm: 1.10\n",
      "step : 1360 | loss: 4.003406047821045 | dt: 169.72 ms | tokens/sec: 36.20 | norm: 1.02\n",
      "step : 1361 | loss: 4.1589274406433105 | dt: 168.72 ms | tokens/sec: 36.42 | norm: 1.08\n",
      "step : 1362 | loss: 3.9954566955566406 | dt: 169.40 ms | tokens/sec: 36.27 | norm: 1.59\n",
      "step : 1363 | loss: 3.8225951194763184 | dt: 169.78 ms | tokens/sec: 36.19 | norm: 1.36\n",
      "step : 1364 | loss: 3.9291255474090576 | dt: 170.04 ms | tokens/sec: 36.13 | norm: 1.36\n",
      "step : 1365 | loss: 3.974825382232666 | dt: 170.54 ms | tokens/sec: 36.03 | norm: 1.12\n",
      "step : 1366 | loss: 3.813744068145752 | dt: 169.31 ms | tokens/sec: 36.29 | norm: 1.07\n",
      "step : 1367 | loss: 3.670016050338745 | dt: 169.31 ms | tokens/sec: 36.29 | norm: 1.23\n",
      "step : 1368 | loss: 4.156193733215332 | dt: 170.01 ms | tokens/sec: 36.14 | norm: 1.74\n",
      "step : 1369 | loss: 3.955132246017456 | dt: 171.24 ms | tokens/sec: 35.88 | norm: 1.38\n",
      "step : 1370 | loss: 3.7964959144592285 | dt: 171.14 ms | tokens/sec: 35.90 | norm: 1.35\n",
      "step : 1371 | loss: 3.859154462814331 | dt: 168.54 ms | tokens/sec: 36.45 | norm: 1.36\n",
      "step : 1372 | loss: 3.676539897918701 | dt: 169.99 ms | tokens/sec: 36.14 | norm: 1.04\n",
      "step : 1373 | loss: 3.415154457092285 | dt: 169.44 ms | tokens/sec: 36.26 | norm: 0.92\n",
      "step : 1374 | loss: 4.101985931396484 | dt: 170.04 ms | tokens/sec: 36.13 | norm: 1.22\n",
      "step : 1375 | loss: 3.887988567352295 | dt: 170.55 ms | tokens/sec: 36.02 | norm: 1.34\n",
      "step : 1376 | loss: 4.033533573150635 | dt: 170.59 ms | tokens/sec: 36.02 | norm: 1.16\n",
      "step : 1377 | loss: 4.035198211669922 | dt: 169.66 ms | tokens/sec: 36.21 | norm: 1.12\n",
      "step : 1378 | loss: 3.945680618286133 | dt: 169.17 ms | tokens/sec: 36.32 | norm: 0.87\n",
      "step : 1379 | loss: 3.6537742614746094 | dt: 169.98 ms | tokens/sec: 36.15 | norm: 0.98\n",
      "step : 1380 | loss: 3.7734575271606445 | dt: 169.93 ms | tokens/sec: 36.16 | norm: 0.97\n",
      "step : 1381 | loss: 3.7712085247039795 | dt: 168.57 ms | tokens/sec: 36.45 | norm: 1.07\n",
      "step : 1382 | loss: 3.963268995285034 | dt: 170.66 ms | tokens/sec: 36.00 | norm: 1.02\n",
      "step : 1383 | loss: 3.9921016693115234 | dt: 169.31 ms | tokens/sec: 36.29 | norm: 1.02\n",
      "step : 1384 | loss: 3.952538251876831 | dt: 168.36 ms | tokens/sec: 36.49 | norm: 1.47\n",
      "step : 1385 | loss: 3.856771945953369 | dt: 169.84 ms | tokens/sec: 36.17 | norm: 1.14\n",
      "step : 1386 | loss: 3.8907277584075928 | dt: 170.11 ms | tokens/sec: 36.12 | norm: 1.07\n",
      "step : 1387 | loss: 3.6844096183776855 | dt: 168.70 ms | tokens/sec: 36.42 | norm: 1.25\n",
      "step : 1388 | loss: 3.9362735748291016 | dt: 170.82 ms | tokens/sec: 35.97 | norm: 1.18\n",
      "step : 1389 | loss: 3.8333754539489746 | dt: 169.81 ms | tokens/sec: 36.18 | norm: 1.20\n",
      "step : 1390 | loss: 3.778041362762451 | dt: 169.00 ms | tokens/sec: 36.36 | norm: 1.63\n",
      "step : 1391 | loss: 4.022647857666016 | dt: 170.46 ms | tokens/sec: 36.04 | norm: 1.26\n",
      "step : 1392 | loss: 4.0667619705200195 | dt: 168.76 ms | tokens/sec: 36.41 | norm: 1.10\n",
      "step : 1393 | loss: 4.038065433502197 | dt: 168.91 ms | tokens/sec: 36.37 | norm: 1.20\n",
      "step : 1394 | loss: 3.9641566276550293 | dt: 170.11 ms | tokens/sec: 36.12 | norm: 1.08\n",
      "step : 1395 | loss: 3.969860792160034 | dt: 168.57 ms | tokens/sec: 36.45 | norm: 1.00\n",
      "step : 1396 | loss: 3.6763923168182373 | dt: 170.42 ms | tokens/sec: 36.05 | norm: 0.93\n",
      "step : 1397 | loss: 3.948439598083496 | dt: 170.05 ms | tokens/sec: 36.13 | norm: 0.98\n",
      "step : 1398 | loss: 4.118854522705078 | dt: 172.65 ms | tokens/sec: 35.59 | norm: 1.16\n",
      "step : 1399 | loss: 4.028347969055176 | dt: 169.43 ms | tokens/sec: 36.26 | norm: 1.17\n",
      "step : 1400 | loss: 3.885110855102539 | dt: 171.04 ms | tokens/sec: 35.92 | norm: 1.16\n",
      "step : 1401 | loss: 4.077287197113037 | dt: 169.76 ms | tokens/sec: 36.19 | norm: 1.42\n",
      "step : 1402 | loss: 3.815908908843994 | dt: 168.86 ms | tokens/sec: 36.38 | norm: 1.16\n",
      "step : 1403 | loss: 4.063755035400391 | dt: 169.19 ms | tokens/sec: 36.31 | norm: 1.15\n",
      "step : 1404 | loss: 3.8180806636810303 | dt: 173.12 ms | tokens/sec: 35.49 | norm: 1.11\n",
      "step : 1405 | loss: 4.049832820892334 | dt: 171.10 ms | tokens/sec: 35.91 | norm: 1.10\n",
      "step : 1406 | loss: 3.97554874420166 | dt: 170.20 ms | tokens/sec: 36.10 | norm: 1.24\n",
      "step : 1407 | loss: 3.7783799171447754 | dt: 170.36 ms | tokens/sec: 36.07 | norm: 1.32\n",
      "step : 1408 | loss: 3.904191493988037 | dt: 171.20 ms | tokens/sec: 35.89 | norm: 1.18\n",
      "step : 1409 | loss: 3.8751754760742188 | dt: 170.29 ms | tokens/sec: 36.08 | norm: 0.97\n",
      "step : 1410 | loss: 3.916670322418213 | dt: 170.02 ms | tokens/sec: 36.14 | norm: 0.95\n",
      "step : 1411 | loss: 4.213372707366943 | dt: 169.39 ms | tokens/sec: 36.27 | norm: 1.21\n",
      "step : 1412 | loss: 4.147096633911133 | dt: 169.33 ms | tokens/sec: 36.29 | norm: 1.28\n",
      "step : 1413 | loss: 4.365501403808594 | dt: 169.46 ms | tokens/sec: 36.26 | norm: 1.44\n",
      "step : 1414 | loss: 4.163735866546631 | dt: 169.95 ms | tokens/sec: 36.15 | norm: 1.44\n",
      "step : 1415 | loss: 3.9766082763671875 | dt: 169.82 ms | tokens/sec: 36.18 | norm: 1.23\n",
      "step : 1416 | loss: 4.106425762176514 | dt: 171.37 ms | tokens/sec: 35.85 | norm: 1.07\n",
      "step : 1417 | loss: 3.955073833465576 | dt: 169.83 ms | tokens/sec: 36.18 | norm: 1.10\n",
      "step : 1418 | loss: 3.778257369995117 | dt: 171.04 ms | tokens/sec: 35.92 | norm: 1.51\n",
      "step : 1419 | loss: 3.9053473472595215 | dt: 171.01 ms | tokens/sec: 35.93 | norm: 1.20\n",
      "step : 1420 | loss: 3.9242875576019287 | dt: 168.85 ms | tokens/sec: 36.39 | norm: 1.24\n",
      "step : 1421 | loss: 3.75323748588562 | dt: 169.23 ms | tokens/sec: 36.31 | norm: 1.18\n",
      "step : 1422 | loss: 3.6340136528015137 | dt: 169.31 ms | tokens/sec: 36.29 | norm: 1.00\n",
      "step : 1423 | loss: 4.106612205505371 | dt: 169.20 ms | tokens/sec: 36.31 | norm: 1.15\n",
      "step : 1424 | loss: 3.9067177772521973 | dt: 170.48 ms | tokens/sec: 36.04 | norm: 1.16\n",
      "step : 1425 | loss: 3.7732181549072266 | dt: 170.68 ms | tokens/sec: 36.00 | norm: 1.50\n",
      "step : 1426 | loss: 3.7997255325317383 | dt: 169.06 ms | tokens/sec: 36.34 | norm: 1.33\n",
      "step : 1427 | loss: 3.6337153911590576 | dt: 170.06 ms | tokens/sec: 36.13 | norm: 1.14\n",
      "step : 1428 | loss: 3.3799521923065186 | dt: 169.81 ms | tokens/sec: 36.18 | norm: 1.12\n",
      "step : 1429 | loss: 4.031161308288574 | dt: 171.04 ms | tokens/sec: 35.92 | norm: 1.41\n",
      "step : 1430 | loss: 3.870866298675537 | dt: 169.37 ms | tokens/sec: 36.28 | norm: 1.20\n",
      "step : 1431 | loss: 3.9605722427368164 | dt: 171.18 ms | tokens/sec: 35.89 | norm: 1.57\n",
      "step : 1432 | loss: 3.938977003097534 | dt: 169.77 ms | tokens/sec: 36.19 | norm: 1.13\n",
      "step : 1433 | loss: 3.890951156616211 | dt: 170.86 ms | tokens/sec: 35.96 | norm: 1.09\n",
      "step : 1434 | loss: 3.5865886211395264 | dt: 169.68 ms | tokens/sec: 36.21 | norm: 0.89\n",
      "step : 1435 | loss: 3.6877918243408203 | dt: 169.28 ms | tokens/sec: 36.29 | norm: 0.91\n",
      "step : 1436 | loss: 3.716703414916992 | dt: 170.91 ms | tokens/sec: 35.95 | norm: 1.00\n",
      "step : 1437 | loss: 3.886068105697632 | dt: 171.21 ms | tokens/sec: 35.89 | norm: 0.87\n",
      "step : 1438 | loss: 3.8979721069335938 | dt: 170.29 ms | tokens/sec: 36.08 | norm: 0.96\n",
      "step : 1439 | loss: 3.9123172760009766 | dt: 169.53 ms | tokens/sec: 36.24 | norm: 1.34\n",
      "step : 1440 | loss: 3.8359029293060303 | dt: 169.84 ms | tokens/sec: 36.18 | norm: 1.19\n",
      "step : 1441 | loss: 3.8382411003112793 | dt: 169.52 ms | tokens/sec: 36.24 | norm: 1.09\n",
      "step : 1442 | loss: 3.690403938293457 | dt: 170.40 ms | tokens/sec: 36.06 | norm: 1.18\n",
      "step : 1443 | loss: 3.8763949871063232 | dt: 172.02 ms | tokens/sec: 35.72 | norm: 1.14\n",
      "step : 1444 | loss: 3.772834300994873 | dt: 169.71 ms | tokens/sec: 36.20 | norm: 1.20\n",
      "step : 1445 | loss: 3.769651412963867 | dt: 170.85 ms | tokens/sec: 35.96 | norm: 1.25\n",
      "step : 1446 | loss: 3.9732584953308105 | dt: 171.59 ms | tokens/sec: 35.81 | norm: 1.15\n",
      "step : 1447 | loss: 3.9695892333984375 | dt: 172.13 ms | tokens/sec: 35.69 | norm: 0.99\n",
      "step : 1448 | loss: 3.9530322551727295 | dt: 169.65 ms | tokens/sec: 36.22 | norm: 1.16\n",
      "step : 1449 | loss: 3.903395175933838 | dt: 172.11 ms | tokens/sec: 35.70 | norm: 1.12\n",
      "step : 1450 | loss: 3.8932597637176514 | dt: 172.04 ms | tokens/sec: 35.71 | norm: 0.93\n",
      "step : 1451 | loss: 3.5999560356140137 | dt: 170.00 ms | tokens/sec: 36.14 | norm: 0.89\n",
      "step : 1452 | loss: 3.838315963745117 | dt: 171.07 ms | tokens/sec: 35.92 | norm: 0.93\n",
      "step : 1453 | loss: 4.0214762687683105 | dt: 170.46 ms | tokens/sec: 36.04 | norm: 1.10\n",
      "step : 1454 | loss: 3.947868824005127 | dt: 171.25 ms | tokens/sec: 35.88 | norm: 1.23\n",
      "step : 1455 | loss: 3.805903911590576 | dt: 169.88 ms | tokens/sec: 36.17 | norm: 1.01\n",
      "step : 1456 | loss: 4.041820526123047 | dt: 171.73 ms | tokens/sec: 35.78 | norm: 1.40\n",
      "step : 1457 | loss: 3.776599407196045 | dt: 171.17 ms | tokens/sec: 35.89 | norm: 1.15\n",
      "step : 1458 | loss: 4.0169548988342285 | dt: 171.27 ms | tokens/sec: 35.87 | norm: 1.25\n",
      "step : 1459 | loss: 3.7755560874938965 | dt: 169.93 ms | tokens/sec: 36.16 | norm: 2.21\n",
      "step : 1460 | loss: 4.042553901672363 | dt: 171.16 ms | tokens/sec: 35.90 | norm: 1.07\n",
      "step : 1461 | loss: 3.938910484313965 | dt: 171.61 ms | tokens/sec: 35.80 | norm: 1.01\n",
      "step : 1462 | loss: 3.734201192855835 | dt: 172.43 ms | tokens/sec: 35.63 | norm: 1.17\n",
      "step : 1463 | loss: 3.8720479011535645 | dt: 169.75 ms | tokens/sec: 36.19 | norm: 1.61\n",
      "step : 1464 | loss: 3.807659149169922 | dt: 171.10 ms | tokens/sec: 35.91 | norm: 1.06\n",
      "step : 1465 | loss: 3.8344180583953857 | dt: 172.02 ms | tokens/sec: 35.72 | norm: 1.03\n",
      "step : 1466 | loss: 4.152902126312256 | dt: 170.36 ms | tokens/sec: 36.06 | norm: 1.32\n",
      "step : 1467 | loss: 4.0983686447143555 | dt: 170.45 ms | tokens/sec: 36.05 | norm: 1.13\n",
      "step : 1468 | loss: 4.31700325012207 | dt: 170.46 ms | tokens/sec: 36.04 | norm: 1.18\n",
      "step : 1469 | loss: 4.089737892150879 | dt: 169.11 ms | tokens/sec: 36.33 | norm: 1.06\n",
      "step : 1470 | loss: 3.9438178539276123 | dt: 169.79 ms | tokens/sec: 36.19 | norm: 1.34\n",
      "step : 1471 | loss: 4.056759834289551 | dt: 169.12 ms | tokens/sec: 36.33 | norm: 1.08\n",
      "step : 1472 | loss: 3.8826491832733154 | dt: 167.87 ms | tokens/sec: 36.60 | norm: 1.22\n",
      "step : 1473 | loss: 3.6900851726531982 | dt: 167.91 ms | tokens/sec: 36.59 | norm: 1.17\n",
      "step : 1474 | loss: 3.8499960899353027 | dt: 169.03 ms | tokens/sec: 36.35 | norm: 1.24\n",
      "step : 1475 | loss: 3.8763442039489746 | dt: 168.11 ms | tokens/sec: 36.55 | norm: 1.34\n",
      "step : 1476 | loss: 3.704340696334839 | dt: 168.69 ms | tokens/sec: 36.42 | norm: 1.04\n",
      "step : 1477 | loss: 3.566664695739746 | dt: 169.14 ms | tokens/sec: 36.33 | norm: 0.92\n",
      "step : 1478 | loss: 4.005721569061279 | dt: 168.94 ms | tokens/sec: 36.37 | norm: 1.11\n",
      "step : 1479 | loss: 3.83076548576355 | dt: 168.61 ms | tokens/sec: 36.44 | norm: 1.09\n",
      "step : 1480 | loss: 3.7144813537597656 | dt: 169.54 ms | tokens/sec: 36.24 | norm: 1.06\n",
      "step : 1481 | loss: 3.731172561645508 | dt: 167.56 ms | tokens/sec: 36.67 | norm: 1.14\n",
      "step : 1482 | loss: 3.550809621810913 | dt: 167.91 ms | tokens/sec: 36.59 | norm: 1.04\n",
      "step : 1483 | loss: 3.3179931640625 | dt: 167.78 ms | tokens/sec: 36.62 | norm: 1.04\n",
      "step : 1484 | loss: 4.011295318603516 | dt: 167.85 ms | tokens/sec: 36.60 | norm: 1.27\n",
      "step : 1485 | loss: 3.810908079147339 | dt: 168.56 ms | tokens/sec: 36.45 | norm: 1.59\n",
      "step : 1486 | loss: 4.006725788116455 | dt: 169.33 ms | tokens/sec: 36.28 | norm: 1.40\n",
      "step : 1487 | loss: 3.957907199859619 | dt: 168.62 ms | tokens/sec: 36.44 | norm: 1.18\n",
      "step : 1488 | loss: 3.902484893798828 | dt: 168.83 ms | tokens/sec: 36.39 | norm: 1.16\n",
      "step : 1489 | loss: 3.569223165512085 | dt: 168.12 ms | tokens/sec: 36.55 | norm: 0.96\n",
      "step : 1490 | loss: 3.659404754638672 | dt: 168.40 ms | tokens/sec: 36.48 | norm: 0.88\n",
      "step : 1491 | loss: 3.660665512084961 | dt: 167.28 ms | tokens/sec: 36.73 | norm: 1.06\n",
      "step : 1492 | loss: 3.8404109477996826 | dt: 167.93 ms | tokens/sec: 36.59 | norm: 1.10\n",
      "step : 1493 | loss: 3.8616323471069336 | dt: 168.21 ms | tokens/sec: 36.53 | norm: 1.03\n",
      "step : 1494 | loss: 3.8227977752685547 | dt: 168.83 ms | tokens/sec: 36.39 | norm: 1.14\n",
      "step : 1495 | loss: 3.7374398708343506 | dt: 169.40 ms | tokens/sec: 36.27 | norm: 0.97\n",
      "step : 1496 | loss: 3.765779972076416 | dt: 168.67 ms | tokens/sec: 36.43 | norm: 1.01\n",
      "step : 1497 | loss: 3.6316280364990234 | dt: 168.02 ms | tokens/sec: 36.57 | norm: 1.21\n",
      "step : 1498 | loss: 3.800752639770508 | dt: 172.79 ms | tokens/sec: 35.56 | norm: 1.09\n",
      "step : 1499 | loss: 3.6808295249938965 | dt: 171.64 ms | tokens/sec: 35.80 | norm: 2.84\n",
      "step : 1500 | loss: 3.6853270530700684 | dt: 171.60 ms | tokens/sec: 35.80 | norm: 1.13\n",
      "step : 1501 | loss: 3.8967082500457764 | dt: 170.02 ms | tokens/sec: 36.14 | norm: 1.11\n",
      "step : 1502 | loss: 3.9167919158935547 | dt: 171.17 ms | tokens/sec: 35.89 | norm: 1.11\n",
      "step : 1503 | loss: 3.908677577972412 | dt: 171.97 ms | tokens/sec: 35.73 | norm: 1.02\n",
      "step : 1504 | loss: 3.8571901321411133 | dt: 171.08 ms | tokens/sec: 35.91 | norm: 1.08\n",
      "step : 1505 | loss: 3.842322826385498 | dt: 171.86 ms | tokens/sec: 35.75 | norm: 0.99\n",
      "step : 1506 | loss: 3.553659439086914 | dt: 171.40 ms | tokens/sec: 35.85 | norm: 1.01\n",
      "step : 1507 | loss: 3.7656726837158203 | dt: 172.17 ms | tokens/sec: 35.68 | norm: 0.96\n",
      "step : 1508 | loss: 3.972407817840576 | dt: 170.50 ms | tokens/sec: 36.04 | norm: 1.05\n",
      "step : 1509 | loss: 3.887951612472534 | dt: 171.23 ms | tokens/sec: 35.88 | norm: 0.98\n",
      "step : 1510 | loss: 3.723752498626709 | dt: 172.23 ms | tokens/sec: 35.67 | norm: 1.21\n",
      "step : 1511 | loss: 3.9390056133270264 | dt: 172.22 ms | tokens/sec: 35.67 | norm: 1.16\n",
      "step : 1512 | loss: 3.69980525970459 | dt: 171.23 ms | tokens/sec: 35.88 | norm: 1.09\n",
      "step : 1513 | loss: 3.8968703746795654 | dt: 171.99 ms | tokens/sec: 35.72 | norm: 1.18\n",
      "step : 1514 | loss: 3.8151769638061523 | dt: 171.47 ms | tokens/sec: 35.83 | norm: 1.09\n",
      "step : 1515 | loss: 3.992438316345215 | dt: 168.36 ms | tokens/sec: 36.49 | norm: 1.04\n",
      "step : 1516 | loss: 3.865858793258667 | dt: 168.45 ms | tokens/sec: 36.47 | norm: 0.95\n",
      "step : 1517 | loss: 3.675389051437378 | dt: 168.99 ms | tokens/sec: 36.36 | norm: 1.39\n",
      "step : 1518 | loss: 3.846473217010498 | dt: 169.39 ms | tokens/sec: 36.27 | norm: 1.14\n",
      "step : 1519 | loss: 3.749715805053711 | dt: 169.43 ms | tokens/sec: 36.26 | norm: 1.11\n",
      "step : 1520 | loss: 3.7596888542175293 | dt: 169.83 ms | tokens/sec: 36.18 | norm: 1.03\n",
      "step : 1521 | loss: 4.056589603424072 | dt: 168.95 ms | tokens/sec: 36.37 | norm: 1.16\n",
      "step : 1522 | loss: 3.998124837875366 | dt: 168.36 ms | tokens/sec: 36.49 | norm: 1.06\n",
      "step : 1523 | loss: 4.23042631149292 | dt: 169.95 ms | tokens/sec: 36.15 | norm: 1.32\n",
      "step : 1524 | loss: 4.00250244140625 | dt: 169.75 ms | tokens/sec: 36.19 | norm: 1.12\n",
      "step : 1525 | loss: 3.8955345153808594 | dt: 169.61 ms | tokens/sec: 36.22 | norm: 1.00\n",
      "step : 1526 | loss: 4.016946792602539 | dt: 169.64 ms | tokens/sec: 36.22 | norm: 1.07\n",
      "step : 1527 | loss: 3.828754425048828 | dt: 169.42 ms | tokens/sec: 36.27 | norm: 1.04\n",
      "step : 1528 | loss: 3.6052708625793457 | dt: 168.20 ms | tokens/sec: 36.53 | norm: 1.16\n",
      "step : 1529 | loss: 3.748696804046631 | dt: 169.52 ms | tokens/sec: 36.24 | norm: 1.05\n",
      "step : 1530 | loss: 3.7967286109924316 | dt: 170.09 ms | tokens/sec: 36.12 | norm: 1.02\n",
      "step : 1531 | loss: 3.6237869262695312 | dt: 169.28 ms | tokens/sec: 36.30 | norm: 1.09\n",
      "step : 1532 | loss: 3.4961516857147217 | dt: 170.16 ms | tokens/sec: 36.11 | norm: 1.35\n",
      "step : 1533 | loss: 3.9392478466033936 | dt: 169.39 ms | tokens/sec: 36.27 | norm: 1.06\n",
      "step : 1534 | loss: 3.771636962890625 | dt: 169.36 ms | tokens/sec: 36.28 | norm: 1.17\n",
      "step : 1535 | loss: 3.651728391647339 | dt: 168.80 ms | tokens/sec: 36.40 | norm: 1.12\n",
      "step : 1536 | loss: 3.635566234588623 | dt: 169.75 ms | tokens/sec: 36.19 | norm: 1.08\n",
      "step : 1537 | loss: 3.488464117050171 | dt: 169.64 ms | tokens/sec: 36.22 | norm: 0.93\n",
      "step : 1538 | loss: 3.2504117488861084 | dt: 169.20 ms | tokens/sec: 36.31 | norm: 0.92\n",
      "step : 1539 | loss: 3.934537410736084 | dt: 169.49 ms | tokens/sec: 36.25 | norm: 1.11\n",
      "step : 1540 | loss: 3.7967917919158936 | dt: 168.33 ms | tokens/sec: 36.50 | norm: 1.25\n",
      "step : 1541 | loss: 3.8772132396698 | dt: 168.92 ms | tokens/sec: 36.37 | norm: 1.33\n",
      "step : 1542 | loss: 3.8411030769348145 | dt: 170.63 ms | tokens/sec: 36.01 | norm: 1.14\n",
      "step : 1543 | loss: 3.7907118797302246 | dt: 169.54 ms | tokens/sec: 36.24 | norm: 0.99\n",
      "step : 1544 | loss: 3.485168933868408 | dt: 168.91 ms | tokens/sec: 36.37 | norm: 1.00\n",
      "step : 1545 | loss: 3.5919675827026367 | dt: 169.77 ms | tokens/sec: 36.19 | norm: 0.84\n",
      "step : 1546 | loss: 3.586564064025879 | dt: 171.29 ms | tokens/sec: 35.87 | norm: 0.99\n",
      "step : 1547 | loss: 3.7796428203582764 | dt: 169.82 ms | tokens/sec: 36.18 | norm: 0.88\n",
      "step : 1548 | loss: 3.7719764709472656 | dt: 170.51 ms | tokens/sec: 36.03 | norm: 0.99\n",
      "step : 1549 | loss: 3.7000041007995605 | dt: 169.04 ms | tokens/sec: 36.35 | norm: 1.13\n",
      "step : 1550 | loss: 3.6340491771698 | dt: 169.38 ms | tokens/sec: 36.27 | norm: 1.04\n",
      "step : 1551 | loss: 3.6580588817596436 | dt: 168.09 ms | tokens/sec: 36.55 | norm: 0.94\n",
      "step : 1552 | loss: 3.5177183151245117 | dt: 169.63 ms | tokens/sec: 36.22 | norm: 0.97\n",
      "step : 1553 | loss: 3.71175479888916 | dt: 171.15 ms | tokens/sec: 35.90 | norm: 1.01\n",
      "step : 1554 | loss: 3.699455738067627 | dt: 169.76 ms | tokens/sec: 36.19 | norm: 1.03\n",
      "step : 1555 | loss: 3.570276975631714 | dt: 168.92 ms | tokens/sec: 36.37 | norm: 1.10\n",
      "step : 1556 | loss: 3.815633773803711 | dt: 168.32 ms | tokens/sec: 36.50 | norm: 1.09\n",
      "step : 1557 | loss: 3.839747190475464 | dt: 168.36 ms | tokens/sec: 36.49 | norm: 1.03\n",
      "step : 1558 | loss: 3.7851312160491943 | dt: 168.76 ms | tokens/sec: 36.41 | norm: 1.07\n",
      "step : 1559 | loss: 3.761215925216675 | dt: 169.06 ms | tokens/sec: 36.34 | norm: 1.02\n",
      "step : 1560 | loss: 3.7643659114837646 | dt: 170.20 ms | tokens/sec: 36.10 | norm: 1.23\n",
      "step : 1561 | loss: 3.496577262878418 | dt: 169.53 ms | tokens/sec: 36.24 | norm: 0.92\n",
      "step : 1562 | loss: 3.7046380043029785 | dt: 169.00 ms | tokens/sec: 36.36 | norm: 1.04\n",
      "step : 1563 | loss: 3.891414165496826 | dt: 167.95 ms | tokens/sec: 36.58 | norm: 1.11\n",
      "step : 1564 | loss: 3.8115642070770264 | dt: 167.79 ms | tokens/sec: 36.62 | norm: 1.25\n",
      "step : 1565 | loss: 3.682281494140625 | dt: 168.23 ms | tokens/sec: 36.52 | norm: 1.07\n",
      "step : 1566 | loss: 3.879444122314453 | dt: 171.33 ms | tokens/sec: 35.86 | norm: 1.21\n",
      "step : 1567 | loss: 3.6538360118865967 | dt: 169.06 ms | tokens/sec: 36.34 | norm: 1.12\n",
      "step : 1568 | loss: 3.8451945781707764 | dt: 169.16 ms | tokens/sec: 36.32 | norm: 1.03\n",
      "step : 1569 | loss: 3.6728339195251465 | dt: 168.92 ms | tokens/sec: 36.37 | norm: 1.09\n",
      "step : 1570 | loss: 3.8834853172302246 | dt: 168.29 ms | tokens/sec: 36.51 | norm: 0.96\n",
      "step : 1571 | loss: 3.783973217010498 | dt: 167.99 ms | tokens/sec: 36.57 | norm: 1.01\n",
      "step : 1572 | loss: 3.6137919425964355 | dt: 168.54 ms | tokens/sec: 36.46 | norm: 1.13\n",
      "step : 1573 | loss: 3.7806479930877686 | dt: 169.80 ms | tokens/sec: 36.18 | norm: 1.11\n",
      "step : 1574 | loss: 3.6906890869140625 | dt: 169.36 ms | tokens/sec: 36.28 | norm: 1.02\n",
      "step : 1575 | loss: 3.678643226623535 | dt: 170.05 ms | tokens/sec: 36.13 | norm: 1.06\n",
      "step : 1576 | loss: 3.9668121337890625 | dt: 168.84 ms | tokens/sec: 36.39 | norm: 1.21\n",
      "step : 1577 | loss: 3.8850276470184326 | dt: 168.37 ms | tokens/sec: 36.49 | norm: 1.27\n",
      "step : 1578 | loss: 4.138057708740234 | dt: 168.01 ms | tokens/sec: 36.57 | norm: 1.12\n",
      "step : 1579 | loss: 3.9227359294891357 | dt: 169.16 ms | tokens/sec: 36.32 | norm: 1.25\n",
      "step : 1580 | loss: 3.800626516342163 | dt: 168.70 ms | tokens/sec: 36.42 | norm: 1.08\n",
      "step : 1581 | loss: 3.9357547760009766 | dt: 169.90 ms | tokens/sec: 36.16 | norm: 1.32\n",
      "step : 1582 | loss: 3.7696473598480225 | dt: 170.15 ms | tokens/sec: 36.11 | norm: 1.46\n",
      "step : 1583 | loss: 3.5655267238616943 | dt: 169.29 ms | tokens/sec: 36.29 | norm: 1.28\n",
      "step : 1584 | loss: 3.709749221801758 | dt: 168.19 ms | tokens/sec: 36.53 | norm: 1.12\n",
      "step : 1585 | loss: 3.7213873863220215 | dt: 168.81 ms | tokens/sec: 36.40 | norm: 1.15\n",
      "step : 1586 | loss: 3.555964469909668 | dt: 168.00 ms | tokens/sec: 36.57 | norm: 1.08\n",
      "step : 1587 | loss: 3.475864887237549 | dt: 168.81 ms | tokens/sec: 36.39 | norm: 1.01\n",
      "step : 1588 | loss: 3.831472158432007 | dt: 169.32 ms | tokens/sec: 36.29 | norm: 1.25\n",
      "step : 1589 | loss: 3.7178962230682373 | dt: 169.30 ms | tokens/sec: 36.29 | norm: 1.38\n",
      "step : 1590 | loss: 3.5756492614746094 | dt: 168.77 ms | tokens/sec: 36.41 | norm: 1.18\n",
      "step : 1591 | loss: 3.571213483810425 | dt: 169.33 ms | tokens/sec: 36.28 | norm: 1.10\n",
      "step : 1592 | loss: 3.4382083415985107 | dt: 168.20 ms | tokens/sec: 36.53 | norm: 1.22\n",
      "step : 1593 | loss: 3.2015788555145264 | dt: 168.08 ms | tokens/sec: 36.55 | norm: 1.03\n",
      "step : 1594 | loss: 3.8677611351013184 | dt: 168.17 ms | tokens/sec: 36.53 | norm: 1.26\n",
      "step : 1595 | loss: 3.72373104095459 | dt: 168.90 ms | tokens/sec: 36.38 | norm: 1.36\n",
      "step : 1596 | loss: 3.860063314437866 | dt: 169.36 ms | tokens/sec: 36.28 | norm: 1.53\n",
      "step : 1597 | loss: 3.7897720336914062 | dt: 169.81 ms | tokens/sec: 36.18 | norm: 1.24\n",
      "step : 1598 | loss: 3.6956822872161865 | dt: 168.96 ms | tokens/sec: 36.36 | norm: 1.05\n",
      "step : 1599 | loss: 3.409322738647461 | dt: 168.35 ms | tokens/sec: 36.50 | norm: 1.23\n",
      "step : 1600 | loss: 3.5252044200897217 | dt: 168.04 ms | tokens/sec: 36.56 | norm: 1.13\n",
      "step : 1601 | loss: 3.528717517852783 | dt: 167.60 ms | tokens/sec: 36.66 | norm: 1.11\n",
      "step : 1602 | loss: 3.7225942611694336 | dt: 168.34 ms | tokens/sec: 36.50 | norm: 1.15\n",
      "step : 1603 | loss: 3.749133586883545 | dt: 169.19 ms | tokens/sec: 36.31 | norm: 1.11\n",
      "step : 1604 | loss: 3.687748908996582 | dt: 169.31 ms | tokens/sec: 36.29 | norm: 1.22\n",
      "step : 1605 | loss: 3.6192424297332764 | dt: 169.29 ms | tokens/sec: 36.29 | norm: 1.16\n",
      "step : 1606 | loss: 3.6177420616149902 | dt: 168.68 ms | tokens/sec: 36.42 | norm: 0.99\n",
      "step : 1607 | loss: 3.441018581390381 | dt: 168.21 ms | tokens/sec: 36.53 | norm: 1.01\n",
      "step : 1608 | loss: 3.664060115814209 | dt: 167.73 ms | tokens/sec: 36.63 | norm: 1.07\n",
      "step : 1609 | loss: 3.5871598720550537 | dt: 167.94 ms | tokens/sec: 36.59 | norm: 1.00\n",
      "step : 1610 | loss: 3.486443281173706 | dt: 169.01 ms | tokens/sec: 36.35 | norm: 0.99\n",
      "step : 1611 | loss: 3.7323384284973145 | dt: 168.49 ms | tokens/sec: 36.47 | norm: 1.09\n",
      "step : 1612 | loss: 3.7867183685302734 | dt: 169.62 ms | tokens/sec: 36.22 | norm: 1.08\n",
      "step : 1613 | loss: 3.7510879039764404 | dt: 168.80 ms | tokens/sec: 36.40 | norm: 1.17\n",
      "step : 1614 | loss: 3.738842725753784 | dt: 168.86 ms | tokens/sec: 36.39 | norm: 1.12\n",
      "step : 1615 | loss: 3.756382465362549 | dt: 169.24 ms | tokens/sec: 36.30 | norm: 1.24\n",
      "step : 1616 | loss: 3.437347173690796 | dt: 168.88 ms | tokens/sec: 36.38 | norm: 1.67\n",
      "step : 1617 | loss: 3.646416187286377 | dt: 168.76 ms | tokens/sec: 36.41 | norm: 1.10\n",
      "step : 1618 | loss: 3.793353796005249 | dt: 168.43 ms | tokens/sec: 36.48 | norm: 1.13\n",
      "step : 1619 | loss: 3.7529611587524414 | dt: 169.40 ms | tokens/sec: 36.27 | norm: 1.02\n",
      "step : 1620 | loss: 3.59727144241333 | dt: 169.44 ms | tokens/sec: 36.26 | norm: 1.13\n",
      "step : 1621 | loss: 3.812398910522461 | dt: 168.53 ms | tokens/sec: 36.46 | norm: 1.40\n",
      "step : 1622 | loss: 3.59030818939209 | dt: 169.39 ms | tokens/sec: 36.27 | norm: 1.22\n",
      "step : 1623 | loss: 3.760913372039795 | dt: 167.82 ms | tokens/sec: 36.61 | norm: 1.35\n",
      "step : 1624 | loss: 3.611995220184326 | dt: 167.65 ms | tokens/sec: 36.65 | norm: 1.45\n",
      "step : 1625 | loss: 3.8279643058776855 | dt: 167.42 ms | tokens/sec: 36.70 | norm: 1.30\n",
      "step : 1626 | loss: 3.7136478424072266 | dt: 168.46 ms | tokens/sec: 36.47 | norm: 1.05\n",
      "step : 1627 | loss: 3.5390849113464355 | dt: 168.27 ms | tokens/sec: 36.51 | norm: 1.10\n",
      "step : 1628 | loss: 3.7089920043945312 | dt: 170.57 ms | tokens/sec: 36.02 | norm: 1.06\n",
      "step : 1629 | loss: 3.6145710945129395 | dt: 169.29 ms | tokens/sec: 36.29 | norm: 1.08\n",
      "step : 1630 | loss: 3.6467444896698 | dt: 168.68 ms | tokens/sec: 36.42 | norm: 1.20\n",
      "step : 1631 | loss: 3.9009323120117188 | dt: 168.34 ms | tokens/sec: 36.50 | norm: 1.46\n",
      "step : 1632 | loss: 3.846200942993164 | dt: 167.76 ms | tokens/sec: 36.62 | norm: 1.42\n",
      "step : 1633 | loss: 4.034071922302246 | dt: 167.47 ms | tokens/sec: 36.69 | norm: 1.06\n",
      "step : 1634 | loss: 3.8336081504821777 | dt: 169.09 ms | tokens/sec: 36.34 | norm: 1.14\n",
      "step : 1635 | loss: 3.73358154296875 | dt: 167.74 ms | tokens/sec: 36.63 | norm: 1.20\n",
      "step : 1636 | loss: 3.8845434188842773 | dt: 169.53 ms | tokens/sec: 36.24 | norm: 1.36\n",
      "step : 1637 | loss: 3.74586820602417 | dt: 169.46 ms | tokens/sec: 36.26 | norm: 1.61\n",
      "step : 1638 | loss: 3.5629210472106934 | dt: 168.75 ms | tokens/sec: 36.41 | norm: 2.22\n",
      "step : 1639 | loss: 3.6688079833984375 | dt: 168.99 ms | tokens/sec: 36.36 | norm: 1.15\n",
      "step : 1640 | loss: 3.6705617904663086 | dt: 168.12 ms | tokens/sec: 36.54 | norm: 1.40\n",
      "step : 1641 | loss: 3.495781898498535 | dt: 169.26 ms | tokens/sec: 36.30 | norm: 1.27\n",
      "step : 1642 | loss: 3.4101719856262207 | dt: 168.20 ms | tokens/sec: 36.53 | norm: 1.05\n",
      "step : 1643 | loss: 3.798333168029785 | dt: 166.22 ms | tokens/sec: 36.96 | norm: 1.17\n",
      "step : 1644 | loss: 3.650298833847046 | dt: 166.50 ms | tokens/sec: 36.90 | norm: 1.43\n",
      "step : 1645 | loss: 3.5421605110168457 | dt: 166.36 ms | tokens/sec: 36.93 | norm: 1.28\n",
      "step : 1646 | loss: 3.5156588554382324 | dt: 166.52 ms | tokens/sec: 36.90 | norm: 1.56\n",
      "step : 1647 | loss: 3.4209201335906982 | dt: 168.57 ms | tokens/sec: 36.45 | norm: 1.29\n",
      "step : 1648 | loss: 3.1805472373962402 | dt: 168.82 ms | tokens/sec: 36.39 | norm: 1.28\n",
      "step : 1649 | loss: 3.836987257003784 | dt: 167.29 ms | tokens/sec: 36.73 | norm: 1.49\n",
      "step : 1650 | loss: 3.7370128631591797 | dt: 167.59 ms | tokens/sec: 36.66 | norm: 1.59\n",
      "step : 1651 | loss: 3.8532934188842773 | dt: 166.67 ms | tokens/sec: 36.86 | norm: 1.30\n",
      "step : 1652 | loss: 3.8182148933410645 | dt: 166.89 ms | tokens/sec: 36.82 | norm: 1.60\n",
      "step : 1653 | loss: 3.668198347091675 | dt: 168.86 ms | tokens/sec: 36.39 | norm: 1.23\n",
      "step : 1654 | loss: 3.3862388134002686 | dt: 168.44 ms | tokens/sec: 36.48 | norm: 1.13\n",
      "step : 1655 | loss: 3.4890360832214355 | dt: 168.30 ms | tokens/sec: 36.51 | norm: 1.12\n",
      "step : 1656 | loss: 3.476875066757202 | dt: 167.32 ms | tokens/sec: 36.72 | norm: 1.22\n",
      "step : 1657 | loss: 3.673191785812378 | dt: 167.43 ms | tokens/sec: 36.70 | norm: 1.10\n",
      "step : 1658 | loss: 3.681396484375 | dt: 167.38 ms | tokens/sec: 36.71 | norm: 1.14\n",
      "step : 1659 | loss: 3.640092372894287 | dt: 168.21 ms | tokens/sec: 36.53 | norm: 1.44\n",
      "step : 1660 | loss: 3.5677132606506348 | dt: 167.75 ms | tokens/sec: 36.63 | norm: 1.09\n",
      "step : 1661 | loss: 3.5775341987609863 | dt: 167.20 ms | tokens/sec: 36.75 | norm: 1.05\n",
      "step : 1662 | loss: 3.393329381942749 | dt: 167.17 ms | tokens/sec: 36.75 | norm: 1.11\n",
      "step : 1663 | loss: 3.626633405685425 | dt: 169.08 ms | tokens/sec: 36.34 | norm: 1.21\n",
      "step : 1664 | loss: 3.501682758331299 | dt: 168.67 ms | tokens/sec: 36.43 | norm: 1.22\n",
      "step : 1665 | loss: 3.425809621810913 | dt: 168.23 ms | tokens/sec: 36.52 | norm: 1.26\n",
      "step : 1666 | loss: 3.6705451011657715 | dt: 169.34 ms | tokens/sec: 36.28 | norm: 1.21\n",
      "step : 1667 | loss: 3.6984362602233887 | dt: 168.25 ms | tokens/sec: 36.52 | norm: 1.12\n",
      "step : 1668 | loss: 3.67470121383667 | dt: 167.53 ms | tokens/sec: 36.67 | norm: 1.20\n",
      "step : 1669 | loss: 3.674807071685791 | dt: 167.95 ms | tokens/sec: 36.58 | norm: 1.18\n",
      "step : 1670 | loss: 3.694063901901245 | dt: 168.01 ms | tokens/sec: 36.57 | norm: 1.17\n",
      "step : 1671 | loss: 3.452308177947998 | dt: 166.32 ms | tokens/sec: 36.94 | norm: 1.19\n",
      "step : 1672 | loss: 3.603041410446167 | dt: 168.71 ms | tokens/sec: 36.42 | norm: 1.36\n",
      "step : 1673 | loss: 3.7576308250427246 | dt: 168.03 ms | tokens/sec: 36.56 | norm: 1.25\n",
      "step : 1674 | loss: 3.6923975944519043 | dt: 168.43 ms | tokens/sec: 36.48 | norm: 1.20\n",
      "step : 1675 | loss: 3.5486841201782227 | dt: 168.47 ms | tokens/sec: 36.47 | norm: 1.21\n",
      "step : 1676 | loss: 3.767869472503662 | dt: 168.63 ms | tokens/sec: 36.43 | norm: 1.26\n",
      "step : 1677 | loss: 3.5435614585876465 | dt: 168.82 ms | tokens/sec: 36.39 | norm: 1.07\n",
      "step : 1678 | loss: 3.757962942123413 | dt: 168.44 ms | tokens/sec: 36.48 | norm: 1.27\n",
      "step : 1679 | loss: 3.62514066696167 | dt: 167.73 ms | tokens/sec: 36.63 | norm: 1.08\n",
      "step : 1680 | loss: 3.818051338195801 | dt: 166.02 ms | tokens/sec: 37.01 | norm: 1.14\n",
      "step : 1681 | loss: 3.671626091003418 | dt: 165.16 ms | tokens/sec: 37.20 | norm: 1.06\n",
      "step : 1682 | loss: 3.471810817718506 | dt: 165.06 ms | tokens/sec: 37.22 | norm: 1.33\n",
      "step : 1683 | loss: 3.6168951988220215 | dt: 166.93 ms | tokens/sec: 36.81 | norm: 1.10\n",
      "step : 1684 | loss: 3.5332038402557373 | dt: 168.05 ms | tokens/sec: 36.56 | norm: 1.00\n",
      "step : 1685 | loss: 3.5679869651794434 | dt: 166.31 ms | tokens/sec: 36.94 | norm: 1.08\n",
      "step : 1686 | loss: 3.827789783477783 | dt: 165.74 ms | tokens/sec: 37.07 | norm: 1.27\n",
      "step : 1687 | loss: 3.8190131187438965 | dt: 165.37 ms | tokens/sec: 37.15 | norm: 1.26\n",
      "step : 1688 | loss: 3.9564480781555176 | dt: 165.13 ms | tokens/sec: 37.21 | norm: 1.13\n",
      "step : 1689 | loss: 3.7350003719329834 | dt: 166.75 ms | tokens/sec: 36.84 | norm: 0.92\n",
      "step : 1690 | loss: 3.6544747352600098 | dt: 165.89 ms | tokens/sec: 37.04 | norm: 0.87\n",
      "step : 1691 | loss: 3.8332324028015137 | dt: 165.50 ms | tokens/sec: 37.12 | norm: 1.07\n",
      "step : 1692 | loss: 3.6711487770080566 | dt: 165.56 ms | tokens/sec: 37.11 | norm: 1.31\n",
      "step : 1693 | loss: 3.510624647140503 | dt: 164.14 ms | tokens/sec: 37.43 | norm: 1.41\n",
      "step : 1694 | loss: 3.583217144012451 | dt: 164.50 ms | tokens/sec: 37.35 | norm: 1.21\n",
      "step : 1695 | loss: 3.616208791732788 | dt: 164.92 ms | tokens/sec: 37.25 | norm: 1.44\n",
      "step : 1696 | loss: 3.444277763366699 | dt: 164.64 ms | tokens/sec: 37.32 | norm: 1.29\n",
      "step : 1697 | loss: 3.3357036113739014 | dt: 166.52 ms | tokens/sec: 36.90 | norm: 1.01\n",
      "step : 1698 | loss: 3.712205410003662 | dt: 165.60 ms | tokens/sec: 37.10 | norm: 1.10\n",
      "step : 1699 | loss: 3.579899311065674 | dt: 165.21 ms | tokens/sec: 37.19 | norm: 1.41\n",
      "step : 1700 | loss: 3.4283578395843506 | dt: 164.96 ms | tokens/sec: 37.25 | norm: 1.17\n",
      "step : 1701 | loss: 3.4528098106384277 | dt: 165.79 ms | tokens/sec: 37.06 | norm: 1.43\n",
      "step : 1702 | loss: 3.3303306102752686 | dt: 165.22 ms | tokens/sec: 37.19 | norm: 1.14\n",
      "step : 1703 | loss: 3.084885358810425 | dt: 166.59 ms | tokens/sec: 36.88 | norm: 1.18\n",
      "step : 1704 | loss: 3.7459449768066406 | dt: 165.72 ms | tokens/sec: 37.08 | norm: 1.48\n",
      "step : 1705 | loss: 3.639247417449951 | dt: 164.38 ms | tokens/sec: 37.38 | norm: 1.58\n",
      "step : 1706 | loss: 3.7444474697113037 | dt: 165.61 ms | tokens/sec: 37.10 | norm: 1.24\n",
      "step : 1707 | loss: 3.7334818840026855 | dt: 164.25 ms | tokens/sec: 37.41 | norm: 1.12\n",
      "step : 1708 | loss: 3.6034114360809326 | dt: 163.77 ms | tokens/sec: 37.52 | norm: 1.10\n",
      "step : 1709 | loss: 3.316830635070801 | dt: 166.34 ms | tokens/sec: 36.94 | norm: 0.99\n",
      "step : 1710 | loss: 3.428554058074951 | dt: 165.07 ms | tokens/sec: 37.22 | norm: 0.96\n",
      "step : 1711 | loss: 3.419734477996826 | dt: 165.19 ms | tokens/sec: 37.19 | norm: 1.10\n",
      "step : 1712 | loss: 3.5861716270446777 | dt: 165.78 ms | tokens/sec: 37.06 | norm: 0.97\n",
      "step : 1713 | loss: 3.628645896911621 | dt: 165.23 ms | tokens/sec: 37.18 | norm: 1.11\n",
      "step : 1714 | loss: 3.5440175533294678 | dt: 165.11 ms | tokens/sec: 37.21 | norm: 1.21\n",
      "step : 1715 | loss: 3.4550750255584717 | dt: 166.69 ms | tokens/sec: 36.86 | norm: 1.20\n",
      "step : 1716 | loss: 3.492670774459839 | dt: 165.77 ms | tokens/sec: 37.06 | norm: 1.15\n",
      "step : 1717 | loss: 3.3356027603149414 | dt: 164.35 ms | tokens/sec: 37.38 | norm: 1.10\n",
      "step : 1718 | loss: 3.559760808944702 | dt: 165.58 ms | tokens/sec: 37.11 | norm: 1.39\n",
      "step : 1719 | loss: 3.4506287574768066 | dt: 163.74 ms | tokens/sec: 37.52 | norm: 1.13\n",
      "step : 1720 | loss: 3.3688888549804688 | dt: 164.50 ms | tokens/sec: 37.35 | norm: 1.40\n",
      "step : 1721 | loss: 3.605924606323242 | dt: 165.01 ms | tokens/sec: 37.23 | norm: 1.14\n",
      "step : 1722 | loss: 3.658547878265381 | dt: 165.64 ms | tokens/sec: 37.09 | norm: 1.35\n",
      "step : 1723 | loss: 3.622948169708252 | dt: 165.53 ms | tokens/sec: 37.12 | norm: 1.19\n",
      "step : 1724 | loss: 3.627526044845581 | dt: 165.95 ms | tokens/sec: 37.02 | norm: 1.27\n",
      "step : 1725 | loss: 3.628369092941284 | dt: 165.30 ms | tokens/sec: 37.17 | norm: 1.09\n",
      "step : 1726 | loss: 3.363769054412842 | dt: 165.20 ms | tokens/sec: 37.19 | norm: 1.11\n",
      "step : 1727 | loss: 3.5567989349365234 | dt: 165.54 ms | tokens/sec: 37.11 | norm: 1.15\n",
      "step : 1728 | loss: 3.652519941329956 | dt: 165.57 ms | tokens/sec: 37.11 | norm: 1.96\n",
      "step : 1729 | loss: 3.6034884452819824 | dt: 165.74 ms | tokens/sec: 37.07 | norm: 1.06\n",
      "step : 1730 | loss: 3.483361005783081 | dt: 165.49 ms | tokens/sec: 37.13 | norm: 1.11\n",
      "step : 1731 | loss: 3.7105793952941895 | dt: 164.55 ms | tokens/sec: 37.34 | norm: 1.34\n",
      "step : 1732 | loss: 3.467984914779663 | dt: 164.66 ms | tokens/sec: 37.31 | norm: 1.22\n",
      "step : 1733 | loss: 3.6801486015319824 | dt: 163.91 ms | tokens/sec: 37.48 | norm: 1.68\n",
      "step : 1734 | loss: 3.584987163543701 | dt: 164.58 ms | tokens/sec: 37.33 | norm: 1.46\n",
      "step : 1735 | loss: 3.739011287689209 | dt: 167.21 ms | tokens/sec: 36.74 | norm: 1.27\n",
      "step : 1736 | loss: 3.6197564601898193 | dt: 165.61 ms | tokens/sec: 37.10 | norm: 1.02\n",
      "step : 1737 | loss: 3.4672162532806396 | dt: 165.62 ms | tokens/sec: 37.10 | norm: 1.15\n",
      "step : 1738 | loss: 3.6039257049560547 | dt: 166.21 ms | tokens/sec: 36.97 | norm: 1.29\n",
      "step : 1739 | loss: 3.493576765060425 | dt: 165.31 ms | tokens/sec: 37.17 | norm: 1.23\n",
      "step : 1740 | loss: 3.545041561126709 | dt: 164.97 ms | tokens/sec: 37.24 | norm: 1.27\n",
      "step : 1741 | loss: 3.8228302001953125 | dt: 167.12 ms | tokens/sec: 36.76 | norm: 1.77\n",
      "step : 1742 | loss: 3.7726571559906006 | dt: 165.32 ms | tokens/sec: 37.16 | norm: 1.70\n",
      "step : 1743 | loss: 3.9067320823669434 | dt: 164.41 ms | tokens/sec: 37.37 | norm: 1.34\n",
      "step : 1744 | loss: 3.6666057109832764 | dt: 165.88 ms | tokens/sec: 37.04 | norm: 1.16\n",
      "step : 1745 | loss: 3.6122846603393555 | dt: 164.43 ms | tokens/sec: 37.37 | norm: 1.06\n",
      "step : 1746 | loss: 3.752772808074951 | dt: 165.44 ms | tokens/sec: 37.14 | norm: 1.37\n",
      "step : 1747 | loss: 3.620466947555542 | dt: 166.40 ms | tokens/sec: 36.92 | norm: 1.56\n",
      "step : 1748 | loss: 3.4574098587036133 | dt: 164.87 ms | tokens/sec: 37.27 | norm: 1.47\n",
      "step : 1749 | loss: 3.559110164642334 | dt: 165.84 ms | tokens/sec: 37.05 | norm: 1.47\n",
      "step : 1750 | loss: 3.5628764629364014 | dt: 165.80 ms | tokens/sec: 37.06 | norm: 1.38\n",
      "step : 1751 | loss: 3.3922276496887207 | dt: 165.18 ms | tokens/sec: 37.20 | norm: 1.39\n",
      "step : 1752 | loss: 3.289259433746338 | dt: 165.97 ms | tokens/sec: 37.02 | norm: 2.29\n",
      "step : 1753 | loss: 3.6472702026367188 | dt: 166.62 ms | tokens/sec: 36.87 | norm: 1.16\n",
      "step : 1754 | loss: 3.521892547607422 | dt: 167.51 ms | tokens/sec: 36.68 | norm: 1.28\n",
      "step : 1755 | loss: 3.3536040782928467 | dt: 166.48 ms | tokens/sec: 36.91 | norm: 1.22\n",
      "step : 1756 | loss: 3.3701391220092773 | dt: 166.15 ms | tokens/sec: 36.98 | norm: 1.62\n",
      "step : 1757 | loss: 3.245208740234375 | dt: 164.75 ms | tokens/sec: 37.29 | norm: 1.08\n",
      "step : 1758 | loss: 3.031205177307129 | dt: 165.99 ms | tokens/sec: 37.01 | norm: 1.05\n",
      "step : 1759 | loss: 3.714811325073242 | dt: 166.68 ms | tokens/sec: 36.86 | norm: 1.61\n",
      "step : 1760 | loss: 3.5837466716766357 | dt: 166.08 ms | tokens/sec: 36.99 | norm: 1.71\n",
      "step : 1761 | loss: 3.6535892486572266 | dt: 166.48 ms | tokens/sec: 36.91 | norm: 1.54\n",
      "step : 1762 | loss: 3.6302833557128906 | dt: 167.63 ms | tokens/sec: 36.65 | norm: 1.37\n",
      "step : 1763 | loss: 3.526226758956909 | dt: 165.14 ms | tokens/sec: 37.20 | norm: 1.18\n",
      "step : 1764 | loss: 3.2560157775878906 | dt: 165.69 ms | tokens/sec: 37.08 | norm: 1.12\n",
      "step : 1765 | loss: 3.341956853866577 | dt: 165.87 ms | tokens/sec: 37.04 | norm: 1.41\n",
      "step : 1766 | loss: 3.3490562438964844 | dt: 166.63 ms | tokens/sec: 36.87 | norm: 1.30\n",
      "step : 1767 | loss: 3.5097453594207764 | dt: 165.89 ms | tokens/sec: 37.04 | norm: 1.14\n",
      "step : 1768 | loss: 3.5695273876190186 | dt: 167.26 ms | tokens/sec: 36.73 | norm: 1.34\n",
      "step : 1769 | loss: 3.5770349502563477 | dt: 164.45 ms | tokens/sec: 37.36 | norm: 1.37\n",
      "step : 1770 | loss: 3.4345462322235107 | dt: 166.20 ms | tokens/sec: 36.97 | norm: 1.23\n",
      "step : 1771 | loss: 3.4855871200561523 | dt: 165.33 ms | tokens/sec: 37.16 | norm: 1.18\n",
      "step : 1772 | loss: 3.2949178218841553 | dt: 163.59 ms | tokens/sec: 37.56 | norm: 1.19\n",
      "step : 1773 | loss: 3.516895055770874 | dt: 167.36 ms | tokens/sec: 36.71 | norm: 1.54\n",
      "step : 1774 | loss: 3.3614394664764404 | dt: 164.32 ms | tokens/sec: 37.39 | norm: 1.11\n",
      "step : 1775 | loss: 3.331531047821045 | dt: 164.18 ms | tokens/sec: 37.42 | norm: 1.20\n",
      "step : 1776 | loss: 3.585890769958496 | dt: 165.55 ms | tokens/sec: 37.11 | norm: 1.53\n",
      "step : 1777 | loss: 3.650479316711426 | dt: 165.06 ms | tokens/sec: 37.22 | norm: 1.63\n",
      "step : 1778 | loss: 3.5997848510742188 | dt: 164.92 ms | tokens/sec: 37.25 | norm: 1.52\n",
      "step : 1779 | loss: 3.58290958404541 | dt: 167.07 ms | tokens/sec: 36.78 | norm: 1.58\n",
      "step : 1780 | loss: 3.5779941082000732 | dt: 165.55 ms | tokens/sec: 37.11 | norm: 1.22\n",
      "step : 1781 | loss: 3.3210811614990234 | dt: 164.63 ms | tokens/sec: 37.32 | norm: 1.19\n",
      "step : 1782 | loss: 3.4880805015563965 | dt: 165.24 ms | tokens/sec: 37.18 | norm: 1.20\n",
      "step : 1783 | loss: 3.7024683952331543 | dt: 164.12 ms | tokens/sec: 37.44 | norm: 1.48\n",
      "step : 1784 | loss: 3.5448126792907715 | dt: 164.66 ms | tokens/sec: 37.31 | norm: 1.30\n",
      "step : 1785 | loss: 3.3903894424438477 | dt: 165.88 ms | tokens/sec: 37.04 | norm: 1.46\n",
      "step : 1786 | loss: 3.664365768432617 | dt: 164.10 ms | tokens/sec: 37.44 | norm: 1.29\n",
      "step : 1787 | loss: 3.408700942993164 | dt: 165.92 ms | tokens/sec: 37.03 | norm: 1.17\n",
      "step : 1788 | loss: 3.6676535606384277 | dt: 165.53 ms | tokens/sec: 37.12 | norm: 2.75\n",
      "step : 1789 | loss: 3.5809078216552734 | dt: 164.72 ms | tokens/sec: 37.30 | norm: 1.76\n",
      "step : 1790 | loss: 3.7300028800964355 | dt: 164.64 ms | tokens/sec: 37.32 | norm: 1.55\n",
      "step : 1791 | loss: 3.5802841186523438 | dt: 165.83 ms | tokens/sec: 37.05 | norm: 1.58\n",
      "step : 1792 | loss: 3.399519681930542 | dt: 166.44 ms | tokens/sec: 36.91 | norm: 1.42\n",
      "step : 1793 | loss: 3.5789248943328857 | dt: 165.74 ms | tokens/sec: 37.07 | norm: 1.22\n",
      "step : 1794 | loss: 3.4621481895446777 | dt: 165.23 ms | tokens/sec: 37.19 | norm: 1.21\n",
      "step : 1795 | loss: 3.5241858959198 | dt: 164.90 ms | tokens/sec: 37.26 | norm: 1.20\n",
      "step : 1796 | loss: 3.816525936126709 | dt: 164.77 ms | tokens/sec: 37.29 | norm: 1.62\n",
      "step : 1797 | loss: 3.762025833129883 | dt: 164.16 ms | tokens/sec: 37.43 | norm: 1.46\n",
      "step : 1798 | loss: 3.8963372707366943 | dt: 164.02 ms | tokens/sec: 37.46 | norm: 1.43\n",
      "step : 1799 | loss: 3.6977992057800293 | dt: 165.44 ms | tokens/sec: 37.14 | norm: 1.89\n",
      "step : 1800 | loss: 3.577922821044922 | dt: 165.29 ms | tokens/sec: 37.17 | norm: 1.17\n",
      "step : 1801 | loss: 3.730440855026245 | dt: 165.10 ms | tokens/sec: 37.21 | norm: 1.21\n",
      "step : 1802 | loss: 3.5831260681152344 | dt: 165.79 ms | tokens/sec: 37.06 | norm: 1.27\n",
      "step : 1803 | loss: 3.4106826782226562 | dt: 165.10 ms | tokens/sec: 37.21 | norm: 1.20\n",
      "step : 1804 | loss: 3.4850821495056152 | dt: 166.48 ms | tokens/sec: 36.91 | norm: 1.17\n",
      "step : 1805 | loss: 3.4853827953338623 | dt: 166.43 ms | tokens/sec: 36.92 | norm: 1.32\n",
      "step : 1806 | loss: 3.330688953399658 | dt: 164.29 ms | tokens/sec: 37.40 | norm: 1.24\n",
      "step : 1807 | loss: 3.307103157043457 | dt: 164.08 ms | tokens/sec: 37.44 | norm: 1.15\n",
      "step : 1808 | loss: 3.570000410079956 | dt: 164.49 ms | tokens/sec: 37.35 | norm: 1.29\n",
      "step : 1809 | loss: 3.4496288299560547 | dt: 164.44 ms | tokens/sec: 37.36 | norm: 1.32\n",
      "step : 1810 | loss: 3.301286220550537 | dt: 164.88 ms | tokens/sec: 37.26 | norm: 1.12\n",
      "step : 1811 | loss: 3.3244283199310303 | dt: 166.70 ms | tokens/sec: 36.86 | norm: 1.16\n",
      "step : 1812 | loss: 3.169342041015625 | dt: 164.72 ms | tokens/sec: 37.30 | norm: 1.16\n",
      "step : 1813 | loss: 2.954883575439453 | dt: 166.39 ms | tokens/sec: 36.93 | norm: 1.45\n",
      "step : 1814 | loss: 3.6066691875457764 | dt: 166.33 ms | tokens/sec: 36.94 | norm: 1.53\n",
      "step : 1815 | loss: 3.5378775596618652 | dt: 164.67 ms | tokens/sec: 37.31 | norm: 1.41\n",
      "step : 1816 | loss: 3.6185431480407715 | dt: 165.36 ms | tokens/sec: 37.16 | norm: 1.29\n",
      "step : 1817 | loss: 3.536187171936035 | dt: 167.76 ms | tokens/sec: 36.62 | norm: 1.38\n",
      "step : 1818 | loss: 3.461212158203125 | dt: 164.78 ms | tokens/sec: 37.29 | norm: 1.32\n",
      "step : 1819 | loss: 3.1853036880493164 | dt: 166.25 ms | tokens/sec: 36.96 | norm: 1.25\n",
      "step : 1820 | loss: 3.315877914428711 | dt: 164.40 ms | tokens/sec: 37.37 | norm: 1.07\n",
      "step : 1821 | loss: 3.255983829498291 | dt: 164.04 ms | tokens/sec: 37.45 | norm: 1.20\n",
      "step : 1822 | loss: 3.4381184577941895 | dt: 164.17 ms | tokens/sec: 37.43 | norm: 1.23\n",
      "step : 1823 | loss: 3.499070644378662 | dt: 164.90 ms | tokens/sec: 37.26 | norm: 1.22\n",
      "step : 1824 | loss: 3.5048842430114746 | dt: 164.62 ms | tokens/sec: 37.32 | norm: 1.77\n",
      "step : 1825 | loss: 3.423588752746582 | dt: 166.35 ms | tokens/sec: 36.93 | norm: 1.44\n",
      "step : 1826 | loss: 3.4528822898864746 | dt: 165.07 ms | tokens/sec: 37.22 | norm: 1.43\n",
      "step : 1827 | loss: 3.2521121501922607 | dt: 164.54 ms | tokens/sec: 37.34 | norm: 1.18\n",
      "step : 1828 | loss: 3.4806079864501953 | dt: 165.91 ms | tokens/sec: 37.03 | norm: 1.25\n",
      "step : 1829 | loss: 3.302711009979248 | dt: 167.54 ms | tokens/sec: 36.67 | norm: 1.33\n",
      "step : 1830 | loss: 3.255469799041748 | dt: 165.17 ms | tokens/sec: 37.20 | norm: 1.54\n",
      "step : 1831 | loss: 3.5302658081054688 | dt: 167.02 ms | tokens/sec: 36.79 | norm: 1.53\n",
      "step : 1832 | loss: 3.612858533859253 | dt: 164.24 ms | tokens/sec: 37.41 | norm: 1.55\n",
      "step : 1833 | loss: 3.550452709197998 | dt: 163.85 ms | tokens/sec: 37.50 | norm: 1.63\n",
      "step : 1834 | loss: 3.5726046562194824 | dt: 164.40 ms | tokens/sec: 37.37 | norm: 1.58\n",
      "step : 1835 | loss: 3.5079421997070312 | dt: 163.87 ms | tokens/sec: 37.49 | norm: 1.64\n",
      "step : 1836 | loss: 3.2690372467041016 | dt: 165.48 ms | tokens/sec: 37.13 | norm: 1.30\n",
      "step : 1837 | loss: 3.4231719970703125 | dt: 165.50 ms | tokens/sec: 37.12 | norm: 1.54\n",
      "step : 1838 | loss: 3.645477294921875 | dt: 165.33 ms | tokens/sec: 37.16 | norm: 1.53\n",
      "step : 1839 | loss: 3.5413851737976074 | dt: 166.42 ms | tokens/sec: 36.92 | norm: 1.95\n",
      "step : 1840 | loss: 3.398263454437256 | dt: 166.08 ms | tokens/sec: 36.99 | norm: 1.44\n",
      "step : 1841 | loss: 3.585087299346924 | dt: 164.97 ms | tokens/sec: 37.24 | norm: 1.38\n",
      "step : 1842 | loss: 3.3658511638641357 | dt: 166.31 ms | tokens/sec: 36.94 | norm: 1.16\n",
      "step : 1843 | loss: 3.7008256912231445 | dt: 165.52 ms | tokens/sec: 37.12 | norm: 2.00\n",
      "step : 1844 | loss: 3.537480115890503 | dt: 163.73 ms | tokens/sec: 37.53 | norm: 1.45\n",
      "step : 1845 | loss: 3.6698975563049316 | dt: 166.27 ms | tokens/sec: 36.95 | norm: 1.61\n",
      "step : 1846 | loss: 3.5325582027435303 | dt: 165.03 ms | tokens/sec: 37.23 | norm: 1.30\n",
      "step : 1847 | loss: 3.383638381958008 | dt: 163.67 ms | tokens/sec: 37.54 | norm: 1.56\n",
      "step : 1848 | loss: 3.522304058074951 | dt: 166.03 ms | tokens/sec: 37.00 | norm: 1.54\n",
      "step : 1849 | loss: 3.4140448570251465 | dt: 164.64 ms | tokens/sec: 37.32 | norm: 1.50\n",
      "step : 1850 | loss: 3.44946551322937 | dt: 164.43 ms | tokens/sec: 37.37 | norm: 1.20\n",
      "step : 1851 | loss: 3.7486112117767334 | dt: 166.70 ms | tokens/sec: 36.86 | norm: 1.49\n",
      "step : 1852 | loss: 3.7115278244018555 | dt: 165.02 ms | tokens/sec: 37.23 | norm: 1.66\n",
      "step : 1853 | loss: 3.8221583366394043 | dt: 164.80 ms | tokens/sec: 37.28 | norm: 1.70\n",
      "step : 1854 | loss: 3.6624155044555664 | dt: 165.39 ms | tokens/sec: 37.15 | norm: 1.66\n",
      "step : 1855 | loss: 3.504185438156128 | dt: 165.12 ms | tokens/sec: 37.21 | norm: 1.25\n",
      "step : 1856 | loss: 3.6485438346862793 | dt: 163.94 ms | tokens/sec: 37.48 | norm: 1.17\n",
      "step : 1857 | loss: 3.490912914276123 | dt: 164.31 ms | tokens/sec: 37.39 | norm: 1.27\n",
      "step : 1858 | loss: 3.3019702434539795 | dt: 163.98 ms | tokens/sec: 37.47 | norm: 1.45\n",
      "step : 1859 | loss: 3.3738887310028076 | dt: 165.86 ms | tokens/sec: 37.04 | norm: 1.09\n",
      "step : 1860 | loss: 3.4233999252319336 | dt: 165.35 ms | tokens/sec: 37.16 | norm: 1.46\n",
      "step : 1861 | loss: 3.289130687713623 | dt: 165.75 ms | tokens/sec: 37.07 | norm: 1.72\n",
      "step : 1862 | loss: 3.218233585357666 | dt: 165.23 ms | tokens/sec: 37.18 | norm: 1.25\n",
      "step : 1863 | loss: 3.5060012340545654 | dt: 165.56 ms | tokens/sec: 37.11 | norm: 1.66\n",
      "step : 1864 | loss: 3.391159772872925 | dt: 164.62 ms | tokens/sec: 37.32 | norm: 2.42\n",
      "step : 1865 | loss: 3.2353219985961914 | dt: 166.02 ms | tokens/sec: 37.01 | norm: 1.22\n",
      "step : 1866 | loss: 3.2451331615448 | dt: 164.95 ms | tokens/sec: 37.25 | norm: 1.31\n",
      "step : 1867 | loss: 3.1159377098083496 | dt: 166.01 ms | tokens/sec: 37.01 | norm: 1.31\n",
      "step : 1868 | loss: 2.91005277633667 | dt: 166.36 ms | tokens/sec: 36.93 | norm: 1.11\n",
      "step : 1869 | loss: 3.552863597869873 | dt: 164.38 ms | tokens/sec: 37.38 | norm: 1.76\n",
      "step : 1870 | loss: 3.4513916969299316 | dt: 163.73 ms | tokens/sec: 37.52 | norm: 1.34\n",
      "step : 1871 | loss: 3.4988391399383545 | dt: 165.40 ms | tokens/sec: 37.15 | norm: 1.35\n",
      "step : 1872 | loss: 3.481907844543457 | dt: 164.57 ms | tokens/sec: 37.33 | norm: 1.32\n",
      "step : 1873 | loss: 3.3969104290008545 | dt: 165.04 ms | tokens/sec: 37.23 | norm: 1.48\n",
      "step : 1874 | loss: 3.148191452026367 | dt: 166.22 ms | tokens/sec: 36.96 | norm: 1.53\n",
      "step : 1875 | loss: 3.242633581161499 | dt: 165.20 ms | tokens/sec: 37.19 | norm: 1.44\n",
      "step : 1876 | loss: 3.2286880016326904 | dt: 164.86 ms | tokens/sec: 37.27 | norm: 1.81\n",
      "step : 1877 | loss: 3.3761019706726074 | dt: 166.46 ms | tokens/sec: 36.91 | norm: 1.57\n",
      "step : 1878 | loss: 3.416402816772461 | dt: 164.49 ms | tokens/sec: 37.35 | norm: 1.20\n",
      "step : 1879 | loss: 3.4251480102539062 | dt: 164.34 ms | tokens/sec: 37.39 | norm: 1.51\n",
      "step : 1880 | loss: 3.306600570678711 | dt: 167.93 ms | tokens/sec: 36.59 | norm: 1.57\n",
      "step : 1881 | loss: 3.350919246673584 | dt: 163.78 ms | tokens/sec: 37.51 | norm: 1.14\n",
      "step : 1882 | loss: 3.1613128185272217 | dt: 164.66 ms | tokens/sec: 37.31 | norm: 1.13\n",
      "step : 1883 | loss: 3.3621273040771484 | dt: 164.77 ms | tokens/sec: 37.29 | norm: 1.08\n",
      "step : 1884 | loss: 3.2270941734313965 | dt: 165.61 ms | tokens/sec: 37.10 | norm: 1.44\n",
      "step : 1885 | loss: 3.189547300338745 | dt: 167.10 ms | tokens/sec: 36.77 | norm: 1.31\n",
      "step : 1886 | loss: 3.4489505290985107 | dt: 166.67 ms | tokens/sec: 36.86 | norm: 1.44\n",
      "step : 1887 | loss: 3.518170118331909 | dt: 165.27 ms | tokens/sec: 37.17 | norm: 1.43\n",
      "step : 1888 | loss: 3.476868152618408 | dt: 165.37 ms | tokens/sec: 37.15 | norm: 1.25\n",
      "step : 1889 | loss: 3.497365951538086 | dt: 167.09 ms | tokens/sec: 36.77 | norm: 1.46\n",
      "step : 1890 | loss: 3.4809823036193848 | dt: 165.52 ms | tokens/sec: 37.12 | norm: 1.31\n",
      "step : 1891 | loss: 3.203630208969116 | dt: 166.38 ms | tokens/sec: 36.93 | norm: 1.18\n",
      "step : 1892 | loss: 3.340099811553955 | dt: 166.89 ms | tokens/sec: 36.82 | norm: 1.23\n",
      "step : 1893 | loss: 3.522937297821045 | dt: 165.65 ms | tokens/sec: 37.09 | norm: 1.24\n",
      "step : 1894 | loss: 3.463376998901367 | dt: 165.11 ms | tokens/sec: 37.21 | norm: 1.24\n",
      "step : 1895 | loss: 3.2902536392211914 | dt: 165.63 ms | tokens/sec: 37.09 | norm: 1.26\n",
      "step : 1896 | loss: 3.4549560546875 | dt: 164.19 ms | tokens/sec: 37.42 | norm: 1.17\n",
      "step : 1897 | loss: 3.249375343322754 | dt: 166.70 ms | tokens/sec: 36.86 | norm: 1.09\n",
      "step : 1898 | loss: 3.5716915130615234 | dt: 165.00 ms | tokens/sec: 37.24 | norm: 1.36\n",
      "step : 1899 | loss: 3.426393985748291 | dt: 164.14 ms | tokens/sec: 37.43 | norm: 1.46\n",
      "step : 1900 | loss: 3.5798652172088623 | dt: 165.35 ms | tokens/sec: 37.16 | norm: 1.52\n",
      "step : 1901 | loss: 3.407651901245117 | dt: 163.75 ms | tokens/sec: 37.52 | norm: 1.39\n",
      "step : 1902 | loss: 3.282897472381592 | dt: 165.05 ms | tokens/sec: 37.23 | norm: 1.27\n",
      "step : 1903 | loss: 3.4502322673797607 | dt: 166.72 ms | tokens/sec: 36.85 | norm: 1.44\n",
      "step : 1904 | loss: 3.369657516479492 | dt: 164.96 ms | tokens/sec: 37.25 | norm: 1.42\n",
      "step : 1905 | loss: 3.40108060836792 | dt: 165.75 ms | tokens/sec: 37.07 | norm: 1.66\n",
      "step : 1906 | loss: 3.670518398284912 | dt: 165.65 ms | tokens/sec: 37.09 | norm: 1.79\n",
      "step : 1907 | loss: 3.669421672821045 | dt: 164.73 ms | tokens/sec: 37.30 | norm: 1.59\n",
      "step : 1908 | loss: 3.731470823287964 | dt: 163.64 ms | tokens/sec: 37.55 | norm: 1.25\n",
      "step : 1909 | loss: 3.5990867614746094 | dt: 166.34 ms | tokens/sec: 36.94 | norm: 1.58\n",
      "step : 1910 | loss: 3.466047763824463 | dt: 162.95 ms | tokens/sec: 37.71 | norm: 1.38\n",
      "step : 1911 | loss: 3.5805280208587646 | dt: 165.01 ms | tokens/sec: 37.23 | norm: 1.40\n",
      "step : 1912 | loss: 3.415829658508301 | dt: 166.36 ms | tokens/sec: 36.93 | norm: 1.37\n",
      "step : 1913 | loss: 3.2568719387054443 | dt: 164.41 ms | tokens/sec: 37.37 | norm: 1.35\n",
      "step : 1914 | loss: 3.3148136138916016 | dt: 164.78 ms | tokens/sec: 37.29 | norm: 1.39\n",
      "step : 1915 | loss: 3.385737895965576 | dt: 165.00 ms | tokens/sec: 37.24 | norm: 1.30\n",
      "step : 1916 | loss: 3.2813708782196045 | dt: 164.35 ms | tokens/sec: 37.38 | norm: 1.45\n",
      "step : 1917 | loss: 3.185896873474121 | dt: 165.95 ms | tokens/sec: 37.02 | norm: 1.42\n",
      "step : 1918 | loss: 3.509638786315918 | dt: 165.68 ms | tokens/sec: 37.08 | norm: 1.65\n",
      "step : 1919 | loss: 3.4624648094177246 | dt: 163.72 ms | tokens/sec: 37.53 | norm: 1.79\n",
      "step : 1920 | loss: 3.1933560371398926 | dt: 164.62 ms | tokens/sec: 37.32 | norm: 1.29\n",
      "step : 1921 | loss: 3.1979598999023438 | dt: 163.81 ms | tokens/sec: 37.51 | norm: 1.34\n",
      "step : 1922 | loss: 3.082878589630127 | dt: 164.50 ms | tokens/sec: 37.35 | norm: 1.94\n",
      "step : 1923 | loss: 2.865396499633789 | dt: 166.76 ms | tokens/sec: 36.84 | norm: 1.45\n",
      "step : 1924 | loss: 3.5008888244628906 | dt: 165.84 ms | tokens/sec: 37.05 | norm: 1.32\n",
      "step : 1925 | loss: 3.357196807861328 | dt: 164.48 ms | tokens/sec: 37.35 | norm: 1.54\n",
      "step : 1926 | loss: 3.4405579566955566 | dt: 165.47 ms | tokens/sec: 37.13 | norm: 1.26\n",
      "step : 1927 | loss: 3.402848243713379 | dt: 164.69 ms | tokens/sec: 37.31 | norm: 1.34\n",
      "step : 1928 | loss: 3.342416763305664 | dt: 163.72 ms | tokens/sec: 37.53 | norm: 1.30\n",
      "step : 1929 | loss: 3.1029860973358154 | dt: 166.58 ms | tokens/sec: 36.88 | norm: 1.45\n",
      "step : 1930 | loss: 3.2011191844940186 | dt: 162.99 ms | tokens/sec: 37.70 | norm: 1.16\n",
      "step : 1931 | loss: 3.196495771408081 | dt: 165.50 ms | tokens/sec: 37.12 | norm: 1.22\n",
      "step : 1932 | loss: 3.353536605834961 | dt: 164.61 ms | tokens/sec: 37.32 | norm: 1.20\n",
      "step : 1933 | loss: 3.3300833702087402 | dt: 164.53 ms | tokens/sec: 37.34 | norm: 1.39\n",
      "step : 1934 | loss: 3.3229167461395264 | dt: 164.96 ms | tokens/sec: 37.25 | norm: 1.27\n",
      "step : 1935 | loss: 3.235595703125 | dt: 165.38 ms | tokens/sec: 37.15 | norm: 1.08\n",
      "step : 1936 | loss: 3.23285174369812 | dt: 164.53 ms | tokens/sec: 37.34 | norm: 1.41\n",
      "step : 1937 | loss: 3.0662670135498047 | dt: 166.45 ms | tokens/sec: 36.91 | norm: 1.11\n",
      "step : 1938 | loss: 3.2651243209838867 | dt: 164.97 ms | tokens/sec: 37.24 | norm: 1.06\n",
      "step : 1939 | loss: 3.149428129196167 | dt: 164.09 ms | tokens/sec: 37.44 | norm: 1.13\n",
      "step : 1940 | loss: 3.1117873191833496 | dt: 164.44 ms | tokens/sec: 37.36 | norm: 1.20\n",
      "step : 1941 | loss: 3.3566513061523438 | dt: 163.73 ms | tokens/sec: 37.52 | norm: 1.23\n",
      "step : 1942 | loss: 3.407482862472534 | dt: 165.08 ms | tokens/sec: 37.22 | norm: 1.26\n",
      "step : 1943 | loss: 3.3647093772888184 | dt: 167.24 ms | tokens/sec: 36.74 | norm: 1.23\n",
      "step : 1944 | loss: 3.373764753341675 | dt: 165.52 ms | tokens/sec: 37.12 | norm: 1.14\n",
      "step : 1945 | loss: 3.363690137863159 | dt: 165.12 ms | tokens/sec: 37.21 | norm: 1.30\n",
      "step : 1946 | loss: 3.1200413703918457 | dt: 166.39 ms | tokens/sec: 36.92 | norm: 1.26\n",
      "step : 1947 | loss: 3.28865909576416 | dt: 165.83 ms | tokens/sec: 37.05 | norm: 1.18\n",
      "step : 1948 | loss: 3.4217300415039062 | dt: 165.43 ms | tokens/sec: 37.14 | norm: 1.25\n",
      "step : 1949 | loss: 3.3355491161346436 | dt: 167.86 ms | tokens/sec: 36.60 | norm: 1.28\n",
      "step : 1950 | loss: 3.2212724685668945 | dt: 166.45 ms | tokens/sec: 36.91 | norm: 1.07\n",
      "step : 1951 | loss: 3.3558435440063477 | dt: 164.66 ms | tokens/sec: 37.31 | norm: 1.15\n",
      "step : 1952 | loss: 3.174980640411377 | dt: 166.42 ms | tokens/sec: 36.92 | norm: 1.05\n",
      "step : 1953 | loss: 3.4609203338623047 | dt: 164.73 ms | tokens/sec: 37.30 | norm: 1.34\n",
      "step : 1954 | loss: 3.3020901679992676 | dt: 165.57 ms | tokens/sec: 37.11 | norm: 1.19\n",
      "step : 1955 | loss: 3.4833202362060547 | dt: 166.82 ms | tokens/sec: 36.83 | norm: 1.21\n",
      "step : 1956 | loss: 3.3434276580810547 | dt: 165.52 ms | tokens/sec: 37.12 | norm: 1.23\n",
      "step : 1957 | loss: 3.1872763633728027 | dt: 163.96 ms | tokens/sec: 37.47 | norm: 1.30\n",
      "step : 1958 | loss: 3.3661670684814453 | dt: 163.68 ms | tokens/sec: 37.54 | norm: 1.40\n",
      "step : 1959 | loss: 3.278201103210449 | dt: 164.38 ms | tokens/sec: 37.38 | norm: 1.12\n",
      "step : 1960 | loss: 3.357452869415283 | dt: 165.10 ms | tokens/sec: 37.21 | norm: 1.44\n",
      "step : 1961 | loss: 3.7173774242401123 | dt: 166.32 ms | tokens/sec: 36.94 | norm: 1.84\n",
      "step : 1962 | loss: 3.669111728668213 | dt: 166.63 ms | tokens/sec: 36.87 | norm: 1.71\n",
      "step : 1963 | loss: 3.686563491821289 | dt: 166.08 ms | tokens/sec: 36.99 | norm: 1.52\n",
      "step : 1964 | loss: 3.5514678955078125 | dt: 165.66 ms | tokens/sec: 37.09 | norm: 1.29\n",
      "step : 1965 | loss: 3.411283016204834 | dt: 164.72 ms | tokens/sec: 37.30 | norm: 1.42\n",
      "step : 1966 | loss: 3.5370423793792725 | dt: 164.75 ms | tokens/sec: 37.29 | norm: 1.53\n",
      "step : 1967 | loss: 3.3625762462615967 | dt: 164.75 ms | tokens/sec: 37.29 | norm: 1.44\n",
      "step : 1968 | loss: 3.2180685997009277 | dt: 163.08 ms | tokens/sec: 37.68 | norm: 1.42\n",
      "step : 1969 | loss: 3.2683768272399902 | dt: 166.82 ms | tokens/sec: 36.83 | norm: 1.16\n",
      "step : 1970 | loss: 3.266218900680542 | dt: 163.51 ms | tokens/sec: 37.57 | norm: 1.24\n",
      "step : 1971 | loss: 3.1896491050720215 | dt: 165.14 ms | tokens/sec: 37.21 | norm: 1.25\n",
      "step : 1972 | loss: 3.1143903732299805 | dt: 165.33 ms | tokens/sec: 37.16 | norm: 1.23\n",
      "step : 1973 | loss: 3.4131133556365967 | dt: 164.67 ms | tokens/sec: 37.31 | norm: 1.28\n",
      "step : 1974 | loss: 3.4116532802581787 | dt: 164.75 ms | tokens/sec: 37.29 | norm: 2.00\n",
      "step : 1975 | loss: 3.154031276702881 | dt: 168.82 ms | tokens/sec: 36.39 | norm: 1.53\n",
      "step : 1976 | loss: 3.144014358520508 | dt: 165.13 ms | tokens/sec: 37.21 | norm: 1.67\n",
      "step : 1977 | loss: 3.0953900814056396 | dt: 164.69 ms | tokens/sec: 37.31 | norm: 1.97\n",
      "step : 1978 | loss: 2.8354544639587402 | dt: 166.49 ms | tokens/sec: 36.90 | norm: 1.17\n",
      "step : 1979 | loss: 3.446741819381714 | dt: 164.03 ms | tokens/sec: 37.46 | norm: 1.43\n",
      "step : 1980 | loss: 3.3080596923828125 | dt: 163.58 ms | tokens/sec: 37.56 | norm: 1.44\n",
      "step : 1981 | loss: 3.3910136222839355 | dt: 165.93 ms | tokens/sec: 37.03 | norm: 1.82\n",
      "step : 1982 | loss: 3.35770845413208 | dt: 163.94 ms | tokens/sec: 37.48 | norm: 1.60\n",
      "step : 1983 | loss: 3.307330846786499 | dt: 166.38 ms | tokens/sec: 36.93 | norm: 1.33\n",
      "step : 1984 | loss: 3.095125913619995 | dt: 165.24 ms | tokens/sec: 37.18 | norm: 1.41\n",
      "step : 1985 | loss: 3.1391706466674805 | dt: 164.52 ms | tokens/sec: 37.34 | norm: 1.17\n",
      "step : 1986 | loss: 3.115509033203125 | dt: 165.87 ms | tokens/sec: 37.04 | norm: 1.29\n",
      "step : 1987 | loss: 3.290780544281006 | dt: 165.95 ms | tokens/sec: 37.02 | norm: 1.60\n",
      "step : 1988 | loss: 3.3593974113464355 | dt: 165.33 ms | tokens/sec: 37.16 | norm: 1.51\n",
      "step : 1989 | loss: 3.395203113555908 | dt: 166.78 ms | tokens/sec: 36.84 | norm: 1.66\n",
      "step : 1990 | loss: 3.2815749645233154 | dt: 165.94 ms | tokens/sec: 37.02 | norm: 1.75\n",
      "step : 1991 | loss: 3.3672327995300293 | dt: 163.98 ms | tokens/sec: 37.47 | norm: 1.61\n",
      "step : 1992 | loss: 3.1211161613464355 | dt: 165.25 ms | tokens/sec: 37.18 | norm: 2.33\n",
      "step : 1993 | loss: 3.2733371257781982 | dt: 164.11 ms | tokens/sec: 37.44 | norm: 1.48\n",
      "step : 1994 | loss: 3.1482391357421875 | dt: 165.87 ms | tokens/sec: 37.04 | norm: 1.44\n",
      "step : 1995 | loss: 3.0818259716033936 | dt: 166.07 ms | tokens/sec: 37.00 | norm: 1.33\n",
      "step : 1996 | loss: 3.29931640625 | dt: 164.47 ms | tokens/sec: 37.36 | norm: 1.45\n",
      "step : 1997 | loss: 3.370419979095459 | dt: 164.83 ms | tokens/sec: 37.27 | norm: 1.38\n",
      "step : 1998 | loss: 3.3481082916259766 | dt: 166.48 ms | tokens/sec: 36.91 | norm: 1.39\n",
      "step : 1999 | loss: 3.362159490585327 | dt: 165.56 ms | tokens/sec: 37.11 | norm: 1.62\n",
      "step : 2000 | loss: 3.363351345062256 | dt: 165.60 ms | tokens/sec: 37.10 | norm: 1.35\n",
      "step : 2001 | loss: 3.088662624359131 | dt: 166.88 ms | tokens/sec: 36.82 | norm: 1.43\n",
      "step : 2002 | loss: 3.266176223754883 | dt: 166.45 ms | tokens/sec: 36.91 | norm: 1.25\n",
      "step : 2003 | loss: 3.416898250579834 | dt: 164.98 ms | tokens/sec: 37.24 | norm: 1.36\n",
      "step : 2004 | loss: 3.3723819255828857 | dt: 165.48 ms | tokens/sec: 37.13 | norm: 1.43\n",
      "step : 2005 | loss: 3.2283589839935303 | dt: 164.33 ms | tokens/sec: 37.39 | norm: 1.23\n",
      "step : 2006 | loss: 3.3310699462890625 | dt: 165.50 ms | tokens/sec: 37.12 | norm: 1.22\n",
      "step : 2007 | loss: 3.169708251953125 | dt: 165.16 ms | tokens/sec: 37.20 | norm: 1.23\n",
      "step : 2008 | loss: 3.4140031337738037 | dt: 163.07 ms | tokens/sec: 37.68 | norm: 1.27\n",
      "step : 2009 | loss: 3.2954463958740234 | dt: 164.11 ms | tokens/sec: 37.44 | norm: 1.43\n",
      "step : 2010 | loss: 3.440129041671753 | dt: 165.01 ms | tokens/sec: 37.23 | norm: 1.27\n",
      "step : 2011 | loss: 3.2997183799743652 | dt: 164.22 ms | tokens/sec: 37.41 | norm: 1.21\n",
      "step : 2012 | loss: 3.1339211463928223 | dt: 164.67 ms | tokens/sec: 37.31 | norm: 1.16\n",
      "step : 2013 | loss: 3.339022397994995 | dt: 166.46 ms | tokens/sec: 36.91 | norm: 1.32\n",
      "step : 2014 | loss: 3.2052993774414062 | dt: 163.69 ms | tokens/sec: 37.53 | norm: 1.32\n",
      "step : 2015 | loss: 3.3351237773895264 | dt: 167.03 ms | tokens/sec: 36.78 | norm: 1.83\n",
      "step : 2016 | loss: 3.6783664226531982 | dt: 164.05 ms | tokens/sec: 37.45 | norm: 1.64\n",
      "step : 2017 | loss: 3.690875768661499 | dt: 164.48 ms | tokens/sec: 37.35 | norm: 1.83\n",
      "step : 2018 | loss: 3.6945996284484863 | dt: 163.80 ms | tokens/sec: 37.51 | norm: 1.45\n",
      "step : 2019 | loss: 3.5305795669555664 | dt: 165.49 ms | tokens/sec: 37.13 | norm: 1.50\n",
      "step : 2020 | loss: 3.412757396697998 | dt: 165.55 ms | tokens/sec: 37.11 | norm: 1.32\n",
      "step : 2021 | loss: 3.5666608810424805 | dt: 166.00 ms | tokens/sec: 37.01 | norm: 1.87\n",
      "step : 2022 | loss: 3.3924331665039062 | dt: 165.06 ms | tokens/sec: 37.22 | norm: 1.44\n",
      "step : 2023 | loss: 3.228062629699707 | dt: 164.94 ms | tokens/sec: 37.25 | norm: 1.48\n",
      "step : 2024 | loss: 3.265371799468994 | dt: 165.36 ms | tokens/sec: 37.16 | norm: 1.64\n",
      "step : 2025 | loss: 3.260061264038086 | dt: 167.52 ms | tokens/sec: 36.68 | norm: 1.59\n",
      "step : 2026 | loss: 3.138378143310547 | dt: 164.00 ms | tokens/sec: 37.46 | norm: 1.45\n",
      "step : 2027 | loss: 3.0825424194335938 | dt: 166.33 ms | tokens/sec: 36.94 | norm: 1.32\n",
      "step : 2028 | loss: 3.377681255340576 | dt: 163.70 ms | tokens/sec: 37.53 | norm: 1.31\n",
      "step : 2029 | loss: 3.3917198181152344 | dt: 164.93 ms | tokens/sec: 37.25 | norm: 1.82\n",
      "step : 2030 | loss: 3.135608673095703 | dt: 163.77 ms | tokens/sec: 37.52 | norm: 1.65\n",
      "step : 2031 | loss: 3.1647849082946777 | dt: 164.80 ms | tokens/sec: 37.28 | norm: 1.57\n",
      "step : 2032 | loss: 3.1110358238220215 | dt: 165.97 ms | tokens/sec: 37.02 | norm: 1.73\n",
      "step : 2033 | loss: 2.784120559692383 | dt: 164.89 ms | tokens/sec: 37.26 | norm: 1.25\n",
      "step : 2034 | loss: 3.385392904281616 | dt: 164.39 ms | tokens/sec: 37.37 | norm: 1.38\n",
      "step : 2035 | loss: 3.2383811473846436 | dt: 166.78 ms | tokens/sec: 36.84 | norm: 1.28\n",
      "step : 2036 | loss: 3.4482474327087402 | dt: 166.45 ms | tokens/sec: 36.91 | norm: 1.89\n",
      "step : 2037 | loss: 3.3582191467285156 | dt: 166.36 ms | tokens/sec: 36.93 | norm: 1.52\n",
      "step : 2038 | loss: 3.2931880950927734 | dt: 167.18 ms | tokens/sec: 36.75 | norm: 1.43\n",
      "step : 2039 | loss: 3.0481667518615723 | dt: 165.85 ms | tokens/sec: 37.05 | norm: 1.27\n",
      "step : 2040 | loss: 3.1010043621063232 | dt: 166.61 ms | tokens/sec: 36.88 | norm: 1.40\n",
      "step : 2041 | loss: 3.0844249725341797 | dt: 166.63 ms | tokens/sec: 36.87 | norm: 1.33\n",
      "step : 2042 | loss: 3.293442487716675 | dt: 166.68 ms | tokens/sec: 36.86 | norm: 1.30\n",
      "step : 2043 | loss: 3.308709144592285 | dt: 166.69 ms | tokens/sec: 36.86 | norm: 1.53\n",
      "step : 2044 | loss: 3.3188271522521973 | dt: 167.52 ms | tokens/sec: 36.68 | norm: 1.58\n",
      "step : 2045 | loss: 3.241422176361084 | dt: 166.06 ms | tokens/sec: 37.00 | norm: 1.43\n",
      "step : 2046 | loss: 3.3013834953308105 | dt: 166.70 ms | tokens/sec: 36.86 | norm: 1.37\n",
      "step : 2047 | loss: 3.115055799484253 | dt: 166.48 ms | tokens/sec: 36.90 | norm: 1.61\n",
      "step : 2048 | loss: 3.226001739501953 | dt: 166.50 ms | tokens/sec: 36.90 | norm: 1.43\n",
      "step : 2049 | loss: 3.1459643840789795 | dt: 166.28 ms | tokens/sec: 36.95 | norm: 1.77\n",
      "step : 2050 | loss: 3.046782970428467 | dt: 166.37 ms | tokens/sec: 36.93 | norm: 1.47\n",
      "step : 2051 | loss: 3.2704391479492188 | dt: 166.29 ms | tokens/sec: 36.95 | norm: 1.51\n",
      "step : 2052 | loss: 3.3102540969848633 | dt: 166.81 ms | tokens/sec: 36.83 | norm: 1.47\n",
      "step : 2053 | loss: 3.2960734367370605 | dt: 166.66 ms | tokens/sec: 36.87 | norm: 1.62\n",
      "step : 2054 | loss: 3.3479745388031006 | dt: 166.87 ms | tokens/sec: 36.82 | norm: 1.56\n",
      "step : 2055 | loss: 3.3187339305877686 | dt: 166.60 ms | tokens/sec: 36.88 | norm: 1.51\n",
      "step : 2056 | loss: 3.0842223167419434 | dt: 166.59 ms | tokens/sec: 36.88 | norm: 1.40\n",
      "step : 2057 | loss: 3.1951892375946045 | dt: 168.03 ms | tokens/sec: 36.56 | norm: 1.46\n",
      "step : 2058 | loss: 3.339961528778076 | dt: 165.95 ms | tokens/sec: 37.02 | norm: 1.40\n",
      "step : 2059 | loss: 3.327284812927246 | dt: 166.77 ms | tokens/sec: 36.84 | norm: 1.68\n",
      "step : 2060 | loss: 3.167665481567383 | dt: 166.63 ms | tokens/sec: 36.87 | norm: 1.39\n",
      "step : 2061 | loss: 3.29705810546875 | dt: 166.74 ms | tokens/sec: 36.85 | norm: 1.65\n",
      "step : 2062 | loss: 3.140249013900757 | dt: 166.65 ms | tokens/sec: 36.87 | norm: 1.28\n",
      "step : 2063 | loss: 3.3358399868011475 | dt: 168.49 ms | tokens/sec: 36.46 | norm: 1.41\n",
      "step : 2064 | loss: 3.260575771331787 | dt: 168.68 ms | tokens/sec: 36.42 | norm: 1.56\n",
      "step : 2065 | loss: 3.4027953147888184 | dt: 170.52 ms | tokens/sec: 36.03 | norm: 1.73\n",
      "step : 2066 | loss: 3.2703208923339844 | dt: 169.25 ms | tokens/sec: 36.30 | norm: 1.39\n",
      "step : 2067 | loss: 3.105069875717163 | dt: 170.11 ms | tokens/sec: 36.12 | norm: 1.30\n",
      "step : 2068 | loss: 3.272254467010498 | dt: 169.66 ms | tokens/sec: 36.21 | norm: 1.52\n",
      "step : 2069 | loss: 3.1536383628845215 | dt: 169.68 ms | tokens/sec: 36.21 | norm: 1.30\n",
      "step : 2070 | loss: 3.2951438426971436 | dt: 168.74 ms | tokens/sec: 36.41 | norm: 1.44\n",
      "step : 2071 | loss: 3.5467822551727295 | dt: 169.00 ms | tokens/sec: 36.35 | norm: 1.69\n",
      "step : 2072 | loss: 3.572408676147461 | dt: 168.73 ms | tokens/sec: 36.41 | norm: 1.78\n",
      "step : 2073 | loss: 3.598642349243164 | dt: 169.62 ms | tokens/sec: 36.22 | norm: 1.61\n",
      "step : 2074 | loss: 3.4178004264831543 | dt: 169.63 ms | tokens/sec: 36.22 | norm: 1.90\n",
      "step : 2075 | loss: 3.2942121028900146 | dt: 170.69 ms | tokens/sec: 36.00 | norm: 1.45\n",
      "step : 2076 | loss: 3.486130475997925 | dt: 168.51 ms | tokens/sec: 36.46 | norm: 1.34\n",
      "step : 2077 | loss: 3.287230968475342 | dt: 169.39 ms | tokens/sec: 36.27 | norm: 1.29\n",
      "step : 2078 | loss: 3.1538302898406982 | dt: 168.73 ms | tokens/sec: 36.41 | norm: 1.64\n",
      "step : 2079 | loss: 3.23321533203125 | dt: 170.55 ms | tokens/sec: 36.02 | norm: 1.40\n",
      "step : 2080 | loss: 3.2068514823913574 | dt: 169.88 ms | tokens/sec: 36.17 | norm: 1.42\n",
      "step : 2081 | loss: 3.093787908554077 | dt: 169.25 ms | tokens/sec: 36.30 | norm: 1.42\n",
      "step : 2082 | loss: 3.0346076488494873 | dt: 169.11 ms | tokens/sec: 36.33 | norm: 1.53\n",
      "step : 2083 | loss: 3.326082944869995 | dt: 169.75 ms | tokens/sec: 36.19 | norm: 1.54\n",
      "step : 2084 | loss: 3.306051731109619 | dt: 169.72 ms | tokens/sec: 36.20 | norm: 1.99\n",
      "step : 2085 | loss: 3.0882163047790527 | dt: 169.36 ms | tokens/sec: 36.28 | norm: 2.27\n",
      "step : 2086 | loss: 3.079706907272339 | dt: 170.64 ms | tokens/sec: 36.01 | norm: 1.41\n",
      "step : 2087 | loss: 3.0435519218444824 | dt: 169.31 ms | tokens/sec: 36.29 | norm: 1.52\n",
      "step : 2088 | loss: 2.7328505516052246 | dt: 170.21 ms | tokens/sec: 36.10 | norm: 1.22\n",
      "step : 2089 | loss: 3.3114013671875 | dt: 168.17 ms | tokens/sec: 36.54 | norm: 1.73\n",
      "step : 2090 | loss: 3.161602735519409 | dt: 167.66 ms | tokens/sec: 36.65 | norm: 1.59\n",
      "step : 2091 | loss: 3.351933479309082 | dt: 166.40 ms | tokens/sec: 36.92 | norm: 1.53\n",
      "step : 2092 | loss: 3.2741336822509766 | dt: 166.60 ms | tokens/sec: 36.88 | norm: 1.45\n",
      "step : 2093 | loss: 3.19397234916687 | dt: 166.46 ms | tokens/sec: 36.91 | norm: 1.51\n",
      "step : 2094 | loss: 2.9519286155700684 | dt: 167.45 ms | tokens/sec: 36.69 | norm: 1.27\n",
      "step : 2095 | loss: 3.0578181743621826 | dt: 166.79 ms | tokens/sec: 36.84 | norm: 1.41\n",
      "step : 2096 | loss: 3.0301730632781982 | dt: 164.16 ms | tokens/sec: 37.43 | norm: 1.54\n",
      "step : 2097 | loss: 3.2066943645477295 | dt: 165.91 ms | tokens/sec: 37.03 | norm: 1.86\n",
      "step : 2098 | loss: 3.242621421813965 | dt: 164.92 ms | tokens/sec: 37.25 | norm: 1.59\n",
      "step : 2099 | loss: 3.2075023651123047 | dt: 163.95 ms | tokens/sec: 37.47 | norm: 1.38\n",
      "step : 2100 | loss: 3.1515491008758545 | dt: 166.36 ms | tokens/sec: 36.93 | norm: 1.46\n",
      "step : 2101 | loss: 3.192321300506592 | dt: 165.69 ms | tokens/sec: 37.08 | norm: 1.31\n",
      "step : 2102 | loss: 3.0406646728515625 | dt: 166.30 ms | tokens/sec: 36.94 | norm: 1.40\n",
      "step : 2103 | loss: 3.1628758907318115 | dt: 165.56 ms | tokens/sec: 37.11 | norm: 1.32\n",
      "step : 2104 | loss: 3.0904462337493896 | dt: 166.53 ms | tokens/sec: 36.89 | norm: 1.29\n",
      "step : 2105 | loss: 2.9757704734802246 | dt: 165.99 ms | tokens/sec: 37.01 | norm: 1.40\n",
      "step : 2106 | loss: 3.172410488128662 | dt: 165.76 ms | tokens/sec: 37.07 | norm: 1.42\n",
      "step : 2107 | loss: 3.225426197052002 | dt: 168.19 ms | tokens/sec: 36.53 | norm: 1.40\n",
      "step : 2108 | loss: 3.2014870643615723 | dt: 165.15 ms | tokens/sec: 37.20 | norm: 1.56\n",
      "step : 2109 | loss: 3.2514655590057373 | dt: 166.69 ms | tokens/sec: 36.86 | norm: 1.74\n",
      "step : 2110 | loss: 3.245237112045288 | dt: 167.03 ms | tokens/sec: 36.78 | norm: 1.58\n",
      "step : 2111 | loss: 3.0106606483459473 | dt: 165.64 ms | tokens/sec: 37.09 | norm: 1.81\n",
      "step : 2112 | loss: 3.1705188751220703 | dt: 166.35 ms | tokens/sec: 36.93 | norm: 1.90\n",
      "step : 2113 | loss: 3.2833971977233887 | dt: 166.47 ms | tokens/sec: 36.91 | norm: 1.70\n",
      "step : 2114 | loss: 3.2960619926452637 | dt: 165.80 ms | tokens/sec: 37.06 | norm: 1.45\n",
      "step : 2115 | loss: 3.1268324851989746 | dt: 166.44 ms | tokens/sec: 36.91 | norm: 1.55\n",
      "step : 2116 | loss: 3.3016176223754883 | dt: 166.71 ms | tokens/sec: 36.85 | norm: 1.65\n",
      "step : 2117 | loss: 3.1153182983398438 | dt: 167.34 ms | tokens/sec: 36.71 | norm: 1.67\n",
      "step : 2118 | loss: 3.3154444694519043 | dt: 165.28 ms | tokens/sec: 37.17 | norm: 1.66\n",
      "step : 2119 | loss: 3.2515907287597656 | dt: 168.42 ms | tokens/sec: 36.48 | norm: 1.77\n",
      "step : 2120 | loss: 3.367365598678589 | dt: 166.98 ms | tokens/sec: 36.79 | norm: 1.88\n",
      "step : 2121 | loss: 3.202117919921875 | dt: 164.42 ms | tokens/sec: 37.37 | norm: 1.51\n",
      "step : 2122 | loss: 3.0497167110443115 | dt: 167.09 ms | tokens/sec: 36.77 | norm: 1.39\n",
      "step : 2123 | loss: 3.2130372524261475 | dt: 166.27 ms | tokens/sec: 36.95 | norm: 1.25\n",
      "step : 2124 | loss: 3.068563938140869 | dt: 166.73 ms | tokens/sec: 36.85 | norm: 1.26\n",
      "step : 2125 | loss: 3.197939872741699 | dt: 167.11 ms | tokens/sec: 36.77 | norm: 1.38\n",
      "step : 2126 | loss: 3.490156888961792 | dt: 166.10 ms | tokens/sec: 36.99 | norm: 1.83\n",
      "step : 2127 | loss: 3.4981818199157715 | dt: 166.24 ms | tokens/sec: 36.96 | norm: 1.71\n",
      "step : 2128 | loss: 3.49804949760437 | dt: 166.01 ms | tokens/sec: 37.01 | norm: 1.72\n",
      "step : 2129 | loss: 3.3523881435394287 | dt: 164.63 ms | tokens/sec: 37.32 | norm: 1.58\n",
      "step : 2130 | loss: 3.2380809783935547 | dt: 166.57 ms | tokens/sec: 36.89 | norm: 1.31\n",
      "step : 2131 | loss: 3.393604278564453 | dt: 165.99 ms | tokens/sec: 37.01 | norm: 1.31\n",
      "step : 2132 | loss: 3.1979053020477295 | dt: 167.39 ms | tokens/sec: 36.71 | norm: 1.48\n",
      "step : 2133 | loss: 3.0540599822998047 | dt: 164.74 ms | tokens/sec: 37.30 | norm: 1.43\n",
      "step : 2134 | loss: 3.145867109298706 | dt: 166.56 ms | tokens/sec: 36.89 | norm: 1.32\n",
      "step : 2135 | loss: 3.1160664558410645 | dt: 163.05 ms | tokens/sec: 37.68 | norm: 1.48\n",
      "step : 2136 | loss: 3.0412001609802246 | dt: 164.87 ms | tokens/sec: 37.26 | norm: 1.55\n",
      "step : 2137 | loss: 2.984408140182495 | dt: 164.65 ms | tokens/sec: 37.32 | norm: 1.66\n",
      "step : 2138 | loss: 3.2597036361694336 | dt: 166.20 ms | tokens/sec: 36.97 | norm: 1.74\n",
      "step : 2139 | loss: 3.28298282623291 | dt: 165.64 ms | tokens/sec: 37.09 | norm: 1.85\n",
      "step : 2140 | loss: 3.1019186973571777 | dt: 166.96 ms | tokens/sec: 36.80 | norm: 1.61\n",
      "step : 2141 | loss: 3.0095343589782715 | dt: 165.11 ms | tokens/sec: 37.21 | norm: 1.52\n",
      "step : 2142 | loss: 2.9673547744750977 | dt: 165.73 ms | tokens/sec: 37.07 | norm: 1.64\n",
      "step : 2143 | loss: 2.6958167552948 | dt: 166.62 ms | tokens/sec: 36.87 | norm: 1.41\n",
      "step : 2144 | loss: 3.3034560680389404 | dt: 166.69 ms | tokens/sec: 36.86 | norm: 1.75\n",
      "step : 2145 | loss: 3.181844472885132 | dt: 166.96 ms | tokens/sec: 36.80 | norm: 1.62\n",
      "step : 2146 | loss: 3.282796621322632 | dt: 167.89 ms | tokens/sec: 36.60 | norm: 1.51\n",
      "step : 2147 | loss: 3.2085607051849365 | dt: 165.08 ms | tokens/sec: 37.22 | norm: 1.48\n",
      "step : 2148 | loss: 3.1635215282440186 | dt: 166.58 ms | tokens/sec: 36.88 | norm: 1.41\n",
      "step : 2149 | loss: 2.9258995056152344 | dt: 167.62 ms | tokens/sec: 36.65 | norm: 1.41\n",
      "step : 2150 | loss: 2.9938626289367676 | dt: 165.76 ms | tokens/sec: 37.06 | norm: 1.60\n",
      "step : 2151 | loss: 2.977375030517578 | dt: 167.32 ms | tokens/sec: 36.72 | norm: 1.43\n",
      "step : 2152 | loss: 3.1976542472839355 | dt: 167.24 ms | tokens/sec: 36.74 | norm: 1.45\n",
      "step : 2153 | loss: 3.171682357788086 | dt: 164.22 ms | tokens/sec: 37.41 | norm: 1.54\n",
      "step : 2154 | loss: 3.1236624717712402 | dt: 166.61 ms | tokens/sec: 36.88 | norm: 1.58\n",
      "step : 2155 | loss: 3.061159133911133 | dt: 167.38 ms | tokens/sec: 36.71 | norm: 1.58\n",
      "step : 2156 | loss: 3.118915557861328 | dt: 166.14 ms | tokens/sec: 36.98 | norm: 1.34\n",
      "step : 2157 | loss: 2.972026824951172 | dt: 167.33 ms | tokens/sec: 36.72 | norm: 1.55\n",
      "step : 2158 | loss: 3.1028640270233154 | dt: 168.49 ms | tokens/sec: 36.47 | norm: 1.52\n",
      "step : 2159 | loss: 2.978576183319092 | dt: 165.32 ms | tokens/sec: 37.16 | norm: 1.43\n",
      "step : 2160 | loss: 2.9130780696868896 | dt: 165.91 ms | tokens/sec: 37.03 | norm: 1.43\n",
      "step : 2161 | loss: 3.1395277976989746 | dt: 167.33 ms | tokens/sec: 36.72 | norm: 1.61\n",
      "step : 2162 | loss: 3.1750102043151855 | dt: 166.10 ms | tokens/sec: 36.99 | norm: 1.75\n",
      "step : 2163 | loss: 3.1786723136901855 | dt: 169.65 ms | tokens/sec: 36.22 | norm: 1.58\n",
      "step : 2164 | loss: 3.2131965160369873 | dt: 168.48 ms | tokens/sec: 36.47 | norm: 1.49\n",
      "step : 2165 | loss: 3.2081542015075684 | dt: 165.49 ms | tokens/sec: 37.13 | norm: 1.56\n",
      "step : 2166 | loss: 2.9926843643188477 | dt: 165.12 ms | tokens/sec: 37.21 | norm: 1.41\n",
      "step : 2167 | loss: 3.1060938835144043 | dt: 166.17 ms | tokens/sec: 36.97 | norm: 1.52\n",
      "step : 2168 | loss: 3.2139289379119873 | dt: 167.07 ms | tokens/sec: 36.78 | norm: 1.85\n",
      "step : 2169 | loss: 3.2047202587127686 | dt: 166.41 ms | tokens/sec: 36.92 | norm: 1.83\n",
      "step : 2170 | loss: 3.0389814376831055 | dt: 166.25 ms | tokens/sec: 36.96 | norm: 1.33\n",
      "step : 2171 | loss: 3.1762642860412598 | dt: 166.85 ms | tokens/sec: 36.82 | norm: 1.44\n",
      "step : 2172 | loss: 3.0229692459106445 | dt: 165.97 ms | tokens/sec: 37.02 | norm: 1.41\n",
      "step : 2173 | loss: 3.1955459117889404 | dt: 166.25 ms | tokens/sec: 36.96 | norm: 1.69\n",
      "step : 2174 | loss: 3.1825404167175293 | dt: 165.89 ms | tokens/sec: 37.04 | norm: 1.55\n",
      "step : 2175 | loss: 3.337928295135498 | dt: 166.34 ms | tokens/sec: 36.94 | norm: 1.45\n",
      "step : 2176 | loss: 3.135145902633667 | dt: 167.73 ms | tokens/sec: 36.63 | norm: 1.51\n",
      "step : 2177 | loss: 2.9628963470458984 | dt: 165.57 ms | tokens/sec: 37.11 | norm: 1.53\n",
      "step : 2178 | loss: 3.135632276535034 | dt: 167.75 ms | tokens/sec: 36.63 | norm: 1.23\n",
      "step : 2179 | loss: 2.96699857711792 | dt: 166.41 ms | tokens/sec: 36.92 | norm: 1.37\n",
      "step : 2180 | loss: 3.124215841293335 | dt: 165.74 ms | tokens/sec: 37.07 | norm: 1.55\n",
      "step : 2181 | loss: 3.451794385910034 | dt: 166.45 ms | tokens/sec: 36.91 | norm: 1.65\n",
      "step : 2182 | loss: 3.480625867843628 | dt: 168.31 ms | tokens/sec: 36.50 | norm: 1.68\n",
      "step : 2183 | loss: 3.48333740234375 | dt: 166.42 ms | tokens/sec: 36.92 | norm: 2.05\n",
      "step : 2184 | loss: 3.3268699645996094 | dt: 165.82 ms | tokens/sec: 37.05 | norm: 1.89\n",
      "step : 2185 | loss: 3.21470308303833 | dt: 166.95 ms | tokens/sec: 36.80 | norm: 1.50\n",
      "step : 2186 | loss: 3.3386294841766357 | dt: 165.68 ms | tokens/sec: 37.08 | norm: 1.53\n",
      "step : 2187 | loss: 3.177827835083008 | dt: 165.88 ms | tokens/sec: 37.04 | norm: 1.81\n",
      "step : 2188 | loss: 2.9998977184295654 | dt: 167.01 ms | tokens/sec: 36.79 | norm: 1.43\n",
      "step : 2189 | loss: 3.1136531829833984 | dt: 165.94 ms | tokens/sec: 37.03 | norm: 1.61\n",
      "step : 2190 | loss: 3.0317838191986084 | dt: 165.73 ms | tokens/sec: 37.07 | norm: 1.45\n",
      "step : 2191 | loss: 2.9534738063812256 | dt: 167.23 ms | tokens/sec: 36.74 | norm: 1.54\n",
      "step : 2192 | loss: 2.9486656188964844 | dt: 166.20 ms | tokens/sec: 36.97 | norm: 1.49\n",
      "step : 2193 | loss: 3.227808713912964 | dt: 166.27 ms | tokens/sec: 36.95 | norm: 1.55\n",
      "step : 2194 | loss: 3.177584648132324 | dt: 167.75 ms | tokens/sec: 36.63 | norm: 1.70\n",
      "step : 2195 | loss: 3.0246188640594482 | dt: 166.91 ms | tokens/sec: 36.81 | norm: 1.58\n",
      "step : 2196 | loss: 2.981384038925171 | dt: 166.01 ms | tokens/sec: 37.01 | norm: 1.79\n",
      "step : 2197 | loss: 2.9278202056884766 | dt: 167.42 ms | tokens/sec: 36.70 | norm: 1.54\n",
      "step : 2198 | loss: 2.638190984725952 | dt: 165.77 ms | tokens/sec: 37.06 | norm: 1.50\n",
      "step : 2199 | loss: 3.250717878341675 | dt: 166.04 ms | tokens/sec: 37.00 | norm: 1.67\n",
      "step : 2200 | loss: 3.1034810543060303 | dt: 166.70 ms | tokens/sec: 36.86 | norm: 1.87\n",
      "step : 2201 | loss: 3.2218122482299805 | dt: 166.60 ms | tokens/sec: 36.88 | norm: 1.79\n",
      "step : 2202 | loss: 3.164095640182495 | dt: 165.50 ms | tokens/sec: 37.12 | norm: 1.66\n",
      "step : 2203 | loss: 3.095946788787842 | dt: 166.97 ms | tokens/sec: 36.80 | norm: 1.46\n",
      "step : 2204 | loss: 2.83449649810791 | dt: 165.84 ms | tokens/sec: 37.05 | norm: 1.56\n",
      "step : 2205 | loss: 2.961972713470459 | dt: 166.73 ms | tokens/sec: 36.85 | norm: 1.35\n",
      "step : 2206 | loss: 2.918769359588623 | dt: 167.13 ms | tokens/sec: 36.76 | norm: 1.32\n",
      "step : 2207 | loss: 3.0990781784057617 | dt: 168.11 ms | tokens/sec: 36.55 | norm: 1.33\n",
      "step : 2208 | loss: 3.106447219848633 | dt: 165.71 ms | tokens/sec: 37.08 | norm: 2.02\n",
      "step : 2209 | loss: 3.0534427165985107 | dt: 167.03 ms | tokens/sec: 36.78 | norm: 1.73\n",
      "step : 2210 | loss: 3.027191638946533 | dt: 165.86 ms | tokens/sec: 37.04 | norm: 1.42\n",
      "step : 2211 | loss: 3.0654497146606445 | dt: 166.28 ms | tokens/sec: 36.95 | norm: 1.54\n",
      "step : 2212 | loss: 2.975691556930542 | dt: 167.27 ms | tokens/sec: 36.73 | norm: 1.56\n",
      "step : 2213 | loss: 3.0832815170288086 | dt: 166.67 ms | tokens/sec: 36.86 | norm: 1.65\n",
      "step : 2214 | loss: 2.928565502166748 | dt: 165.94 ms | tokens/sec: 37.03 | norm: 1.47\n",
      "step : 2215 | loss: 2.8978824615478516 | dt: 167.09 ms | tokens/sec: 36.77 | norm: 1.63\n",
      "step : 2216 | loss: 3.0997157096862793 | dt: 165.26 ms | tokens/sec: 37.18 | norm: 1.80\n",
      "step : 2217 | loss: 3.1475417613983154 | dt: 166.47 ms | tokens/sec: 36.91 | norm: 2.25\n",
      "step : 2218 | loss: 3.1019725799560547 | dt: 167.15 ms | tokens/sec: 36.76 | norm: 1.73\n",
      "step : 2219 | loss: 3.1384615898132324 | dt: 165.92 ms | tokens/sec: 37.03 | norm: 1.63\n",
      "step : 2220 | loss: 3.1407229900360107 | dt: 166.53 ms | tokens/sec: 36.89 | norm: 1.48\n",
      "step : 2221 | loss: 2.9224841594696045 | dt: 167.13 ms | tokens/sec: 36.76 | norm: 1.41\n",
      "step : 2222 | loss: 3.0747179985046387 | dt: 165.91 ms | tokens/sec: 37.03 | norm: 1.35\n",
      "step : 2223 | loss: 3.1931681632995605 | dt: 166.37 ms | tokens/sec: 36.93 | norm: 2.76\n",
      "step : 2224 | loss: 3.189136028289795 | dt: 166.05 ms | tokens/sec: 37.00 | norm: 1.66\n",
      "step : 2225 | loss: 3.015059232711792 | dt: 166.96 ms | tokens/sec: 36.80 | norm: 1.55\n",
      "step : 2226 | loss: 3.1718764305114746 | dt: 168.49 ms | tokens/sec: 36.46 | norm: 1.54\n",
      "step : 2227 | loss: 3.0212631225585938 | dt: 167.35 ms | tokens/sec: 36.71 | norm: 1.47\n",
      "step : 2228 | loss: 3.2220046520233154 | dt: 166.18 ms | tokens/sec: 36.97 | norm: 1.90\n",
      "step : 2229 | loss: 3.158721446990967 | dt: 166.06 ms | tokens/sec: 37.00 | norm: 1.89\n",
      "step : 2230 | loss: 3.2570064067840576 | dt: 167.19 ms | tokens/sec: 36.75 | norm: 1.76\n",
      "step : 2231 | loss: 3.1228575706481934 | dt: 166.23 ms | tokens/sec: 36.96 | norm: 1.51\n",
      "step : 2232 | loss: 2.9379422664642334 | dt: 167.38 ms | tokens/sec: 36.71 | norm: 1.61\n",
      "step : 2233 | loss: 3.0394396781921387 | dt: 166.90 ms | tokens/sec: 36.81 | norm: 1.46\n",
      "step : 2234 | loss: 2.9490153789520264 | dt: 165.99 ms | tokens/sec: 37.01 | norm: 1.37\n",
      "step : 2235 | loss: 3.086395740509033 | dt: 166.33 ms | tokens/sec: 36.94 | norm: 1.54\n",
      "step : 2236 | loss: 3.3248672485351562 | dt: 166.51 ms | tokens/sec: 36.90 | norm: 1.84\n",
      "step : 2237 | loss: 3.357642650604248 | dt: 167.75 ms | tokens/sec: 36.63 | norm: 1.74\n",
      "step : 2238 | loss: 3.439408302307129 | dt: 167.96 ms | tokens/sec: 36.58 | norm: 2.99\n",
      "step : 2239 | loss: 3.3182685375213623 | dt: 167.05 ms | tokens/sec: 36.78 | norm: 1.82\n",
      "step : 2240 | loss: 3.210475444793701 | dt: 165.99 ms | tokens/sec: 37.02 | norm: 1.71\n",
      "step : 2241 | loss: 3.3590962886810303 | dt: 166.15 ms | tokens/sec: 36.98 | norm: 1.79\n",
      "step : 2242 | loss: 3.2212624549865723 | dt: 166.98 ms | tokens/sec: 36.79 | norm: 1.87\n",
      "step : 2243 | loss: 3.00791335105896 | dt: 165.77 ms | tokens/sec: 37.06 | norm: 2.05\n",
      "step : 2244 | loss: 3.062016248703003 | dt: 165.70 ms | tokens/sec: 37.08 | norm: 1.58\n",
      "step : 2245 | loss: 3.0392799377441406 | dt: 167.98 ms | tokens/sec: 36.58 | norm: 1.61\n",
      "step : 2246 | loss: 2.9004459381103516 | dt: 165.41 ms | tokens/sec: 37.15 | norm: 1.38\n",
      "step : 2247 | loss: 2.8961398601531982 | dt: 165.92 ms | tokens/sec: 37.03 | norm: 1.82\n",
      "step : 2248 | loss: 3.132467269897461 | dt: 166.87 ms | tokens/sec: 36.82 | norm: 1.64\n",
      "step : 2249 | loss: 3.133779525756836 | dt: 165.94 ms | tokens/sec: 37.02 | norm: 1.60\n",
      "step : 2250 | loss: 2.9813671112060547 | dt: 166.11 ms | tokens/sec: 36.99 | norm: 1.55\n",
      "step : 2251 | loss: 2.928999662399292 | dt: 168.68 ms | tokens/sec: 36.42 | norm: 1.54\n",
      "step : 2252 | loss: 2.9049487113952637 | dt: 165.93 ms | tokens/sec: 37.03 | norm: 1.71\n",
      "step : 2253 | loss: 2.5973427295684814 | dt: 166.07 ms | tokens/sec: 37.00 | norm: 1.38\n",
      "step : 2254 | loss: 3.1751742362976074 | dt: 166.74 ms | tokens/sec: 36.85 | norm: 1.77\n",
      "step : 2255 | loss: 3.0656490325927734 | dt: 166.02 ms | tokens/sec: 37.01 | norm: 2.14\n",
      "step : 2256 | loss: 3.1373825073242188 | dt: 166.25 ms | tokens/sec: 36.96 | norm: 1.70\n",
      "step : 2257 | loss: 3.066814422607422 | dt: 167.74 ms | tokens/sec: 36.63 | norm: 1.52\n",
      "step : 2258 | loss: 3.004009962081909 | dt: 165.94 ms | tokens/sec: 37.03 | norm: 1.31\n",
      "step : 2259 | loss: 2.795806884765625 | dt: 166.39 ms | tokens/sec: 36.93 | norm: 1.34\n",
      "step : 2260 | loss: 2.8830504417419434 | dt: 167.30 ms | tokens/sec: 36.73 | norm: 1.48\n",
      "step : 2261 | loss: 2.831022262573242 | dt: 166.12 ms | tokens/sec: 36.99 | norm: 1.57\n",
      "step : 2262 | loss: 3.0237269401550293 | dt: 165.87 ms | tokens/sec: 37.04 | norm: 1.35\n",
      "step : 2263 | loss: 3.048591136932373 | dt: 168.46 ms | tokens/sec: 36.47 | norm: 1.44\n",
      "step : 2264 | loss: 2.9947657585144043 | dt: 166.57 ms | tokens/sec: 36.89 | norm: 1.75\n",
      "step : 2265 | loss: 2.9173617362976074 | dt: 165.93 ms | tokens/sec: 37.03 | norm: 1.43\n",
      "step : 2266 | loss: 2.982750654220581 | dt: 167.18 ms | tokens/sec: 36.75 | norm: 1.32\n",
      "step : 2267 | loss: 2.871677875518799 | dt: 165.86 ms | tokens/sec: 37.04 | norm: 1.29\n",
      "step : 2268 | loss: 2.9751791954040527 | dt: 165.63 ms | tokens/sec: 37.09 | norm: 1.36\n",
      "step : 2269 | loss: 2.837200164794922 | dt: 167.23 ms | tokens/sec: 36.74 | norm: 1.41\n",
      "step : 2270 | loss: 2.7831411361694336 | dt: 166.71 ms | tokens/sec: 36.85 | norm: 1.44\n",
      "step : 2271 | loss: 2.9951510429382324 | dt: 166.05 ms | tokens/sec: 37.00 | norm: 1.46\n",
      "step : 2272 | loss: 3.0695416927337646 | dt: 166.98 ms | tokens/sec: 36.79 | norm: 1.52\n",
      "step : 2273 | loss: 3.017465114593506 | dt: 166.02 ms | tokens/sec: 37.01 | norm: 1.80\n",
      "step : 2274 | loss: 3.024895429611206 | dt: 166.01 ms | tokens/sec: 37.01 | norm: 1.52\n",
      "step : 2275 | loss: 3.035287380218506 | dt: 167.44 ms | tokens/sec: 36.69 | norm: 1.39\n",
      "step : 2276 | loss: 2.822719097137451 | dt: 167.32 ms | tokens/sec: 36.72 | norm: 1.51\n",
      "step : 2277 | loss: 2.963500499725342 | dt: 166.04 ms | tokens/sec: 37.00 | norm: 1.42\n",
      "step : 2278 | loss: 3.1538639068603516 | dt: 167.19 ms | tokens/sec: 36.75 | norm: 1.67\n",
      "step : 2279 | loss: 3.0890865325927734 | dt: 165.80 ms | tokens/sec: 37.06 | norm: 1.56\n",
      "step : 2280 | loss: 2.9340381622314453 | dt: 166.24 ms | tokens/sec: 36.96 | norm: 1.43\n",
      "step : 2281 | loss: 3.084146022796631 | dt: 167.35 ms | tokens/sec: 36.71 | norm: 2.08\n",
      "step : 2282 | loss: 2.932581901550293 | dt: 166.68 ms | tokens/sec: 36.86 | norm: 1.31\n",
      "step : 2283 | loss: 3.161912679672241 | dt: 167.13 ms | tokens/sec: 36.76 | norm: 2.91\n",
      "step : 2284 | loss: 3.1106009483337402 | dt: 167.06 ms | tokens/sec: 36.78 | norm: 1.77\n",
      "step : 2285 | loss: 3.206531047821045 | dt: 165.81 ms | tokens/sec: 37.06 | norm: 1.77\n",
      "step : 2286 | loss: 3.0492615699768066 | dt: 165.80 ms | tokens/sec: 37.06 | norm: 1.45\n",
      "step : 2287 | loss: 2.8945910930633545 | dt: 167.24 ms | tokens/sec: 36.74 | norm: 1.64\n",
      "step : 2288 | loss: 3.0029494762420654 | dt: 166.26 ms | tokens/sec: 36.95 | norm: 1.48\n",
      "step : 2289 | loss: 2.882014274597168 | dt: 166.83 ms | tokens/sec: 36.83 | norm: 1.47\n",
      "step : 2290 | loss: 3.009451389312744 | dt: 167.04 ms | tokens/sec: 36.78 | norm: 1.55\n",
      "step : 2291 | loss: 3.2306315898895264 | dt: 166.19 ms | tokens/sec: 36.97 | norm: 1.69\n",
      "step : 2292 | loss: 3.2700393199920654 | dt: 165.88 ms | tokens/sec: 37.04 | norm: 1.59\n",
      "step : 2293 | loss: 3.425260543823242 | dt: 167.35 ms | tokens/sec: 36.71 | norm: 1.66\n",
      "step : 2294 | loss: 3.249629497528076 | dt: 166.00 ms | tokens/sec: 37.01 | norm: 1.72\n",
      "step : 2295 | loss: 3.1162261962890625 | dt: 166.74 ms | tokens/sec: 36.85 | norm: 1.55\n",
      "step : 2296 | loss: 3.242584228515625 | dt: 167.06 ms | tokens/sec: 36.78 | norm: 1.55\n",
      "step : 2297 | loss: 3.1115097999572754 | dt: 165.80 ms | tokens/sec: 37.06 | norm: 1.67\n",
      "step : 2298 | loss: 2.919369697570801 | dt: 166.05 ms | tokens/sec: 37.00 | norm: 1.90\n",
      "step : 2299 | loss: 2.9891421794891357 | dt: 165.99 ms | tokens/sec: 37.01 | norm: 1.60\n",
      "step : 2300 | loss: 2.971149444580078 | dt: 167.07 ms | tokens/sec: 36.78 | norm: 1.85\n",
      "step : 2301 | loss: 2.8326187133789062 | dt: 167.11 ms | tokens/sec: 36.77 | norm: 1.55\n",
      "step : 2302 | loss: 2.8268027305603027 | dt: 167.58 ms | tokens/sec: 36.66 | norm: 1.69\n",
      "step : 2303 | loss: 3.063413143157959 | dt: 165.54 ms | tokens/sec: 37.11 | norm: 3.05\n",
      "step : 2304 | loss: 3.092966079711914 | dt: 165.89 ms | tokens/sec: 37.04 | norm: 1.71\n",
      "step : 2305 | loss: 2.9239509105682373 | dt: 167.15 ms | tokens/sec: 36.76 | norm: 1.80\n",
      "step : 2306 | loss: 2.8684005737304688 | dt: 165.93 ms | tokens/sec: 37.03 | norm: 1.74\n",
      "step : 2307 | loss: 2.8447318077087402 | dt: 167.05 ms | tokens/sec: 36.78 | norm: 1.88\n",
      "step : 2308 | loss: 2.5659451484680176 | dt: 167.06 ms | tokens/sec: 36.78 | norm: 1.56\n",
      "step : 2309 | loss: 3.1583757400512695 | dt: 165.70 ms | tokens/sec: 37.08 | norm: 2.02\n",
      "step : 2310 | loss: 3.0966384410858154 | dt: 165.57 ms | tokens/sec: 37.11 | norm: 2.19\n",
      "step : 2311 | loss: 3.2082314491271973 | dt: 167.42 ms | tokens/sec: 36.70 | norm: 1.90\n",
      "step : 2312 | loss: 3.077510356903076 | dt: 165.42 ms | tokens/sec: 37.14 | norm: 1.93\n",
      "step : 2313 | loss: 2.9926929473876953 | dt: 165.92 ms | tokens/sec: 37.03 | norm: 1.81\n",
      "step : 2314 | loss: 2.7951011657714844 | dt: 168.39 ms | tokens/sec: 36.49 | norm: 1.82\n",
      "step : 2315 | loss: 2.8725132942199707 | dt: 165.70 ms | tokens/sec: 37.08 | norm: 1.62\n",
      "step : 2316 | loss: 2.8674113750457764 | dt: 165.36 ms | tokens/sec: 37.16 | norm: 1.76\n",
      "step : 2317 | loss: 2.9834353923797607 | dt: 167.32 ms | tokens/sec: 36.72 | norm: 1.66\n",
      "step : 2318 | loss: 2.994323253631592 | dt: 166.08 ms | tokens/sec: 36.99 | norm: 1.57\n",
      "step : 2319 | loss: 2.967388868331909 | dt: 166.35 ms | tokens/sec: 36.94 | norm: 2.17\n",
      "step : 2320 | loss: 2.875828504562378 | dt: 168.23 ms | tokens/sec: 36.52 | norm: 1.63\n",
      "step : 2321 | loss: 2.911776542663574 | dt: 165.91 ms | tokens/sec: 37.03 | norm: 1.43\n",
      "step : 2322 | loss: 2.798919439315796 | dt: 165.63 ms | tokens/sec: 37.09 | norm: 1.55\n",
      "step : 2323 | loss: 2.9314918518066406 | dt: 168.72 ms | tokens/sec: 36.41 | norm: 1.47\n",
      "step : 2324 | loss: 2.800457715988159 | dt: 165.46 ms | tokens/sec: 37.13 | norm: 1.39\n",
      "step : 2325 | loss: 2.7518515586853027 | dt: 166.15 ms | tokens/sec: 36.98 | norm: 1.60\n",
      "step : 2326 | loss: 2.970643997192383 | dt: 168.65 ms | tokens/sec: 36.43 | norm: 1.50\n",
      "step : 2327 | loss: 3.039047956466675 | dt: 166.67 ms | tokens/sec: 36.86 | norm: 1.76\n",
      "step : 2328 | loss: 2.9848227500915527 | dt: 166.90 ms | tokens/sec: 36.81 | norm: 1.49\n",
      "step : 2329 | loss: 2.9642162322998047 | dt: 168.09 ms | tokens/sec: 36.55 | norm: 1.49\n",
      "step : 2330 | loss: 2.955512523651123 | dt: 166.69 ms | tokens/sec: 36.86 | norm: 1.62\n",
      "step : 2331 | loss: 2.77899169921875 | dt: 166.51 ms | tokens/sec: 36.90 | norm: 1.47\n",
      "step : 2332 | loss: 2.870975971221924 | dt: 167.22 ms | tokens/sec: 36.74 | norm: 1.64\n",
      "step : 2333 | loss: 3.077454090118408 | dt: 165.86 ms | tokens/sec: 37.04 | norm: 1.60\n",
      "step : 2334 | loss: 3.009054183959961 | dt: 165.98 ms | tokens/sec: 37.02 | norm: 1.46\n",
      "step : 2335 | loss: 2.8506617546081543 | dt: 167.84 ms | tokens/sec: 36.61 | norm: 1.41\n",
      "step : 2336 | loss: 3.0468833446502686 | dt: 166.04 ms | tokens/sec: 37.00 | norm: 1.52\n",
      "step : 2337 | loss: 2.8936290740966797 | dt: 167.59 ms | tokens/sec: 36.66 | norm: 1.42\n",
      "step : 2338 | loss: 3.188202381134033 | dt: 168.51 ms | tokens/sec: 36.46 | norm: 1.91\n",
      "step : 2339 | loss: 3.064986228942871 | dt: 167.50 ms | tokens/sec: 36.68 | norm: 1.70\n",
      "step : 2340 | loss: 3.1811366081237793 | dt: 166.67 ms | tokens/sec: 36.86 | norm: 1.63\n",
      "step : 2341 | loss: 2.983017683029175 | dt: 167.07 ms | tokens/sec: 36.78 | norm: 1.65\n",
      "step : 2342 | loss: 2.871511936187744 | dt: 166.38 ms | tokens/sec: 36.93 | norm: 1.49\n",
      "step : 2343 | loss: 2.9702672958374023 | dt: 167.69 ms | tokens/sec: 36.64 | norm: 1.66\n",
      "step : 2344 | loss: 2.832111358642578 | dt: 169.50 ms | tokens/sec: 36.25 | norm: 1.43\n",
      "step : 2345 | loss: 2.948253631591797 | dt: 166.99 ms | tokens/sec: 36.79 | norm: 1.83\n",
      "step : 2346 | loss: 3.1668753623962402 | dt: 165.24 ms | tokens/sec: 37.18 | norm: 1.73\n",
      "step : 2347 | loss: 3.1815555095672607 | dt: 165.13 ms | tokens/sec: 37.21 | norm: 1.68\n",
      "step : 2348 | loss: 3.277848243713379 | dt: 165.49 ms | tokens/sec: 37.13 | norm: 1.56\n",
      "step : 2349 | loss: 3.09299635887146 | dt: 165.82 ms | tokens/sec: 37.05 | norm: 1.53\n",
      "step : 2350 | loss: 3.014235258102417 | dt: 166.47 ms | tokens/sec: 36.91 | norm: 1.56\n",
      "step : 2351 | loss: 3.1452929973602295 | dt: 166.37 ms | tokens/sec: 36.93 | norm: 1.28\n",
      "step : 2352 | loss: 3.0252254009246826 | dt: 166.64 ms | tokens/sec: 36.87 | norm: 1.58\n",
      "step : 2353 | loss: 2.900979518890381 | dt: 166.87 ms | tokens/sec: 36.82 | norm: 1.80\n",
      "step : 2354 | loss: 2.930445432662964 | dt: 166.09 ms | tokens/sec: 36.99 | norm: 1.69\n",
      "step : 2355 | loss: 2.9011263847351074 | dt: 166.32 ms | tokens/sec: 36.94 | norm: 1.43\n",
      "step : 2356 | loss: 2.773634672164917 | dt: 167.22 ms | tokens/sec: 36.74 | norm: 1.59\n",
      "step : 2357 | loss: 2.797853469848633 | dt: 166.06 ms | tokens/sec: 37.00 | norm: 1.68\n",
      "step : 2358 | loss: 3.0625646114349365 | dt: 166.10 ms | tokens/sec: 36.99 | norm: 1.51\n",
      "step : 2359 | loss: 2.9989402294158936 | dt: 166.96 ms | tokens/sec: 36.80 | norm: 1.77\n",
      "step : 2360 | loss: 2.828782558441162 | dt: 165.59 ms | tokens/sec: 37.10 | norm: 1.63\n",
      "step : 2361 | loss: 2.7433278560638428 | dt: 165.75 ms | tokens/sec: 37.07 | norm: 1.34\n",
      "step : 2362 | loss: 2.719782590866089 | dt: 166.97 ms | tokens/sec: 36.80 | norm: 2.94\n",
      "step : 2363 | loss: 2.475924491882324 | dt: 165.62 ms | tokens/sec: 37.10 | norm: 1.43\n",
      "step : 2364 | loss: 3.0692214965820312 | dt: 170.10 ms | tokens/sec: 36.12 | norm: 1.90\n",
      "step : 2365 | loss: 3.0315470695495605 | dt: 168.38 ms | tokens/sec: 36.49 | norm: 2.39\n",
      "step : 2366 | loss: 3.1648383140563965 | dt: 168.79 ms | tokens/sec: 36.40 | norm: 2.07\n",
      "step : 2367 | loss: 3.0807628631591797 | dt: 168.03 ms | tokens/sec: 36.57 | norm: 2.27\n",
      "step : 2368 | loss: 2.9749364852905273 | dt: 168.11 ms | tokens/sec: 36.55 | norm: 2.21\n",
      "step : 2369 | loss: 2.7798399925231934 | dt: 168.87 ms | tokens/sec: 36.38 | norm: 2.11\n",
      "step : 2370 | loss: 2.861865997314453 | dt: 169.60 ms | tokens/sec: 36.23 | norm: 1.67\n",
      "step : 2371 | loss: 2.8317103385925293 | dt: 168.58 ms | tokens/sec: 36.45 | norm: 1.83\n",
      "step : 2372 | loss: 2.9820315837860107 | dt: 168.62 ms | tokens/sec: 36.44 | norm: 1.78\n",
      "step : 2373 | loss: 2.9846534729003906 | dt: 167.76 ms | tokens/sec: 36.62 | norm: 1.74\n",
      "step : 2374 | loss: 3.0365328788757324 | dt: 167.71 ms | tokens/sec: 36.63 | norm: 1.66\n",
      "step : 2375 | loss: 2.8938205242156982 | dt: 167.44 ms | tokens/sec: 36.69 | norm: 1.75\n",
      "step : 2376 | loss: 2.959016799926758 | dt: 169.42 ms | tokens/sec: 36.26 | norm: 1.79\n",
      "step : 2377 | loss: 2.818784236907959 | dt: 168.96 ms | tokens/sec: 36.36 | norm: 1.63\n",
      "step : 2378 | loss: 2.912647247314453 | dt: 168.70 ms | tokens/sec: 36.42 | norm: 1.47\n",
      "step : 2379 | loss: 2.7740745544433594 | dt: 168.86 ms | tokens/sec: 36.38 | norm: 1.63\n",
      "step : 2380 | loss: 2.725358724594116 | dt: 167.95 ms | tokens/sec: 36.58 | norm: 2.37\n",
      "step : 2381 | loss: 2.9385595321655273 | dt: 169.07 ms | tokens/sec: 36.34 | norm: 1.84\n",
      "step : 2382 | loss: 3.003950595855713 | dt: 170.36 ms | tokens/sec: 36.06 | norm: 1.77\n",
      "step : 2383 | loss: 2.931945323944092 | dt: 167.75 ms | tokens/sec: 36.62 | norm: 1.62\n",
      "step : 2384 | loss: 2.9492430686950684 | dt: 168.20 ms | tokens/sec: 36.53 | norm: 1.63\n",
      "step : 2385 | loss: 2.9554624557495117 | dt: 169.23 ms | tokens/sec: 36.31 | norm: 1.48\n",
      "step : 2386 | loss: 2.7496135234832764 | dt: 168.82 ms | tokens/sec: 36.39 | norm: 1.51\n",
      "step : 2387 | loss: 2.838351011276245 | dt: 168.73 ms | tokens/sec: 36.41 | norm: 1.55\n",
      "step : 2388 | loss: 2.9987473487854004 | dt: 168.83 ms | tokens/sec: 36.39 | norm: 1.92\n",
      "step : 2389 | loss: 2.914989948272705 | dt: 168.52 ms | tokens/sec: 36.46 | norm: 1.59\n",
      "step : 2390 | loss: 2.7607953548431396 | dt: 168.48 ms | tokens/sec: 36.47 | norm: 1.40\n",
      "step : 2391 | loss: 2.930945873260498 | dt: 167.80 ms | tokens/sec: 36.62 | norm: 1.60\n",
      "step : 2392 | loss: 2.7933335304260254 | dt: 168.77 ms | tokens/sec: 36.40 | norm: 1.52\n",
      "step : 2393 | loss: 3.0686824321746826 | dt: 168.88 ms | tokens/sec: 36.38 | norm: 1.54\n",
      "step : 2394 | loss: 2.9593312740325928 | dt: 169.94 ms | tokens/sec: 36.15 | norm: 2.87\n",
      "step : 2395 | loss: 3.105313301086426 | dt: 169.02 ms | tokens/sec: 36.35 | norm: 1.91\n",
      "step : 2396 | loss: 2.9185686111450195 | dt: 168.54 ms | tokens/sec: 36.45 | norm: 1.72\n",
      "step : 2397 | loss: 2.808013916015625 | dt: 167.92 ms | tokens/sec: 36.59 | norm: 1.58\n",
      "step : 2398 | loss: 2.9179701805114746 | dt: 167.95 ms | tokens/sec: 36.58 | norm: 1.65\n",
      "step : 2399 | loss: 2.7573680877685547 | dt: 167.63 ms | tokens/sec: 36.65 | norm: 1.43\n",
      "step : 2400 | loss: 2.870134115219116 | dt: 168.47 ms | tokens/sec: 36.47 | norm: 1.39\n",
      "step : 2401 | loss: 3.0734994411468506 | dt: 169.18 ms | tokens/sec: 36.32 | norm: 1.87\n",
      "step : 2402 | loss: 3.110492706298828 | dt: 168.58 ms | tokens/sec: 36.44 | norm: 1.68\n",
      "step : 2403 | loss: 3.2227420806884766 | dt: 169.42 ms | tokens/sec: 36.26 | norm: 1.96\n",
      "step : 2404 | loss: 3.0203824043273926 | dt: 168.47 ms | tokens/sec: 36.47 | norm: 1.71\n",
      "step : 2405 | loss: 2.9772744178771973 | dt: 168.67 ms | tokens/sec: 36.43 | norm: 1.73\n",
      "step : 2406 | loss: 3.0517845153808594 | dt: 167.85 ms | tokens/sec: 36.60 | norm: 1.73\n",
      "step : 2407 | loss: 2.9333534240722656 | dt: 168.80 ms | tokens/sec: 36.40 | norm: 1.59\n",
      "step : 2408 | loss: 2.8287367820739746 | dt: 168.16 ms | tokens/sec: 36.54 | norm: 1.68\n",
      "step : 2409 | loss: 2.8667826652526855 | dt: 167.69 ms | tokens/sec: 36.64 | norm: 1.48\n",
      "step : 2410 | loss: 2.8264269828796387 | dt: 168.10 ms | tokens/sec: 36.55 | norm: 1.70\n",
      "step : 2411 | loss: 2.706325054168701 | dt: 168.88 ms | tokens/sec: 36.38 | norm: 1.34\n",
      "step : 2412 | loss: 2.744288921356201 | dt: 168.56 ms | tokens/sec: 36.45 | norm: 1.37\n",
      "step : 2413 | loss: 2.984391689300537 | dt: 169.35 ms | tokens/sec: 36.28 | norm: 1.51\n",
      "step : 2414 | loss: 2.968306303024292 | dt: 169.15 ms | tokens/sec: 36.32 | norm: 1.72\n",
      "step : 2415 | loss: 2.7928149700164795 | dt: 168.05 ms | tokens/sec: 36.56 | norm: 1.55\n",
      "step : 2416 | loss: 2.6904380321502686 | dt: 168.13 ms | tokens/sec: 36.54 | norm: 1.54\n",
      "step : 2417 | loss: 2.7391514778137207 | dt: 167.06 ms | tokens/sec: 36.78 | norm: 1.53\n",
      "step : 2418 | loss: 2.409548759460449 | dt: 167.97 ms | tokens/sec: 36.58 | norm: 1.40\n",
      "step : 2419 | loss: 2.9599692821502686 | dt: 167.88 ms | tokens/sec: 36.60 | norm: 1.58\n",
      "step : 2420 | loss: 2.9162471294403076 | dt: 169.77 ms | tokens/sec: 36.19 | norm: 2.05\n",
      "step : 2421 | loss: 3.0169992446899414 | dt: 168.41 ms | tokens/sec: 36.48 | norm: 1.90\n",
      "step : 2422 | loss: 2.9958369731903076 | dt: 168.56 ms | tokens/sec: 36.45 | norm: 1.70\n",
      "step : 2423 | loss: 2.908876419067383 | dt: 167.79 ms | tokens/sec: 36.62 | norm: 1.65\n",
      "step : 2424 | loss: 2.7076826095581055 | dt: 168.31 ms | tokens/sec: 36.50 | norm: 1.77\n",
      "step : 2425 | loss: 2.779508590698242 | dt: 167.94 ms | tokens/sec: 36.58 | norm: 1.39\n",
      "step : 2426 | loss: 2.744752883911133 | dt: 168.88 ms | tokens/sec: 36.38 | norm: 1.59\n",
      "step : 2427 | loss: 2.8857760429382324 | dt: 167.53 ms | tokens/sec: 36.67 | norm: 1.65\n",
      "step : 2428 | loss: 2.8456368446350098 | dt: 168.07 ms | tokens/sec: 36.56 | norm: 1.58\n",
      "step : 2429 | loss: 2.8503355979919434 | dt: 169.76 ms | tokens/sec: 36.19 | norm: 1.54\n",
      "step : 2430 | loss: 2.7507362365722656 | dt: 168.95 ms | tokens/sec: 36.37 | norm: 1.42\n",
      "step : 2431 | loss: 2.8187575340270996 | dt: 167.68 ms | tokens/sec: 36.64 | norm: 1.88\n",
      "step : 2432 | loss: 2.684724807739258 | dt: 168.75 ms | tokens/sec: 36.41 | norm: 1.52\n",
      "step : 2433 | loss: 2.7807321548461914 | dt: 168.50 ms | tokens/sec: 36.46 | norm: 1.45\n",
      "step : 2434 | loss: 2.680283308029175 | dt: 167.95 ms | tokens/sec: 36.58 | norm: 1.67\n",
      "step : 2435 | loss: 2.66630220413208 | dt: 167.55 ms | tokens/sec: 36.67 | norm: 1.63\n",
      "step : 2436 | loss: 2.840245246887207 | dt: 168.12 ms | tokens/sec: 36.55 | norm: 1.76\n",
      "step : 2437 | loss: 2.921254873275757 | dt: 167.04 ms | tokens/sec: 36.78 | norm: 1.81\n",
      "step : 2438 | loss: 2.834543228149414 | dt: 173.92 ms | tokens/sec: 35.33 | norm: 1.71\n",
      "step : 2439 | loss: 2.8670654296875 | dt: 170.83 ms | tokens/sec: 35.97 | norm: 2.05\n",
      "step : 2440 | loss: 2.8752503395080566 | dt: 170.07 ms | tokens/sec: 36.13 | norm: 1.58\n",
      "step : 2441 | loss: 2.704312801361084 | dt: 170.78 ms | tokens/sec: 35.98 | norm: 1.72\n",
      "step : 2442 | loss: 2.777890682220459 | dt: 170.25 ms | tokens/sec: 36.09 | norm: 1.90\n",
      "step : 2443 | loss: 2.9504737854003906 | dt: 171.45 ms | tokens/sec: 35.83 | norm: 1.97\n",
      "step : 2444 | loss: 2.880014419555664 | dt: 171.30 ms | tokens/sec: 35.87 | norm: 1.71\n",
      "step : 2445 | loss: 2.6936941146850586 | dt: 170.91 ms | tokens/sec: 35.95 | norm: 1.62\n",
      "step : 2446 | loss: 2.8775153160095215 | dt: 171.12 ms | tokens/sec: 35.90 | norm: 1.86\n",
      "step : 2447 | loss: 2.745800733566284 | dt: 171.34 ms | tokens/sec: 35.86 | norm: 1.56\n",
      "step : 2448 | loss: 2.978046417236328 | dt: 171.15 ms | tokens/sec: 35.90 | norm: 1.65\n",
      "step : 2449 | loss: 3.003559112548828 | dt: 171.21 ms | tokens/sec: 35.89 | norm: 2.32\n",
      "step : 2450 | loss: 3.038166046142578 | dt: 172.02 ms | tokens/sec: 35.72 | norm: 1.91\n",
      "step : 2451 | loss: 2.8928542137145996 | dt: 170.89 ms | tokens/sec: 35.95 | norm: 1.80\n",
      "step : 2452 | loss: 2.777217388153076 | dt: 171.10 ms | tokens/sec: 35.91 | norm: 1.75\n",
      "step : 2453 | loss: 2.9037070274353027 | dt: 170.21 ms | tokens/sec: 36.10 | norm: 1.54\n",
      "step : 2454 | loss: 2.744098663330078 | dt: 170.81 ms | tokens/sec: 35.97 | norm: 1.86\n",
      "step : 2455 | loss: 2.846295118331909 | dt: 170.28 ms | tokens/sec: 36.08 | norm: 1.61\n",
      "step : 2456 | loss: 3.1352920532226562 | dt: 171.01 ms | tokens/sec: 35.93 | norm: 1.92\n",
      "step : 2457 | loss: 3.083449363708496 | dt: 171.23 ms | tokens/sec: 35.88 | norm: 1.56\n",
      "step : 2458 | loss: 3.1906440258026123 | dt: 171.47 ms | tokens/sec: 35.83 | norm: 1.61\n",
      "step : 2459 | loss: 2.9894824028015137 | dt: 170.19 ms | tokens/sec: 36.10 | norm: 1.79\n",
      "step : 2460 | loss: 2.9154796600341797 | dt: 171.25 ms | tokens/sec: 35.88 | norm: 1.44\n",
      "step : 2461 | loss: 3.0028140544891357 | dt: 171.06 ms | tokens/sec: 35.92 | norm: 1.69\n",
      "step : 2462 | loss: 2.873116970062256 | dt: 171.98 ms | tokens/sec: 35.73 | norm: 1.75\n",
      "step : 2463 | loss: 2.7714574337005615 | dt: 171.88 ms | tokens/sec: 35.75 | norm: 1.65\n",
      "step : 2464 | loss: 2.781215190887451 | dt: 171.28 ms | tokens/sec: 35.87 | norm: 1.64\n",
      "step : 2465 | loss: 2.7826170921325684 | dt: 170.83 ms | tokens/sec: 35.97 | norm: 1.61\n",
      "step : 2466 | loss: 2.630549192428589 | dt: 170.37 ms | tokens/sec: 36.06 | norm: 1.59\n",
      "step : 2467 | loss: 2.6930088996887207 | dt: 170.41 ms | tokens/sec: 36.05 | norm: 1.60\n",
      "step : 2468 | loss: 2.9235637187957764 | dt: 171.38 ms | tokens/sec: 35.85 | norm: 2.52\n",
      "step : 2469 | loss: 2.9056396484375 | dt: 171.20 ms | tokens/sec: 35.89 | norm: 1.87\n",
      "step : 2470 | loss: 2.734598159790039 | dt: 170.21 ms | tokens/sec: 36.10 | norm: 1.60\n",
      "step : 2471 | loss: 2.6406631469726562 | dt: 170.70 ms | tokens/sec: 35.99 | norm: 1.41\n",
      "step : 2472 | loss: 2.6580843925476074 | dt: 171.37 ms | tokens/sec: 35.85 | norm: 1.67\n",
      "step : 2473 | loss: 2.395404577255249 | dt: 171.44 ms | tokens/sec: 35.84 | norm: 2.04\n",
      "step : 2474 | loss: 2.8794097900390625 | dt: 170.06 ms | tokens/sec: 36.13 | norm: 2.08\n",
      "step : 2475 | loss: 2.857861280441284 | dt: 171.19 ms | tokens/sec: 35.89 | norm: 2.06\n",
      "step : 2476 | loss: 2.987393856048584 | dt: 170.44 ms | tokens/sec: 36.05 | norm: 1.78\n",
      "step : 2477 | loss: 2.8922784328460693 | dt: 172.79 ms | tokens/sec: 35.56 | norm: 1.96\n",
      "step : 2478 | loss: 2.8569865226745605 | dt: 171.21 ms | tokens/sec: 35.89 | norm: 1.67\n",
      "step : 2479 | loss: 2.6448287963867188 | dt: 171.05 ms | tokens/sec: 35.92 | norm: 1.73\n",
      "step : 2480 | loss: 2.6900241374969482 | dt: 170.76 ms | tokens/sec: 35.98 | norm: 1.41\n",
      "step : 2481 | loss: 2.6889359951019287 | dt: 172.45 ms | tokens/sec: 35.63 | norm: 1.65\n",
      "step : 2482 | loss: 2.8556723594665527 | dt: 171.00 ms | tokens/sec: 35.93 | norm: 1.67\n",
      "step : 2483 | loss: 2.8326282501220703 | dt: 170.06 ms | tokens/sec: 36.13 | norm: 1.89\n",
      "step : 2484 | loss: 2.8547427654266357 | dt: 170.69 ms | tokens/sec: 35.99 | norm: 2.00\n",
      "step : 2485 | loss: 2.7658371925354004 | dt: 170.07 ms | tokens/sec: 36.13 | norm: 2.34\n",
      "step : 2486 | loss: 2.8625905513763428 | dt: 170.74 ms | tokens/sec: 35.98 | norm: 1.67\n",
      "step : 2487 | loss: 2.6982696056365967 | dt: 171.19 ms | tokens/sec: 35.89 | norm: 1.53\n",
      "step : 2488 | loss: 2.7619118690490723 | dt: 170.55 ms | tokens/sec: 36.03 | norm: 1.62\n",
      "step : 2489 | loss: 2.636786460876465 | dt: 170.27 ms | tokens/sec: 36.08 | norm: 1.43\n",
      "step : 2490 | loss: 2.607578992843628 | dt: 170.00 ms | tokens/sec: 36.14 | norm: 1.52\n",
      "step : 2491 | loss: 2.765949249267578 | dt: 171.34 ms | tokens/sec: 35.86 | norm: 1.63\n",
      "step : 2492 | loss: 2.878171443939209 | dt: 170.72 ms | tokens/sec: 35.99 | norm: 1.74\n",
      "step : 2493 | loss: 2.7890796661376953 | dt: 171.38 ms | tokens/sec: 35.85 | norm: 1.88\n",
      "step : 2494 | loss: 2.858036756515503 | dt: 168.93 ms | tokens/sec: 36.37 | norm: 1.70\n",
      "step : 2495 | loss: 2.8496501445770264 | dt: 170.77 ms | tokens/sec: 35.98 | norm: 1.87\n",
      "step : 2496 | loss: 2.679673671722412 | dt: 170.89 ms | tokens/sec: 35.95 | norm: 1.95\n",
      "step : 2497 | loss: 2.7994532585144043 | dt: 171.05 ms | tokens/sec: 35.92 | norm: 1.61\n",
      "step : 2498 | loss: 2.9816863536834717 | dt: 169.58 ms | tokens/sec: 36.23 | norm: 1.99\n",
      "step : 2499 | loss: 2.8694639205932617 | dt: 171.29 ms | tokens/sec: 35.87 | norm: 1.82\n",
      "step : 2500 | loss: 2.7207086086273193 | dt: 169.56 ms | tokens/sec: 36.23 | norm: 1.54\n",
      "step : 2501 | loss: 2.905935049057007 | dt: 170.62 ms | tokens/sec: 36.01 | norm: 1.81\n",
      "step : 2502 | loss: 2.7384536266326904 | dt: 170.16 ms | tokens/sec: 36.11 | norm: 1.69\n",
      "step : 2503 | loss: 2.8998045921325684 | dt: 170.11 ms | tokens/sec: 36.12 | norm: 1.69\n",
      "step : 2504 | loss: 2.946990966796875 | dt: 170.65 ms | tokens/sec: 36.00 | norm: 1.85\n",
      "step : 2505 | loss: 3.000314712524414 | dt: 171.13 ms | tokens/sec: 35.90 | norm: 2.26\n",
      "step : 2506 | loss: 2.820413589477539 | dt: 171.06 ms | tokens/sec: 35.92 | norm: 1.79\n",
      "step : 2507 | loss: 2.707427740097046 | dt: 170.14 ms | tokens/sec: 36.11 | norm: 1.89\n",
      "step : 2508 | loss: 2.8027923107147217 | dt: 170.77 ms | tokens/sec: 35.98 | norm: 1.60\n",
      "step : 2509 | loss: 2.716670036315918 | dt: 171.43 ms | tokens/sec: 35.84 | norm: 2.03\n",
      "step : 2510 | loss: 2.7963485717773438 | dt: 170.23 ms | tokens/sec: 36.09 | norm: 1.66\n",
      "step : 2511 | loss: 3.0673539638519287 | dt: 170.60 ms | tokens/sec: 36.01 | norm: 1.96\n",
      "step : 2512 | loss: 3.0256190299987793 | dt: 171.27 ms | tokens/sec: 35.87 | norm: 1.70\n",
      "step : 2513 | loss: 3.125288486480713 | dt: 170.30 ms | tokens/sec: 36.08 | norm: 1.66\n",
      "step : 2514 | loss: 2.977717399597168 | dt: 171.31 ms | tokens/sec: 35.86 | norm: 1.72\n",
      "step : 2515 | loss: 2.855213165283203 | dt: 170.40 ms | tokens/sec: 36.06 | norm: 1.64\n",
      "step : 2516 | loss: 2.9603261947631836 | dt: 170.78 ms | tokens/sec: 35.98 | norm: 1.65\n",
      "step : 2517 | loss: 2.807861328125 | dt: 170.73 ms | tokens/sec: 35.99 | norm: 1.71\n",
      "step : 2518 | loss: 2.6899499893188477 | dt: 170.90 ms | tokens/sec: 35.95 | norm: 1.53\n",
      "step : 2519 | loss: 2.7397875785827637 | dt: 169.80 ms | tokens/sec: 36.18 | norm: 1.55\n",
      "step : 2520 | loss: 2.7087864875793457 | dt: 169.89 ms | tokens/sec: 36.16 | norm: 1.59\n",
      "step : 2521 | loss: 2.570678234100342 | dt: 170.42 ms | tokens/sec: 36.05 | norm: 1.44\n",
      "step : 2522 | loss: 2.6348531246185303 | dt: 170.32 ms | tokens/sec: 36.07 | norm: 1.53\n",
      "step : 2523 | loss: 2.916423797607422 | dt: 170.15 ms | tokens/sec: 36.11 | norm: 1.76\n",
      "step : 2524 | loss: 2.869152545928955 | dt: 171.52 ms | tokens/sec: 35.82 | norm: 1.76\n",
      "step : 2525 | loss: 2.6920363903045654 | dt: 170.04 ms | tokens/sec: 36.13 | norm: 1.53\n",
      "step : 2526 | loss: 2.5687460899353027 | dt: 170.78 ms | tokens/sec: 35.98 | norm: 1.76\n",
      "step : 2527 | loss: 2.623380661010742 | dt: 171.02 ms | tokens/sec: 35.93 | norm: 1.87\n",
      "step : 2528 | loss: 2.35758900642395 | dt: 170.68 ms | tokens/sec: 36.00 | norm: 1.56\n",
      "step : 2529 | loss: 2.859048366546631 | dt: 169.74 ms | tokens/sec: 36.20 | norm: 2.02\n",
      "step : 2530 | loss: 2.855502128601074 | dt: 171.18 ms | tokens/sec: 35.89 | norm: 1.75\n",
      "step : 2531 | loss: 2.927417755126953 | dt: 170.59 ms | tokens/sec: 36.02 | norm: 1.89\n",
      "step : 2532 | loss: 2.894808292388916 | dt: 170.48 ms | tokens/sec: 36.04 | norm: 2.24\n",
      "step : 2533 | loss: 2.8272719383239746 | dt: 170.40 ms | tokens/sec: 36.06 | norm: 2.09\n",
      "step : 2534 | loss: 2.618797540664673 | dt: 169.32 ms | tokens/sec: 36.29 | norm: 2.17\n",
      "step : 2535 | loss: 2.6181721687316895 | dt: 171.31 ms | tokens/sec: 35.86 | norm: 1.48\n",
      "step : 2536 | loss: 2.620027542114258 | dt: 170.48 ms | tokens/sec: 36.04 | norm: 1.69\n",
      "step : 2537 | loss: 2.7758116722106934 | dt: 170.67 ms | tokens/sec: 36.00 | norm: 1.61\n",
      "step : 2538 | loss: 2.848828077316284 | dt: 170.66 ms | tokens/sec: 36.00 | norm: 1.98\n",
      "step : 2539 | loss: 2.8812575340270996 | dt: 170.82 ms | tokens/sec: 35.97 | norm: 2.24\n",
      "step : 2540 | loss: 2.7855100631713867 | dt: 169.27 ms | tokens/sec: 36.30 | norm: 1.64\n",
      "step : 2541 | loss: 2.814582347869873 | dt: 170.20 ms | tokens/sec: 36.10 | norm: 1.57\n",
      "step : 2542 | loss: 2.6863794326782227 | dt: 171.64 ms | tokens/sec: 35.80 | norm: 1.82\n",
      "step : 2543 | loss: 2.7566230297088623 | dt: 170.08 ms | tokens/sec: 36.12 | norm: 1.67\n",
      "step : 2544 | loss: 2.5841407775878906 | dt: 170.35 ms | tokens/sec: 36.07 | norm: 1.42\n",
      "step : 2545 | loss: 2.5652084350585938 | dt: 170.39 ms | tokens/sec: 36.06 | norm: 2.14\n",
      "step : 2546 | loss: 2.740938901901245 | dt: 170.63 ms | tokens/sec: 36.01 | norm: 1.85\n",
      "step : 2547 | loss: 2.836867332458496 | dt: 170.12 ms | tokens/sec: 36.11 | norm: 1.83\n",
      "step : 2548 | loss: 2.7412822246551514 | dt: 171.54 ms | tokens/sec: 35.82 | norm: 1.76\n",
      "step : 2549 | loss: 2.752826690673828 | dt: 169.14 ms | tokens/sec: 36.32 | norm: 1.65\n",
      "step : 2550 | loss: 2.781628370285034 | dt: 170.77 ms | tokens/sec: 35.98 | norm: 2.02\n",
      "step : 2551 | loss: 2.6149744987487793 | dt: 170.38 ms | tokens/sec: 36.06 | norm: 1.64\n",
      "step : 2552 | loss: 2.7114710807800293 | dt: 170.34 ms | tokens/sec: 36.07 | norm: 2.29\n",
      "step : 2553 | loss: 2.879730224609375 | dt: 169.73 ms | tokens/sec: 36.20 | norm: 1.82\n",
      "step : 2554 | loss: 2.8182406425476074 | dt: 170.18 ms | tokens/sec: 36.10 | norm: 1.78\n",
      "step : 2555 | loss: 2.647340774536133 | dt: 170.35 ms | tokens/sec: 36.07 | norm: 1.49\n",
      "step : 2556 | loss: 2.8833727836608887 | dt: 170.16 ms | tokens/sec: 36.11 | norm: 1.67\n",
      "step : 2557 | loss: 2.7316761016845703 | dt: 170.62 ms | tokens/sec: 36.01 | norm: 1.68\n",
      "step : 2558 | loss: 2.8805465698242188 | dt: 170.32 ms | tokens/sec: 36.07 | norm: 2.46\n",
      "step : 2559 | loss: 2.8932273387908936 | dt: 170.19 ms | tokens/sec: 36.10 | norm: 1.97\n",
      "step : 2560 | loss: 2.982133626937866 | dt: 169.75 ms | tokens/sec: 36.19 | norm: 1.77\n",
      "step : 2561 | loss: 2.7760581970214844 | dt: 170.76 ms | tokens/sec: 35.98 | norm: 1.81\n",
      "step : 2562 | loss: 2.699382781982422 | dt: 169.82 ms | tokens/sec: 36.18 | norm: 2.01\n",
      "step : 2563 | loss: 2.7819745540618896 | dt: 170.18 ms | tokens/sec: 36.10 | norm: 1.61\n",
      "step : 2564 | loss: 2.692049026489258 | dt: 170.46 ms | tokens/sec: 36.04 | norm: 1.71\n",
      "step : 2565 | loss: 2.7570695877075195 | dt: 170.56 ms | tokens/sec: 36.02 | norm: 1.78\n",
      "step : 2566 | loss: 3.045858383178711 | dt: 171.00 ms | tokens/sec: 35.93 | norm: 1.86\n",
      "step : 2567 | loss: 3.002635955810547 | dt: 171.14 ms | tokens/sec: 35.90 | norm: 1.89\n",
      "step : 2568 | loss: 3.0637621879577637 | dt: 170.65 ms | tokens/sec: 36.00 | norm: 1.70\n",
      "step : 2569 | loss: 2.9523673057556152 | dt: 169.28 ms | tokens/sec: 36.29 | norm: 1.73\n",
      "step : 2570 | loss: 2.8373591899871826 | dt: 170.53 ms | tokens/sec: 36.03 | norm: 1.66\n",
      "step : 2571 | loss: 2.920858860015869 | dt: 169.88 ms | tokens/sec: 36.17 | norm: 1.60\n",
      "step : 2572 | loss: 2.7825849056243896 | dt: 169.99 ms | tokens/sec: 36.14 | norm: 1.70\n",
      "step : 2573 | loss: 2.639394521713257 | dt: 171.01 ms | tokens/sec: 35.93 | norm: 1.68\n",
      "step : 2574 | loss: 2.7103536128997803 | dt: 170.95 ms | tokens/sec: 35.94 | norm: 1.54\n",
      "step : 2575 | loss: 2.66131591796875 | dt: 171.11 ms | tokens/sec: 35.91 | norm: 1.68\n",
      "step : 2576 | loss: 2.51410174369812 | dt: 170.29 ms | tokens/sec: 36.08 | norm: 1.64\n",
      "step : 2577 | loss: 2.553556203842163 | dt: 170.78 ms | tokens/sec: 35.98 | norm: 1.58\n",
      "step : 2578 | loss: 2.8257272243499756 | dt: 169.86 ms | tokens/sec: 36.17 | norm: 1.68\n",
      "step : 2579 | loss: 2.8203625679016113 | dt: 171.25 ms | tokens/sec: 35.88 | norm: 1.85\n",
      "step : 2580 | loss: 2.6269567012786865 | dt: 168.82 ms | tokens/sec: 36.39 | norm: 1.70\n",
      "step : 2581 | loss: 2.538181781768799 | dt: 169.63 ms | tokens/sec: 36.22 | norm: 1.94\n",
      "step : 2582 | loss: 2.6034700870513916 | dt: 169.13 ms | tokens/sec: 36.33 | norm: 1.74\n",
      "step : 2583 | loss: 2.3260231018066406 | dt: 170.31 ms | tokens/sec: 36.08 | norm: 1.55\n",
      "step : 2584 | loss: 2.8628764152526855 | dt: 170.83 ms | tokens/sec: 35.97 | norm: 1.89\n",
      "step : 2585 | loss: 2.7773663997650146 | dt: 170.58 ms | tokens/sec: 36.02 | norm: 2.33\n",
      "step : 2586 | loss: 2.877277374267578 | dt: 170.17 ms | tokens/sec: 36.11 | norm: 1.84\n",
      "step : 2587 | loss: 2.84854793548584 | dt: 169.54 ms | tokens/sec: 36.24 | norm: 1.81\n",
      "step : 2588 | loss: 2.780505895614624 | dt: 170.29 ms | tokens/sec: 36.08 | norm: 1.92\n",
      "step : 2589 | loss: 2.5781304836273193 | dt: 170.04 ms | tokens/sec: 36.13 | norm: 1.60\n",
      "step : 2590 | loss: 2.564228057861328 | dt: 169.91 ms | tokens/sec: 36.16 | norm: 1.52\n",
      "step : 2591 | loss: 2.584228992462158 | dt: 167.89 ms | tokens/sec: 36.59 | norm: 2.35\n",
      "step : 2592 | loss: 2.7181167602539062 | dt: 165.61 ms | tokens/sec: 37.10 | norm: 1.86\n",
      "step : 2593 | loss: 2.781376600265503 | dt: 165.39 ms | tokens/sec: 37.15 | norm: 2.37\n",
      "step : 2594 | loss: 2.8316543102264404 | dt: 165.84 ms | tokens/sec: 37.05 | norm: 1.95\n",
      "step : 2595 | loss: 2.6757819652557373 | dt: 166.03 ms | tokens/sec: 37.01 | norm: 1.85\n",
      "step : 2596 | loss: 2.759927749633789 | dt: 166.42 ms | tokens/sec: 36.92 | norm: 1.83\n",
      "step : 2597 | loss: 2.682720899581909 | dt: 165.94 ms | tokens/sec: 37.03 | norm: 1.72\n",
      "step : 2598 | loss: 2.733907699584961 | dt: 166.91 ms | tokens/sec: 36.81 | norm: 1.94\n",
      "step : 2599 | loss: 2.5629801750183105 | dt: 166.00 ms | tokens/sec: 37.01 | norm: 1.63\n",
      "step : 2600 | loss: 2.5653927326202393 | dt: 166.42 ms | tokens/sec: 36.92 | norm: 2.08\n",
      "step : 2601 | loss: 2.7292914390563965 | dt: 166.67 ms | tokens/sec: 36.86 | norm: 1.99\n",
      "step : 2602 | loss: 2.7980220317840576 | dt: 166.61 ms | tokens/sec: 36.88 | norm: 1.72\n",
      "step : 2603 | loss: 2.7007853984832764 | dt: 166.54 ms | tokens/sec: 36.89 | norm: 1.65\n",
      "step : 2604 | loss: 2.714536190032959 | dt: 167.26 ms | tokens/sec: 36.73 | norm: 1.65\n",
      "step : 2605 | loss: 2.7381091117858887 | dt: 165.97 ms | tokens/sec: 37.02 | norm: 1.80\n",
      "step : 2606 | loss: 2.569619655609131 | dt: 166.78 ms | tokens/sec: 36.84 | norm: 1.52\n",
      "step : 2607 | loss: 2.661376714706421 | dt: 166.40 ms | tokens/sec: 36.92 | norm: 1.66\n",
      "step : 2608 | loss: 2.7769064903259277 | dt: 166.58 ms | tokens/sec: 36.88 | norm: 1.81\n",
      "step : 2609 | loss: 2.7249274253845215 | dt: 166.69 ms | tokens/sec: 36.86 | norm: 1.68\n",
      "step : 2610 | loss: 2.5548970699310303 | dt: 166.73 ms | tokens/sec: 36.85 | norm: 1.43\n",
      "step : 2611 | loss: 2.7744593620300293 | dt: 166.35 ms | tokens/sec: 36.93 | norm: 1.57\n",
      "step : 2612 | loss: 2.6211562156677246 | dt: 166.86 ms | tokens/sec: 36.82 | norm: 1.45\n",
      "step : 2613 | loss: 2.838514804840088 | dt: 166.40 ms | tokens/sec: 36.92 | norm: 2.01\n",
      "step : 2614 | loss: 2.8214805126190186 | dt: 166.58 ms | tokens/sec: 36.88 | norm: 1.94\n",
      "step : 2615 | loss: 2.8852782249450684 | dt: 167.05 ms | tokens/sec: 36.78 | norm: 1.80\n",
      "step : 2616 | loss: 2.7112674713134766 | dt: 167.50 ms | tokens/sec: 36.68 | norm: 1.68\n",
      "step : 2617 | loss: 2.6408767700195312 | dt: 166.07 ms | tokens/sec: 37.00 | norm: 1.83\n",
      "step : 2618 | loss: 2.7045106887817383 | dt: 165.95 ms | tokens/sec: 37.02 | norm: 1.63\n",
      "step : 2619 | loss: 2.607229709625244 | dt: 166.83 ms | tokens/sec: 36.83 | norm: 1.76\n",
      "step : 2620 | loss: 2.674935817718506 | dt: 166.29 ms | tokens/sec: 36.95 | norm: 1.60\n",
      "step : 2621 | loss: 2.9207916259765625 | dt: 166.03 ms | tokens/sec: 37.00 | norm: 1.89\n",
      "step : 2622 | loss: 2.919278621673584 | dt: 166.99 ms | tokens/sec: 36.79 | norm: 2.06\n",
      "step : 2623 | loss: 2.967289924621582 | dt: 167.62 ms | tokens/sec: 36.66 | norm: 1.73\n",
      "step : 2624 | loss: 2.830371618270874 | dt: 165.95 ms | tokens/sec: 37.02 | norm: 1.66\n",
      "step : 2625 | loss: 2.7277209758758545 | dt: 166.69 ms | tokens/sec: 36.86 | norm: 1.42\n",
      "step : 2626 | loss: 2.8595759868621826 | dt: 166.30 ms | tokens/sec: 36.94 | norm: 1.67\n",
      "step : 2627 | loss: 2.757401943206787 | dt: 166.13 ms | tokens/sec: 36.98 | norm: 1.65\n",
      "step : 2628 | loss: 2.601080894470215 | dt: 166.79 ms | tokens/sec: 36.84 | norm: 1.58\n",
      "step : 2629 | loss: 2.640174388885498 | dt: 167.06 ms | tokens/sec: 36.78 | norm: 1.62\n",
      "step : 2630 | loss: 2.6470351219177246 | dt: 165.79 ms | tokens/sec: 37.06 | norm: 2.14\n",
      "step : 2631 | loss: 2.5060951709747314 | dt: 167.45 ms | tokens/sec: 36.69 | norm: 1.74\n",
      "step : 2632 | loss: 2.51820707321167 | dt: 166.54 ms | tokens/sec: 36.89 | norm: 4.39\n",
      "step : 2633 | loss: 2.7911791801452637 | dt: 165.92 ms | tokens/sec: 37.03 | norm: 1.84\n",
      "step : 2634 | loss: 2.804427146911621 | dt: 167.29 ms | tokens/sec: 36.73 | norm: 2.22\n",
      "step : 2635 | loss: 2.6368446350097656 | dt: 167.23 ms | tokens/sec: 36.74 | norm: 1.65\n",
      "step : 2636 | loss: 2.540722131729126 | dt: 166.11 ms | tokens/sec: 36.99 | norm: 2.01\n",
      "step : 2637 | loss: 2.549557685852051 | dt: 167.27 ms | tokens/sec: 36.73 | norm: 1.62\n",
      "step : 2638 | loss: 2.280581474304199 | dt: 166.36 ms | tokens/sec: 36.93 | norm: 1.55\n",
      "step : 2639 | loss: 2.7771964073181152 | dt: 166.06 ms | tokens/sec: 37.00 | norm: 1.90\n",
      "step : 2640 | loss: 2.7411611080169678 | dt: 167.43 ms | tokens/sec: 36.70 | norm: 2.01\n",
      "step : 2641 | loss: 2.8253886699676514 | dt: 166.64 ms | tokens/sec: 36.87 | norm: 1.80\n",
      "step : 2642 | loss: 2.770604133605957 | dt: 166.07 ms | tokens/sec: 37.00 | norm: 1.75\n",
      "step : 2643 | loss: 2.71101713180542 | dt: 167.24 ms | tokens/sec: 36.74 | norm: 1.59\n",
      "step : 2644 | loss: 2.5164475440979004 | dt: 166.27 ms | tokens/sec: 36.95 | norm: 1.64\n",
      "step : 2645 | loss: 2.5301337242126465 | dt: 165.98 ms | tokens/sec: 37.02 | norm: 1.52\n",
      "step : 2646 | loss: 2.5655953884124756 | dt: 166.95 ms | tokens/sec: 36.80 | norm: 1.69\n",
      "step : 2647 | loss: 2.670968532562256 | dt: 166.64 ms | tokens/sec: 36.87 | norm: 1.77\n",
      "step : 2648 | loss: 2.7070701122283936 | dt: 166.93 ms | tokens/sec: 36.81 | norm: 2.02\n",
      "step : 2649 | loss: 2.733109951019287 | dt: 167.50 ms | tokens/sec: 36.68 | norm: 2.04\n",
      "step : 2650 | loss: 2.627650737762451 | dt: 166.30 ms | tokens/sec: 36.94 | norm: 1.61\n",
      "step : 2651 | loss: 2.671250820159912 | dt: 165.35 ms | tokens/sec: 37.16 | norm: 1.83\n",
      "step : 2652 | loss: 2.5646257400512695 | dt: 166.75 ms | tokens/sec: 36.85 | norm: 2.05\n",
      "step : 2653 | loss: 2.6356186866760254 | dt: 166.80 ms | tokens/sec: 36.83 | norm: 1.70\n",
      "step : 2654 | loss: 2.5025124549865723 | dt: 166.42 ms | tokens/sec: 36.92 | norm: 1.95\n",
      "step : 2655 | loss: 2.5194907188415527 | dt: 167.42 ms | tokens/sec: 36.70 | norm: 1.87\n",
      "step : 2656 | loss: 2.6718811988830566 | dt: 166.46 ms | tokens/sec: 36.91 | norm: 2.45\n",
      "step : 2657 | loss: 2.725590229034424 | dt: 165.79 ms | tokens/sec: 37.06 | norm: 1.93\n",
      "step : 2658 | loss: 2.672778606414795 | dt: 166.55 ms | tokens/sec: 36.89 | norm: 1.79\n",
      "step : 2659 | loss: 2.712688446044922 | dt: 166.48 ms | tokens/sec: 36.91 | norm: 2.02\n",
      "step : 2660 | loss: 2.7100989818573 | dt: 166.63 ms | tokens/sec: 36.87 | norm: 1.74\n",
      "step : 2661 | loss: 2.530254364013672 | dt: 167.14 ms | tokens/sec: 36.76 | norm: 1.71\n",
      "step : 2662 | loss: 2.6093969345092773 | dt: 166.69 ms | tokens/sec: 36.86 | norm: 1.80\n",
      "step : 2663 | loss: 2.7163991928100586 | dt: 165.87 ms | tokens/sec: 37.04 | norm: 2.07\n",
      "step : 2664 | loss: 2.6441259384155273 | dt: 166.60 ms | tokens/sec: 36.88 | norm: 1.91\n",
      "step : 2665 | loss: 2.488271713256836 | dt: 166.51 ms | tokens/sec: 36.90 | norm: 1.56\n",
      "step : 2666 | loss: 2.6956138610839844 | dt: 166.83 ms | tokens/sec: 36.83 | norm: 1.75\n",
      "step : 2667 | loss: 2.5614216327667236 | dt: 168.48 ms | tokens/sec: 36.47 | norm: 1.47\n",
      "step : 2668 | loss: 2.77105712890625 | dt: 166.16 ms | tokens/sec: 36.98 | norm: 1.84\n",
      "step : 2669 | loss: 2.757607936859131 | dt: 164.83 ms | tokens/sec: 37.27 | norm: 2.29\n",
      "step : 2670 | loss: 2.7829909324645996 | dt: 167.05 ms | tokens/sec: 36.78 | norm: 1.64\n",
      "step : 2671 | loss: 2.6020355224609375 | dt: 166.20 ms | tokens/sec: 36.97 | norm: 1.61\n",
      "step : 2672 | loss: 2.538750171661377 | dt: 166.64 ms | tokens/sec: 36.87 | norm: 1.47\n",
      "step : 2673 | loss: 2.6201729774475098 | dt: 167.92 ms | tokens/sec: 36.59 | norm: 1.53\n",
      "step : 2674 | loss: 2.5158908367156982 | dt: 166.06 ms | tokens/sec: 37.00 | norm: 1.72\n",
      "step : 2675 | loss: 2.541104793548584 | dt: 165.50 ms | tokens/sec: 37.12 | norm: 1.52\n",
      "step : 2676 | loss: 2.8308329582214355 | dt: 166.34 ms | tokens/sec: 36.94 | norm: 2.10\n",
      "step : 2677 | loss: 2.844494581222534 | dt: 166.06 ms | tokens/sec: 37.00 | norm: 1.80\n",
      "step : 2678 | loss: 2.8608882427215576 | dt: 166.23 ms | tokens/sec: 36.96 | norm: 1.60\n",
      "step : 2679 | loss: 2.73325514793396 | dt: 168.20 ms | tokens/sec: 36.53 | norm: 1.74\n",
      "step : 2680 | loss: 2.656879186630249 | dt: 165.89 ms | tokens/sec: 37.04 | norm: 1.52\n",
      "step : 2681 | loss: 2.772160291671753 | dt: 165.67 ms | tokens/sec: 37.09 | norm: 1.58\n",
      "step : 2682 | loss: 2.6442553997039795 | dt: 166.90 ms | tokens/sec: 36.81 | norm: 1.80\n",
      "step : 2683 | loss: 2.5268771648406982 | dt: 165.96 ms | tokens/sec: 37.02 | norm: 1.86\n",
      "step : 2684 | loss: 2.5613784790039062 | dt: 166.30 ms | tokens/sec: 36.95 | norm: 1.55\n",
      "step : 2685 | loss: 2.585753917694092 | dt: 167.64 ms | tokens/sec: 36.65 | norm: 1.94\n",
      "step : 2686 | loss: 2.424016237258911 | dt: 165.94 ms | tokens/sec: 37.03 | norm: 2.01\n",
      "step : 2687 | loss: 2.5407896041870117 | dt: 166.06 ms | tokens/sec: 37.00 | norm: 1.58\n",
      "step : 2688 | loss: 2.6802899837493896 | dt: 167.94 ms | tokens/sec: 36.58 | norm: 1.72\n",
      "step : 2689 | loss: 2.7188613414764404 | dt: 166.85 ms | tokens/sec: 36.82 | norm: 1.89\n",
      "step : 2690 | loss: 2.5291850566864014 | dt: 166.64 ms | tokens/sec: 36.87 | norm: 1.78\n",
      "step : 2691 | loss: 2.4792652130126953 | dt: 167.36 ms | tokens/sec: 36.71 | norm: 2.09\n",
      "step : 2692 | loss: 2.4650020599365234 | dt: 168.37 ms | tokens/sec: 36.49 | norm: 1.65\n",
      "step : 2693 | loss: 2.202129364013672 | dt: 165.11 ms | tokens/sec: 37.21 | norm: 2.45\n",
      "step : 2694 | loss: 2.7049031257629395 | dt: 166.89 ms | tokens/sec: 36.81 | norm: 1.86\n",
      "step : 2695 | loss: 2.691873550415039 | dt: 166.03 ms | tokens/sec: 37.00 | norm: 1.89\n",
      "step : 2696 | loss: 2.772979259490967 | dt: 165.80 ms | tokens/sec: 37.06 | norm: 2.04\n",
      "step : 2697 | loss: 2.7113139629364014 | dt: 166.64 ms | tokens/sec: 36.87 | norm: 1.81\n",
      "step : 2698 | loss: 2.624213218688965 | dt: 166.47 ms | tokens/sec: 36.91 | norm: 1.63\n",
      "step : 2699 | loss: 2.4338042736053467 | dt: 165.94 ms | tokens/sec: 37.03 | norm: 1.53\n",
      "step : 2700 | loss: 2.461298942565918 | dt: 167.72 ms | tokens/sec: 36.63 | norm: 1.43\n",
      "step : 2701 | loss: 2.4814727306365967 | dt: 166.00 ms | tokens/sec: 37.01 | norm: 1.63\n",
      "step : 2702 | loss: 2.606699228286743 | dt: 166.36 ms | tokens/sec: 36.93 | norm: 1.74\n",
      "step : 2703 | loss: 2.649651050567627 | dt: 167.69 ms | tokens/sec: 36.64 | norm: 2.17\n",
      "step : 2704 | loss: 2.6749439239501953 | dt: 168.54 ms | tokens/sec: 36.45 | norm: 1.78\n",
      "step : 2705 | loss: 2.5627689361572266 | dt: 165.94 ms | tokens/sec: 37.02 | norm: 2.02\n",
      "step : 2706 | loss: 2.6476197242736816 | dt: 168.60 ms | tokens/sec: 36.44 | norm: 2.40\n",
      "step : 2707 | loss: 2.5331435203552246 | dt: 166.67 ms | tokens/sec: 36.86 | norm: 1.62\n",
      "step : 2708 | loss: 2.569507598876953 | dt: 166.51 ms | tokens/sec: 36.90 | norm: 1.72\n",
      "step : 2709 | loss: 2.437004566192627 | dt: 167.54 ms | tokens/sec: 36.67 | norm: 1.59\n",
      "step : 2710 | loss: 2.448029041290283 | dt: 170.26 ms | tokens/sec: 36.09 | norm: 1.79\n",
      "step : 2711 | loss: 2.6282312870025635 | dt: 165.25 ms | tokens/sec: 37.18 | norm: 1.91\n",
      "step : 2712 | loss: 2.6555771827697754 | dt: 166.69 ms | tokens/sec: 36.86 | norm: 2.02\n",
      "step : 2713 | loss: 2.5730626583099365 | dt: 166.49 ms | tokens/sec: 36.90 | norm: 1.70\n",
      "step : 2714 | loss: 2.6480932235717773 | dt: 164.93 ms | tokens/sec: 37.25 | norm: 2.02\n",
      "step : 2715 | loss: 2.634497880935669 | dt: 167.93 ms | tokens/sec: 36.59 | norm: 2.30\n",
      "step : 2716 | loss: 2.4753732681274414 | dt: 166.60 ms | tokens/sec: 36.88 | norm: 1.69\n",
      "step : 2717 | loss: 2.580267906188965 | dt: 167.34 ms | tokens/sec: 36.71 | norm: 1.97\n",
      "step : 2718 | loss: 2.715579032897949 | dt: 166.14 ms | tokens/sec: 36.98 | norm: 2.51\n",
      "step : 2719 | loss: 2.637328863143921 | dt: 166.55 ms | tokens/sec: 36.89 | norm: 1.99\n",
      "step : 2720 | loss: 2.450562000274658 | dt: 165.16 ms | tokens/sec: 37.20 | norm: 1.83\n",
      "step : 2721 | loss: 2.645946502685547 | dt: 168.00 ms | tokens/sec: 36.57 | norm: 1.84\n",
      "step : 2722 | loss: 2.489737033843994 | dt: 166.19 ms | tokens/sec: 36.97 | norm: 1.43\n",
      "step : 2723 | loss: 2.7024779319763184 | dt: 165.77 ms | tokens/sec: 37.06 | norm: 1.80\n",
      "step : 2724 | loss: 2.703615188598633 | dt: 166.62 ms | tokens/sec: 36.87 | norm: 1.95\n",
      "step : 2725 | loss: 2.7095775604248047 | dt: 165.78 ms | tokens/sec: 37.06 | norm: 1.95\n",
      "step : 2726 | loss: 2.5266642570495605 | dt: 165.36 ms | tokens/sec: 37.15 | norm: 1.64\n",
      "step : 2727 | loss: 2.47995662689209 | dt: 168.25 ms | tokens/sec: 36.52 | norm: 1.73\n",
      "step : 2728 | loss: 2.576158285140991 | dt: 166.69 ms | tokens/sec: 36.86 | norm: 1.66\n",
      "step : 2729 | loss: 2.4849860668182373 | dt: 166.43 ms | tokens/sec: 36.92 | norm: 1.66\n",
      "step : 2730 | loss: 2.5179543495178223 | dt: 166.79 ms | tokens/sec: 36.84 | norm: 1.77\n",
      "step : 2731 | loss: 2.8085193634033203 | dt: 166.15 ms | tokens/sec: 36.98 | norm: 1.89\n",
      "step : 2732 | loss: 2.7795677185058594 | dt: 166.09 ms | tokens/sec: 36.99 | norm: 1.74\n",
      "step : 2733 | loss: 2.7738418579101562 | dt: 168.37 ms | tokens/sec: 36.49 | norm: 1.81\n",
      "step : 2734 | loss: 2.6427597999572754 | dt: 166.83 ms | tokens/sec: 36.83 | norm: 1.73\n",
      "step : 2735 | loss: 2.5592200756073 | dt: 167.21 ms | tokens/sec: 36.74 | norm: 1.56\n",
      "step : 2736 | loss: 2.674837112426758 | dt: 166.11 ms | tokens/sec: 36.99 | norm: 1.66\n",
      "step : 2737 | loss: 2.60540771484375 | dt: 166.63 ms | tokens/sec: 36.87 | norm: 1.70\n",
      "step : 2738 | loss: 2.5180346965789795 | dt: 164.95 ms | tokens/sec: 37.25 | norm: 1.93\n",
      "step : 2739 | loss: 2.5373659133911133 | dt: 167.90 ms | tokens/sec: 36.59 | norm: 2.02\n",
      "step : 2740 | loss: 2.5357666015625 | dt: 166.49 ms | tokens/sec: 36.90 | norm: 1.82\n",
      "step : 2741 | loss: 2.4008700847625732 | dt: 165.25 ms | tokens/sec: 37.18 | norm: 1.65\n",
      "step : 2742 | loss: 2.4671051502227783 | dt: 168.45 ms | tokens/sec: 36.47 | norm: 1.86\n",
      "step : 2743 | loss: 2.6308398246765137 | dt: 166.31 ms | tokens/sec: 36.94 | norm: 1.96\n",
      "step : 2744 | loss: 2.650700807571411 | dt: 165.91 ms | tokens/sec: 37.03 | norm: 1.68\n",
      "step : 2745 | loss: 2.4845681190490723 | dt: 167.96 ms | tokens/sec: 36.58 | norm: 1.72\n",
      "step : 2746 | loss: 2.4123570919036865 | dt: 166.41 ms | tokens/sec: 36.92 | norm: 1.59\n",
      "step : 2747 | loss: 2.401045322418213 | dt: 168.44 ms | tokens/sec: 36.48 | norm: 1.67\n",
      "step : 2748 | loss: 2.178466796875 | dt: 166.77 ms | tokens/sec: 36.84 | norm: 1.48\n",
      "step : 2749 | loss: 2.632498264312744 | dt: 168.73 ms | tokens/sec: 36.41 | norm: 3.10\n",
      "step : 2750 | loss: 2.6346230506896973 | dt: 169.34 ms | tokens/sec: 36.28 | norm: 2.00\n",
      "step : 2751 | loss: 2.693624496459961 | dt: 168.11 ms | tokens/sec: 36.55 | norm: 2.06\n",
      "step : 2752 | loss: 2.611135959625244 | dt: 168.53 ms | tokens/sec: 36.46 | norm: 2.11\n",
      "step : 2753 | loss: 2.546398162841797 | dt: 168.78 ms | tokens/sec: 36.40 | norm: 1.80\n",
      "step : 2754 | loss: 2.4163894653320312 | dt: 171.28 ms | tokens/sec: 35.87 | norm: 1.63\n",
      "step : 2755 | loss: 2.3998522758483887 | dt: 166.78 ms | tokens/sec: 36.84 | norm: 1.65\n",
      "step : 2756 | loss: 2.424720287322998 | dt: 169.07 ms | tokens/sec: 36.34 | norm: 1.70\n",
      "step : 2757 | loss: 2.5422399044036865 | dt: 168.70 ms | tokens/sec: 36.42 | norm: 1.64\n",
      "step : 2758 | loss: 2.587667226791382 | dt: 168.66 ms | tokens/sec: 36.43 | norm: 1.75\n",
      "step : 2759 | loss: 2.5707759857177734 | dt: 167.84 ms | tokens/sec: 36.61 | norm: 1.69\n",
      "step : 2760 | loss: 2.4706666469573975 | dt: 167.82 ms | tokens/sec: 36.61 | norm: 1.67\n",
      "step : 2761 | loss: 2.592909812927246 | dt: 167.52 ms | tokens/sec: 36.68 | norm: 1.62\n",
      "step : 2762 | loss: 2.45503306388855 | dt: 168.01 ms | tokens/sec: 36.57 | norm: 1.92\n",
      "step : 2763 | loss: 2.5000970363616943 | dt: 167.90 ms | tokens/sec: 36.59 | norm: 1.71\n",
      "step : 2764 | loss: 2.3359150886535645 | dt: 169.00 ms | tokens/sec: 36.35 | norm: 1.62\n",
      "step : 2765 | loss: 2.351734161376953 | dt: 168.80 ms | tokens/sec: 36.40 | norm: 1.64\n",
      "step : 2766 | loss: 2.500704765319824 | dt: 168.62 ms | tokens/sec: 36.44 | norm: 1.92\n",
      "step : 2767 | loss: 2.5666513442993164 | dt: 170.66 ms | tokens/sec: 36.00 | norm: 2.02\n",
      "step : 2768 | loss: 2.4591174125671387 | dt: 168.91 ms | tokens/sec: 36.37 | norm: 1.75\n",
      "step : 2769 | loss: 2.5172829627990723 | dt: 168.73 ms | tokens/sec: 36.41 | norm: 1.68\n",
      "step : 2770 | loss: 2.553445816040039 | dt: 170.01 ms | tokens/sec: 36.14 | norm: 1.79\n",
      "step : 2771 | loss: 2.3833203315734863 | dt: 167.80 ms | tokens/sec: 36.62 | norm: 1.65\n",
      "step : 2772 | loss: 2.4863457679748535 | dt: 168.77 ms | tokens/sec: 36.40 | norm: 1.66\n",
      "step : 2773 | loss: 2.61299204826355 | dt: 169.59 ms | tokens/sec: 36.23 | norm: 1.86\n",
      "step : 2774 | loss: 2.5545740127563477 | dt: 168.42 ms | tokens/sec: 36.48 | norm: 2.03\n",
      "step : 2775 | loss: 2.37150502204895 | dt: 168.02 ms | tokens/sec: 36.57 | norm: 1.63\n",
      "step : 2776 | loss: 2.6087679862976074 | dt: 167.04 ms | tokens/sec: 36.78 | norm: 1.85\n",
      "step : 2777 | loss: 2.4277961254119873 | dt: 167.74 ms | tokens/sec: 36.63 | norm: 1.91\n",
      "step : 2778 | loss: 2.632162570953369 | dt: 168.32 ms | tokens/sec: 36.50 | norm: 1.66\n",
      "step : 2779 | loss: 2.707078456878662 | dt: 169.48 ms | tokens/sec: 36.25 | norm: 2.07\n",
      "step : 2780 | loss: 2.6891019344329834 | dt: 168.24 ms | tokens/sec: 36.52 | norm: 1.89\n",
      "step : 2781 | loss: 2.4950501918792725 | dt: 168.20 ms | tokens/sec: 36.53 | norm: 1.82\n",
      "step : 2782 | loss: 2.4283344745635986 | dt: 168.79 ms | tokens/sec: 36.40 | norm: 1.90\n",
      "step : 2783 | loss: 2.4927806854248047 | dt: 168.73 ms | tokens/sec: 36.41 | norm: 1.64\n",
      "step : 2784 | loss: 2.3798489570617676 | dt: 168.69 ms | tokens/sec: 36.42 | norm: 1.72\n",
      "step : 2785 | loss: 2.4540019035339355 | dt: 168.07 ms | tokens/sec: 36.56 | norm: 1.59\n",
      "step : 2786 | loss: 2.734353542327881 | dt: 167.62 ms | tokens/sec: 36.65 | norm: 1.94\n",
      "step : 2787 | loss: 2.7433981895446777 | dt: 168.69 ms | tokens/sec: 36.42 | norm: 1.98\n",
      "step : 2788 | loss: 2.7863900661468506 | dt: 168.41 ms | tokens/sec: 36.48 | norm: 1.86\n",
      "step : 2789 | loss: 2.646852731704712 | dt: 168.34 ms | tokens/sec: 36.50 | norm: 1.80\n",
      "step : 2790 | loss: 2.5568456649780273 | dt: 167.71 ms | tokens/sec: 36.64 | norm: 1.78\n",
      "step : 2791 | loss: 2.662149667739868 | dt: 168.98 ms | tokens/sec: 36.36 | norm: 1.73\n",
      "step : 2792 | loss: 2.513869047164917 | dt: 168.48 ms | tokens/sec: 36.47 | norm: 1.76\n",
      "step : 2793 | loss: 2.4581167697906494 | dt: 168.14 ms | tokens/sec: 36.54 | norm: 1.84\n",
      "step : 2794 | loss: 2.460200309753418 | dt: 168.11 ms | tokens/sec: 36.55 | norm: 1.79\n",
      "step : 2795 | loss: 2.4712955951690674 | dt: 167.32 ms | tokens/sec: 36.72 | norm: 2.13\n",
      "step : 2796 | loss: 2.3274238109588623 | dt: 168.43 ms | tokens/sec: 36.48 | norm: 2.06\n",
      "step : 2797 | loss: 2.4006354808807373 | dt: 168.23 ms | tokens/sec: 36.52 | norm: 1.65\n",
      "step : 2798 | loss: 2.5981926918029785 | dt: 169.49 ms | tokens/sec: 36.25 | norm: 1.79\n",
      "step : 2799 | loss: 2.6245217323303223 | dt: 168.76 ms | tokens/sec: 36.41 | norm: 2.37\n",
      "step : 2800 | loss: 2.437480926513672 | dt: 168.30 ms | tokens/sec: 36.51 | norm: 2.00\n",
      "step : 2801 | loss: 2.3423614501953125 | dt: 168.37 ms | tokens/sec: 36.49 | norm: 2.01\n",
      "step : 2802 | loss: 2.324070930480957 | dt: 168.27 ms | tokens/sec: 36.51 | norm: 1.72\n",
      "step : 2803 | loss: 2.0979714393615723 | dt: 168.62 ms | tokens/sec: 36.44 | norm: 1.65\n",
      "step : 2804 | loss: 2.6284584999084473 | dt: 167.82 ms | tokens/sec: 36.61 | norm: 2.08\n",
      "step : 2805 | loss: 2.6040167808532715 | dt: 167.19 ms | tokens/sec: 36.75 | norm: 2.41\n",
      "step : 2806 | loss: 2.642756938934326 | dt: 167.47 ms | tokens/sec: 36.69 | norm: 2.47\n",
      "step : 2807 | loss: 2.5993120670318604 | dt: 168.05 ms | tokens/sec: 36.56 | norm: 2.25\n",
      "step : 2808 | loss: 2.5073201656341553 | dt: 167.21 ms | tokens/sec: 36.74 | norm: 1.98\n",
      "step : 2809 | loss: 2.3424811363220215 | dt: 166.48 ms | tokens/sec: 36.90 | norm: 1.86\n",
      "step : 2810 | loss: 2.38281512260437 | dt: 165.45 ms | tokens/sec: 37.13 | norm: 1.72\n",
      "step : 2811 | loss: 2.3811442852020264 | dt: 167.13 ms | tokens/sec: 36.76 | norm: 1.87\n",
      "step : 2812 | loss: 2.4874978065490723 | dt: 166.28 ms | tokens/sec: 36.95 | norm: 1.73\n",
      "step : 2813 | loss: 2.5628113746643066 | dt: 164.70 ms | tokens/sec: 37.30 | norm: 2.06\n",
      "step : 2814 | loss: 2.507390022277832 | dt: 165.66 ms | tokens/sec: 37.09 | norm: 1.87\n",
      "step : 2815 | loss: 2.430168628692627 | dt: 166.92 ms | tokens/sec: 36.81 | norm: 1.87\n",
      "step : 2816 | loss: 2.4800524711608887 | dt: 166.01 ms | tokens/sec: 37.01 | norm: 1.57\n",
      "step : 2817 | loss: 2.3949782848358154 | dt: 170.14 ms | tokens/sec: 36.11 | norm: 1.58\n",
      "step : 2818 | loss: 2.4408795833587646 | dt: 166.36 ms | tokens/sec: 36.93 | norm: 1.67\n",
      "step : 2819 | loss: 2.2744216918945312 | dt: 165.19 ms | tokens/sec: 37.19 | norm: 1.84\n",
      "step : 2820 | loss: 2.316178560256958 | dt: 165.77 ms | tokens/sec: 37.06 | norm: 2.08\n",
      "step : 2821 | loss: 2.461186647415161 | dt: 165.94 ms | tokens/sec: 37.02 | norm: 2.08\n",
      "step : 2822 | loss: 2.5464484691619873 | dt: 165.57 ms | tokens/sec: 37.11 | norm: 1.99\n",
      "step : 2823 | loss: 2.4428138732910156 | dt: 168.10 ms | tokens/sec: 36.55 | norm: 1.98\n",
      "step : 2824 | loss: 2.4586877822875977 | dt: 166.09 ms | tokens/sec: 36.99 | norm: 1.95\n",
      "step : 2825 | loss: 2.4897513389587402 | dt: 165.34 ms | tokens/sec: 37.16 | norm: 1.72\n",
      "step : 2826 | loss: 2.3020544052124023 | dt: 165.59 ms | tokens/sec: 37.10 | norm: 1.64\n",
      "step : 2827 | loss: 2.4120283126831055 | dt: 166.52 ms | tokens/sec: 36.90 | norm: 1.81\n",
      "step : 2828 | loss: 2.512070655822754 | dt: 166.39 ms | tokens/sec: 36.93 | norm: 1.93\n",
      "step : 2829 | loss: 2.4732608795166016 | dt: 167.27 ms | tokens/sec: 36.73 | norm: 1.79\n",
      "step : 2830 | loss: 2.3052616119384766 | dt: 167.01 ms | tokens/sec: 36.79 | norm: 1.59\n",
      "step : 2831 | loss: 2.5115458965301514 | dt: 166.21 ms | tokens/sec: 36.97 | norm: 1.97\n",
      "step : 2832 | loss: 2.3766446113586426 | dt: 165.68 ms | tokens/sec: 37.08 | norm: 1.70\n",
      "step : 2833 | loss: 2.555861234664917 | dt: 167.08 ms | tokens/sec: 36.77 | norm: 1.93\n",
      "step : 2834 | loss: 2.6531262397766113 | dt: 166.14 ms | tokens/sec: 36.98 | norm: 2.08\n",
      "step : 2835 | loss: 2.687350273132324 | dt: 167.63 ms | tokens/sec: 36.65 | norm: 2.13\n",
      "step : 2836 | loss: 2.4653968811035156 | dt: 167.56 ms | tokens/sec: 36.67 | norm: 2.02\n",
      "step : 2837 | loss: 2.3901755809783936 | dt: 165.84 ms | tokens/sec: 37.05 | norm: 1.76\n",
      "step : 2838 | loss: 2.4380054473876953 | dt: 165.74 ms | tokens/sec: 37.07 | norm: 1.67\n",
      "step : 2839 | loss: 2.3356003761291504 | dt: 167.12 ms | tokens/sec: 36.76 | norm: 1.61\n",
      "step : 2840 | loss: 2.3754498958587646 | dt: 165.81 ms | tokens/sec: 37.05 | norm: 1.65\n",
      "step : 2841 | loss: 2.6610655784606934 | dt: 168.21 ms | tokens/sec: 36.53 | norm: 2.19\n",
      "step : 2842 | loss: 2.6876583099365234 | dt: 166.98 ms | tokens/sec: 36.79 | norm: 1.79\n",
      "step : 2843 | loss: 2.6860084533691406 | dt: 166.17 ms | tokens/sec: 36.97 | norm: 1.89\n",
      "step : 2844 | loss: 2.5608980655670166 | dt: 167.75 ms | tokens/sec: 36.62 | norm: 1.76\n",
      "step : 2845 | loss: 2.507650852203369 | dt: 166.12 ms | tokens/sec: 36.99 | norm: 1.83\n",
      "step : 2846 | loss: 2.6080234050750732 | dt: 165.50 ms | tokens/sec: 37.12 | norm: 1.80\n",
      "step : 2847 | loss: 2.460000514984131 | dt: 166.61 ms | tokens/sec: 36.88 | norm: 1.87\n",
      "step : 2848 | loss: 2.4212656021118164 | dt: 167.07 ms | tokens/sec: 36.77 | norm: 2.49\n",
      "step : 2849 | loss: 2.4065842628479004 | dt: 165.71 ms | tokens/sec: 37.08 | norm: 1.80\n",
      "step : 2850 | loss: 2.4553565979003906 | dt: 165.64 ms | tokens/sec: 37.09 | norm: 1.84\n",
      "step : 2851 | loss: 2.311117172241211 | dt: 167.24 ms | tokens/sec: 36.74 | norm: 1.82\n",
      "step : 2852 | loss: 2.3363733291625977 | dt: 165.86 ms | tokens/sec: 37.04 | norm: 1.81\n",
      "step : 2853 | loss: 2.4930639266967773 | dt: 166.89 ms | tokens/sec: 36.81 | norm: 1.60\n",
      "step : 2854 | loss: 2.5463643074035645 | dt: 168.03 ms | tokens/sec: 36.56 | norm: 1.90\n",
      "step : 2855 | loss: 2.3716652393341064 | dt: 165.26 ms | tokens/sec: 37.18 | norm: 1.97\n",
      "step : 2856 | loss: 2.2845892906188965 | dt: 165.68 ms | tokens/sec: 37.08 | norm: 1.67\n",
      "step : 2857 | loss: 2.257676601409912 | dt: 166.72 ms | tokens/sec: 36.85 | norm: 1.62\n",
      "step : 2858 | loss: 2.077366352081299 | dt: 165.70 ms | tokens/sec: 37.08 | norm: 1.63\n",
      "step : 2859 | loss: 2.5178284645080566 | dt: 167.01 ms | tokens/sec: 36.79 | norm: 2.05\n",
      "step : 2860 | loss: 2.504915952682495 | dt: 167.87 ms | tokens/sec: 36.60 | norm: 1.93\n",
      "step : 2861 | loss: 2.5902087688446045 | dt: 165.75 ms | tokens/sec: 37.07 | norm: 2.25\n",
      "step : 2862 | loss: 2.532052993774414 | dt: 165.85 ms | tokens/sec: 37.05 | norm: 1.77\n",
      "step : 2863 | loss: 2.463078260421753 | dt: 167.35 ms | tokens/sec: 36.71 | norm: 1.84\n",
      "step : 2864 | loss: 2.2734367847442627 | dt: 166.47 ms | tokens/sec: 36.91 | norm: 1.65\n",
      "step : 2865 | loss: 2.300358295440674 | dt: 166.70 ms | tokens/sec: 36.86 | norm: 2.44\n",
      "step : 2866 | loss: 2.3006656169891357 | dt: 166.91 ms | tokens/sec: 36.81 | norm: 1.53\n",
      "step : 2867 | loss: 2.4109818935394287 | dt: 166.29 ms | tokens/sec: 36.95 | norm: 1.72\n",
      "step : 2868 | loss: 2.4600629806518555 | dt: 165.82 ms | tokens/sec: 37.05 | norm: 1.82\n",
      "step : 2869 | loss: 2.4215352535247803 | dt: 167.14 ms | tokens/sec: 36.76 | norm: 1.88\n",
      "step : 2870 | loss: 2.3350629806518555 | dt: 165.52 ms | tokens/sec: 37.12 | norm: 1.58\n",
      "step : 2871 | loss: 2.390838146209717 | dt: 167.13 ms | tokens/sec: 36.76 | norm: 1.68\n",
      "step : 2872 | loss: 2.312386989593506 | dt: 166.85 ms | tokens/sec: 36.82 | norm: 1.61\n",
      "step : 2873 | loss: 2.3498504161834717 | dt: 167.01 ms | tokens/sec: 36.79 | norm: 1.86\n",
      "step : 2874 | loss: 2.2063307762145996 | dt: 165.71 ms | tokens/sec: 37.08 | norm: 1.74\n",
      "step : 2875 | loss: 2.2505481243133545 | dt: 167.18 ms | tokens/sec: 36.75 | norm: 1.93\n",
      "step : 2876 | loss: 2.38767671585083 | dt: 165.60 ms | tokens/sec: 37.10 | norm: 2.16\n",
      "step : 2877 | loss: 2.495783805847168 | dt: 167.10 ms | tokens/sec: 36.77 | norm: 1.86\n",
      "step : 2878 | loss: 2.365631580352783 | dt: 166.98 ms | tokens/sec: 36.79 | norm: 2.23\n",
      "step : 2879 | loss: 2.382345676422119 | dt: 167.50 ms | tokens/sec: 36.68 | norm: 1.89\n",
      "step : 2880 | loss: 2.404106855392456 | dt: 165.56 ms | tokens/sec: 37.11 | norm: 1.86\n",
      "step : 2881 | loss: 2.2266836166381836 | dt: 167.07 ms | tokens/sec: 36.77 | norm: 1.83\n",
      "step : 2882 | loss: 2.34183931350708 | dt: 166.05 ms | tokens/sec: 37.00 | norm: 1.88\n",
      "step : 2883 | loss: 2.428811550140381 | dt: 166.97 ms | tokens/sec: 36.80 | norm: 2.30\n",
      "step : 2884 | loss: 2.4082555770874023 | dt: 166.80 ms | tokens/sec: 36.83 | norm: 1.79\n",
      "step : 2885 | loss: 2.2365922927856445 | dt: 166.74 ms | tokens/sec: 36.85 | norm: 1.57\n",
      "step : 2886 | loss: 2.46382999420166 | dt: 166.81 ms | tokens/sec: 36.83 | norm: 1.96\n",
      "step : 2887 | loss: 2.313948392868042 | dt: 167.01 ms | tokens/sec: 36.79 | norm: 1.73\n",
      "step : 2888 | loss: 2.456427812576294 | dt: 166.55 ms | tokens/sec: 36.89 | norm: 1.82\n",
      "step : 2889 | loss: 2.5190587043762207 | dt: 166.57 ms | tokens/sec: 36.88 | norm: 1.73\n",
      "step : 2890 | loss: 2.5246992111206055 | dt: 166.93 ms | tokens/sec: 36.81 | norm: 1.80\n",
      "step : 2891 | loss: 2.3276753425598145 | dt: 166.42 ms | tokens/sec: 36.92 | norm: 1.72\n",
      "step : 2892 | loss: 2.311021327972412 | dt: 166.54 ms | tokens/sec: 36.89 | norm: 1.74\n",
      "step : 2893 | loss: 2.3734521865844727 | dt: 166.06 ms | tokens/sec: 37.00 | norm: 1.75\n",
      "step : 2894 | loss: 2.2446539402008057 | dt: 165.82 ms | tokens/sec: 37.05 | norm: 1.57\n",
      "step : 2895 | loss: 2.3003082275390625 | dt: 166.91 ms | tokens/sec: 36.81 | norm: 1.67\n",
      "step : 2896 | loss: 2.6536691188812256 | dt: 166.92 ms | tokens/sec: 36.81 | norm: 2.30\n",
      "step : 2897 | loss: 2.5947012901306152 | dt: 165.81 ms | tokens/sec: 37.05 | norm: 1.73\n",
      "step : 2898 | loss: 2.5911850929260254 | dt: 166.75 ms | tokens/sec: 36.85 | norm: 1.89\n",
      "step : 2899 | loss: 2.4555232524871826 | dt: 166.99 ms | tokens/sec: 36.79 | norm: 1.77\n",
      "step : 2900 | loss: 2.3934454917907715 | dt: 165.82 ms | tokens/sec: 37.05 | norm: 1.63\n",
      "step : 2901 | loss: 2.511927604675293 | dt: 166.80 ms | tokens/sec: 36.83 | norm: 1.78\n",
      "step : 2902 | loss: 2.4131016731262207 | dt: 167.55 ms | tokens/sec: 36.67 | norm: 1.88\n",
      "step : 2903 | loss: 2.4213461875915527 | dt: 165.59 ms | tokens/sec: 37.10 | norm: 2.19\n",
      "step : 2904 | loss: 2.3780198097229004 | dt: 166.43 ms | tokens/sec: 36.92 | norm: 1.85\n",
      "step : 2905 | loss: 2.3634002208709717 | dt: 167.32 ms | tokens/sec: 36.72 | norm: 1.79\n",
      "step : 2906 | loss: 2.2237324714660645 | dt: 165.81 ms | tokens/sec: 37.05 | norm: 1.68\n",
      "step : 2907 | loss: 2.274716854095459 | dt: 166.79 ms | tokens/sec: 36.84 | norm: 1.64\n",
      "step : 2908 | loss: 2.427816390991211 | dt: 166.90 ms | tokens/sec: 36.81 | norm: 1.99\n",
      "step : 2909 | loss: 2.4666924476623535 | dt: 166.13 ms | tokens/sec: 36.98 | norm: 2.90\n",
      "step : 2910 | loss: 2.30934476852417 | dt: 167.60 ms | tokens/sec: 36.66 | norm: 1.88\n",
      "step : 2911 | loss: 2.1956706047058105 | dt: 166.89 ms | tokens/sec: 36.81 | norm: 1.88\n",
      "step : 2912 | loss: 2.178165912628174 | dt: 166.05 ms | tokens/sec: 37.00 | norm: 1.56\n",
      "step : 2913 | loss: 1.979229211807251 | dt: 167.46 ms | tokens/sec: 36.69 | norm: 1.45\n",
      "step : 2914 | loss: 2.4148738384246826 | dt: 166.43 ms | tokens/sec: 36.92 | norm: 1.63\n",
      "step : 2915 | loss: 2.3881442546844482 | dt: 165.99 ms | tokens/sec: 37.01 | norm: 1.97\n",
      "step : 2916 | loss: 2.48160982131958 | dt: 165.86 ms | tokens/sec: 37.04 | norm: 1.84\n",
      "step : 2917 | loss: 2.399955987930298 | dt: 168.13 ms | tokens/sec: 36.54 | norm: 2.08\n",
      "step : 2918 | loss: 2.351595878601074 | dt: 166.14 ms | tokens/sec: 36.98 | norm: 1.70\n",
      "step : 2919 | loss: 2.175654172897339 | dt: 166.72 ms | tokens/sec: 36.85 | norm: 1.54\n",
      "step : 2920 | loss: 2.263352870941162 | dt: 166.82 ms | tokens/sec: 36.83 | norm: 1.66\n",
      "step : 2921 | loss: 2.202624797821045 | dt: 165.55 ms | tokens/sec: 37.11 | norm: 1.68\n",
      "step : 2922 | loss: 2.346071720123291 | dt: 165.70 ms | tokens/sec: 37.08 | norm: 1.69\n",
      "step : 2923 | loss: 2.3619489669799805 | dt: 167.58 ms | tokens/sec: 36.66 | norm: 1.60\n",
      "step : 2924 | loss: 2.3546459674835205 | dt: 165.75 ms | tokens/sec: 37.07 | norm: 1.61\n",
      "step : 2925 | loss: 2.2395191192626953 | dt: 167.54 ms | tokens/sec: 36.67 | norm: 1.72\n",
      "step : 2926 | loss: 2.3175954818725586 | dt: 166.74 ms | tokens/sec: 36.85 | norm: 1.58\n",
      "step : 2927 | loss: 2.229287624359131 | dt: 165.72 ms | tokens/sec: 37.07 | norm: 2.00\n",
      "step : 2928 | loss: 2.2622921466827393 | dt: 165.51 ms | tokens/sec: 37.12 | norm: 1.63\n",
      "step : 2929 | loss: 2.1297810077667236 | dt: 167.46 ms | tokens/sec: 36.69 | norm: 1.69\n",
      "step : 2930 | loss: 2.1595373153686523 | dt: 166.39 ms | tokens/sec: 36.92 | norm: 1.71\n",
      "step : 2931 | loss: 2.2959094047546387 | dt: 166.76 ms | tokens/sec: 36.84 | norm: 2.11\n",
      "step : 2932 | loss: 2.3794069290161133 | dt: 167.00 ms | tokens/sec: 36.79 | norm: 2.11\n",
      "step : 2933 | loss: 2.285080671310425 | dt: 165.77 ms | tokens/sec: 37.06 | norm: 1.89\n",
      "step : 2934 | loss: 2.301241636276245 | dt: 165.94 ms | tokens/sec: 37.03 | norm: 1.73\n",
      "step : 2935 | loss: 2.334242582321167 | dt: 168.09 ms | tokens/sec: 36.55 | norm: 1.84\n",
      "step : 2936 | loss: 2.150644540786743 | dt: 166.56 ms | tokens/sec: 36.89 | norm: 1.75\n",
      "step : 2937 | loss: 2.2764830589294434 | dt: 166.79 ms | tokens/sec: 36.84 | norm: 2.20\n",
      "step : 2938 | loss: 2.388115644454956 | dt: 167.00 ms | tokens/sec: 36.79 | norm: 2.00\n",
      "step : 2939 | loss: 2.3457727432250977 | dt: 166.18 ms | tokens/sec: 36.97 | norm: 1.96\n",
      "step : 2940 | loss: 2.1758203506469727 | dt: 165.71 ms | tokens/sec: 37.08 | norm: 1.65\n",
      "step : 2941 | loss: 2.4137017726898193 | dt: 167.21 ms | tokens/sec: 36.74 | norm: 2.01\n",
      "step : 2942 | loss: 2.2532222270965576 | dt: 166.30 ms | tokens/sec: 36.95 | norm: 1.54\n",
      "step : 2943 | loss: 2.4026293754577637 | dt: 166.72 ms | tokens/sec: 36.85 | norm: 1.96\n",
      "step : 2944 | loss: 2.4383459091186523 | dt: 167.02 ms | tokens/sec: 36.79 | norm: 1.96\n",
      "step : 2945 | loss: 2.45377516746521 | dt: 165.84 ms | tokens/sec: 37.05 | norm: 1.82\n",
      "step : 2946 | loss: 2.256956100463867 | dt: 165.86 ms | tokens/sec: 37.04 | norm: 1.84\n",
      "step : 2947 | loss: 2.217926025390625 | dt: 167.10 ms | tokens/sec: 36.77 | norm: 1.86\n",
      "step : 2948 | loss: 2.2927825450897217 | dt: 166.73 ms | tokens/sec: 36.85 | norm: 1.63\n",
      "step : 2949 | loss: 2.172790765762329 | dt: 166.83 ms | tokens/sec: 36.83 | norm: 1.60\n",
      "step : 2950 | loss: 2.2325358390808105 | dt: 166.92 ms | tokens/sec: 36.81 | norm: 1.69\n",
      "step : 2951 | loss: 2.563292980194092 | dt: 166.01 ms | tokens/sec: 37.01 | norm: 2.04\n",
      "step : 2952 | loss: 2.517242908477783 | dt: 165.81 ms | tokens/sec: 37.06 | norm: 1.81\n",
      "step : 2953 | loss: 2.5206117630004883 | dt: 167.10 ms | tokens/sec: 36.77 | norm: 1.98\n",
      "step : 2954 | loss: 2.3844127655029297 | dt: 167.31 ms | tokens/sec: 36.72 | norm: 1.79\n",
      "step : 2955 | loss: 2.33042311668396 | dt: 169.54 ms | tokens/sec: 36.24 | norm: 1.75\n",
      "step : 2956 | loss: 2.429530620574951 | dt: 166.27 ms | tokens/sec: 36.95 | norm: 1.64\n",
      "step : 2957 | loss: 2.3183536529541016 | dt: 164.34 ms | tokens/sec: 37.39 | norm: 1.56\n",
      "step : 2958 | loss: 2.3089065551757812 | dt: 165.67 ms | tokens/sec: 37.09 | norm: 1.63\n",
      "step : 2959 | loss: 2.273573398590088 | dt: 167.02 ms | tokens/sec: 36.79 | norm: 1.73\n",
      "step : 2960 | loss: 2.279384136199951 | dt: 165.85 ms | tokens/sec: 37.05 | norm: 1.85\n",
      "step : 2961 | loss: 2.1412088871002197 | dt: 167.30 ms | tokens/sec: 36.72 | norm: 1.76\n",
      "step : 2962 | loss: 2.2120256423950195 | dt: 166.85 ms | tokens/sec: 36.82 | norm: 1.93\n",
      "step : 2963 | loss: 2.3870205879211426 | dt: 165.99 ms | tokens/sec: 37.01 | norm: 2.19\n",
      "step : 2964 | loss: 2.4878804683685303 | dt: 165.72 ms | tokens/sec: 37.07 | norm: 2.16\n",
      "step : 2965 | loss: 2.3040952682495117 | dt: 166.97 ms | tokens/sec: 36.80 | norm: 1.99\n",
      "step : 2966 | loss: 2.186389923095703 | dt: 165.80 ms | tokens/sec: 37.06 | norm: 1.82\n",
      "step : 2967 | loss: 2.135145902633667 | dt: 167.74 ms | tokens/sec: 36.63 | norm: 1.81\n",
      "step : 2968 | loss: 1.9175457954406738 | dt: 167.00 ms | tokens/sec: 36.79 | norm: 1.50\n",
      "step : 2969 | loss: 2.3412909507751465 | dt: 166.04 ms | tokens/sec: 37.00 | norm: 2.14\n",
      "step : 2970 | loss: 2.321831464767456 | dt: 166.10 ms | tokens/sec: 36.99 | norm: 1.87\n",
      "step : 2971 | loss: 2.422908306121826 | dt: 167.37 ms | tokens/sec: 36.71 | norm: 2.01\n",
      "step : 2972 | loss: 2.3471908569335938 | dt: 166.36 ms | tokens/sec: 36.93 | norm: 1.84\n",
      "step : 2973 | loss: 2.2647862434387207 | dt: 167.80 ms | tokens/sec: 36.62 | norm: 1.73\n",
      "step : 2974 | loss: 2.124936103820801 | dt: 167.21 ms | tokens/sec: 36.74 | norm: 1.72\n",
      "step : 2975 | loss: 2.204563856124878 | dt: 165.55 ms | tokens/sec: 37.11 | norm: 1.76\n",
      "step : 2976 | loss: 2.1556944847106934 | dt: 165.51 ms | tokens/sec: 37.12 | norm: 1.77\n",
      "step : 2977 | loss: 2.291959047317505 | dt: 167.11 ms | tokens/sec: 36.77 | norm: 1.83\n",
      "step : 2978 | loss: 2.330293655395508 | dt: 166.03 ms | tokens/sec: 37.01 | norm: 2.06\n",
      "step : 2979 | loss: 2.3348026275634766 | dt: 168.66 ms | tokens/sec: 36.43 | norm: 2.26\n",
      "step : 2980 | loss: 2.239922046661377 | dt: 166.46 ms | tokens/sec: 36.91 | norm: 1.91\n",
      "step : 2981 | loss: 2.2748830318450928 | dt: 165.39 ms | tokens/sec: 37.15 | norm: 1.70\n",
      "step : 2982 | loss: 2.2164273262023926 | dt: 165.88 ms | tokens/sec: 37.04 | norm: 1.75\n",
      "step : 2983 | loss: 2.215614080429077 | dt: 166.91 ms | tokens/sec: 36.81 | norm: 1.58\n",
      "step : 2984 | loss: 2.077425479888916 | dt: 165.81 ms | tokens/sec: 37.05 | norm: 1.61\n",
      "step : 2985 | loss: 2.103065252304077 | dt: 167.19 ms | tokens/sec: 36.75 | norm: 1.70\n",
      "step : 2986 | loss: 2.255720376968384 | dt: 167.30 ms | tokens/sec: 36.73 | norm: 1.86\n",
      "step : 2987 | loss: 2.3227803707122803 | dt: 165.85 ms | tokens/sec: 37.05 | norm: 1.82\n",
      "step : 2988 | loss: 2.2407381534576416 | dt: 165.62 ms | tokens/sec: 37.10 | norm: 1.85\n",
      "step : 2989 | loss: 2.236081600189209 | dt: 166.79 ms | tokens/sec: 36.84 | norm: 1.75\n",
      "step : 2990 | loss: 2.270566940307617 | dt: 165.71 ms | tokens/sec: 37.08 | norm: 1.83\n",
      "step : 2991 | loss: 2.125394821166992 | dt: 167.75 ms | tokens/sec: 36.63 | norm: 1.83\n",
      "step : 2992 | loss: 2.249545097351074 | dt: 167.82 ms | tokens/sec: 36.61 | norm: 1.81\n",
      "step : 2993 | loss: 2.3281939029693604 | dt: 165.84 ms | tokens/sec: 37.05 | norm: 2.15\n",
      "step : 2994 | loss: 2.3074424266815186 | dt: 166.35 ms | tokens/sec: 36.93 | norm: 2.13\n",
      "step : 2995 | loss: 2.134884834289551 | dt: 166.94 ms | tokens/sec: 36.80 | norm: 1.96\n",
      "step : 2996 | loss: 2.366330862045288 | dt: 165.84 ms | tokens/sec: 37.05 | norm: 1.91\n",
      "step : 2997 | loss: 2.179152011871338 | dt: 167.15 ms | tokens/sec: 36.76 | norm: 1.74\n",
      "step : 2998 | loss: 2.3342843055725098 | dt: 167.31 ms | tokens/sec: 36.72 | norm: 1.74\n",
      "step : 2999 | loss: 2.353893995285034 | dt: 166.10 ms | tokens/sec: 36.99 | norm: 2.20\n",
      "step : 3000 | loss: 2.3639562129974365 | dt: 165.86 ms | tokens/sec: 37.04 | norm: 1.91\n",
      "step : 3001 | loss: 2.2079050540924072 | dt: 167.03 ms | tokens/sec: 36.78 | norm: 1.80\n",
      "step : 3002 | loss: 2.1556997299194336 | dt: 165.63 ms | tokens/sec: 37.09 | norm: 1.81\n",
      "step : 3003 | loss: 2.218897581100464 | dt: 167.02 ms | tokens/sec: 36.79 | norm: 1.59\n",
      "step : 3004 | loss: 2.1141867637634277 | dt: 168.04 ms | tokens/sec: 36.56 | norm: 1.81\n",
      "step : 3005 | loss: 2.164214611053467 | dt: 166.48 ms | tokens/sec: 36.91 | norm: 1.88\n",
      "step : 3006 | loss: 2.491081714630127 | dt: 165.91 ms | tokens/sec: 37.03 | norm: 2.32\n",
      "step : 3007 | loss: 2.4563100337982178 | dt: 167.09 ms | tokens/sec: 36.77 | norm: 2.05\n",
      "step : 3008 | loss: 2.4437732696533203 | dt: 165.74 ms | tokens/sec: 37.07 | norm: 1.88\n",
      "step : 3009 | loss: 2.3394575119018555 | dt: 167.29 ms | tokens/sec: 36.73 | norm: 1.89\n",
      "step : 3010 | loss: 2.269458055496216 | dt: 166.76 ms | tokens/sec: 36.84 | norm: 2.08\n",
      "step : 3011 | loss: 2.3780593872070312 | dt: 166.28 ms | tokens/sec: 36.95 | norm: 1.86\n",
      "step : 3012 | loss: 2.264260768890381 | dt: 165.90 ms | tokens/sec: 37.04 | norm: 1.86\n",
      "step : 3013 | loss: 2.249769926071167 | dt: 167.21 ms | tokens/sec: 36.74 | norm: 1.80\n",
      "step : 3014 | loss: 2.23298978805542 | dt: 166.30 ms | tokens/sec: 36.95 | norm: 1.78\n",
      "step : 3015 | loss: 2.246126651763916 | dt: 166.99 ms | tokens/sec: 36.79 | norm: 1.92\n",
      "step : 3016 | loss: 2.1038339138031006 | dt: 166.81 ms | tokens/sec: 36.83 | norm: 2.18\n",
      "step : 3017 | loss: 2.1507253646850586 | dt: 166.03 ms | tokens/sec: 37.01 | norm: 1.72\n",
      "step : 3018 | loss: 2.3113677501678467 | dt: 165.64 ms | tokens/sec: 37.09 | norm: 1.78\n",
      "step : 3019 | loss: 2.4082999229431152 | dt: 167.34 ms | tokens/sec: 36.72 | norm: 1.97\n",
      "step : 3020 | loss: 2.232011318206787 | dt: 166.18 ms | tokens/sec: 36.97 | norm: 1.82\n",
      "step : 3021 | loss: 2.1072096824645996 | dt: 166.95 ms | tokens/sec: 36.80 | norm: 1.92\n",
      "step : 3022 | loss: 2.0866410732269287 | dt: 167.43 ms | tokens/sec: 36.70 | norm: 1.76\n",
      "step : 3023 | loss: 1.8805469274520874 | dt: 168.46 ms | tokens/sec: 36.47 | norm: 1.66\n",
      "step : 3024 | loss: 2.3519814014434814 | dt: 166.04 ms | tokens/sec: 37.00 | norm: 2.32\n",
      "step : 3025 | loss: 2.3517861366271973 | dt: 165.71 ms | tokens/sec: 37.08 | norm: 2.37\n",
      "step : 3026 | loss: 2.518411636352539 | dt: 165.54 ms | tokens/sec: 37.11 | norm: 2.76\n",
      "step : 3027 | loss: 2.409538507461548 | dt: 166.76 ms | tokens/sec: 36.84 | norm: 2.40\n",
      "step : 3028 | loss: 2.359171152114868 | dt: 167.42 ms | tokens/sec: 36.70 | norm: 2.75\n",
      "step : 3029 | loss: 2.1568403244018555 | dt: 165.69 ms | tokens/sec: 37.08 | norm: 2.41\n",
      "step : 3030 | loss: 2.1661927700042725 | dt: 166.14 ms | tokens/sec: 36.98 | norm: 1.90\n",
      "step : 3031 | loss: 2.1073012351989746 | dt: 167.00 ms | tokens/sec: 36.79 | norm: 1.62\n",
      "step : 3032 | loss: 2.2363383769989014 | dt: 165.70 ms | tokens/sec: 37.08 | norm: 1.60\n",
      "step : 3033 | loss: 2.268618583679199 | dt: 166.93 ms | tokens/sec: 36.80 | norm: 2.06\n",
      "step : 3034 | loss: 2.2384915351867676 | dt: 166.63 ms | tokens/sec: 36.87 | norm: 1.82\n",
      "step : 3035 | loss: 2.164897918701172 | dt: 165.61 ms | tokens/sec: 37.10 | norm: 1.78\n",
      "step : 3036 | loss: 2.2427737712860107 | dt: 167.43 ms | tokens/sec: 36.70 | norm: 1.86\n",
      "step : 3037 | loss: 2.2033944129943848 | dt: 167.23 ms | tokens/sec: 36.74 | norm: 2.10\n",
      "step : 3038 | loss: 2.181427240371704 | dt: 165.82 ms | tokens/sec: 37.05 | norm: 1.80\n",
      "step : 3039 | loss: 2.0682876110076904 | dt: 166.97 ms | tokens/sec: 36.80 | norm: 2.11\n",
      "step : 3040 | loss: 2.0896830558776855 | dt: 166.86 ms | tokens/sec: 36.82 | norm: 1.99\n",
      "step : 3041 | loss: 2.2245748043060303 | dt: 166.34 ms | tokens/sec: 36.94 | norm: 2.07\n",
      "step : 3042 | loss: 2.258615493774414 | dt: 167.03 ms | tokens/sec: 36.78 | norm: 1.86\n",
      "step : 3043 | loss: 2.147125482559204 | dt: 166.87 ms | tokens/sec: 36.82 | norm: 1.59\n",
      "step : 3044 | loss: 2.139313220977783 | dt: 165.65 ms | tokens/sec: 37.09 | norm: 1.74\n",
      "step : 3045 | loss: 2.198488712310791 | dt: 166.65 ms | tokens/sec: 36.87 | norm: 1.72\n",
      "step : 3046 | loss: 2.0485410690307617 | dt: 166.10 ms | tokens/sec: 36.99 | norm: 1.84\n",
      "step : 3047 | loss: 2.1656203269958496 | dt: 165.24 ms | tokens/sec: 37.18 | norm: 1.78\n",
      "step : 3048 | loss: 2.2512643337249756 | dt: 166.52 ms | tokens/sec: 36.90 | norm: 1.79\n",
      "step : 3049 | loss: 2.2841193675994873 | dt: 166.52 ms | tokens/sec: 36.90 | norm: 2.07\n",
      "step : 3050 | loss: 2.103102684020996 | dt: 165.42 ms | tokens/sec: 37.14 | norm: 1.80\n",
      "step : 3051 | loss: 2.324965238571167 | dt: 167.14 ms | tokens/sec: 36.76 | norm: 2.15\n",
      "step : 3052 | loss: 2.168635129928589 | dt: 166.63 ms | tokens/sec: 36.87 | norm: 1.86\n",
      "step : 3053 | loss: 2.308469295501709 | dt: 165.33 ms | tokens/sec: 37.16 | norm: 1.84\n",
      "step : 3054 | loss: 2.379757881164551 | dt: 167.14 ms | tokens/sec: 36.76 | norm: 1.94\n",
      "step : 3055 | loss: 2.3609352111816406 | dt: 167.62 ms | tokens/sec: 36.65 | norm: 2.35\n",
      "step : 3056 | loss: 2.1832709312438965 | dt: 165.96 ms | tokens/sec: 37.02 | norm: 2.11\n",
      "step : 3057 | loss: 2.1505484580993652 | dt: 167.77 ms | tokens/sec: 36.62 | norm: 2.12\n",
      "step : 3058 | loss: 2.184161424636841 | dt: 166.81 ms | tokens/sec: 36.83 | norm: 1.82\n",
      "step : 3059 | loss: 2.068894147872925 | dt: 165.51 ms | tokens/sec: 37.12 | norm: 1.82\n",
      "step : 3060 | loss: 2.133582830429077 | dt: 166.30 ms | tokens/sec: 36.95 | norm: 1.95\n",
      "step : 3061 | loss: 2.442028284072876 | dt: 168.38 ms | tokens/sec: 36.49 | norm: 2.12\n",
      "step : 3062 | loss: 2.4011998176574707 | dt: 166.78 ms | tokens/sec: 36.84 | norm: 1.94\n",
      "step : 3063 | loss: 2.3989853858947754 | dt: 167.30 ms | tokens/sec: 36.73 | norm: 2.15\n",
      "step : 3064 | loss: 2.271456718444824 | dt: 167.44 ms | tokens/sec: 36.69 | norm: 2.16\n",
      "step : 3065 | loss: 2.2599306106567383 | dt: 166.36 ms | tokens/sec: 36.93 | norm: 2.03\n",
      "step : 3066 | loss: 2.3305397033691406 | dt: 167.54 ms | tokens/sec: 36.67 | norm: 2.18\n",
      "step : 3067 | loss: 2.206834554672241 | dt: 167.37 ms | tokens/sec: 36.71 | norm: 1.97\n",
      "step : 3068 | loss: 2.17846941947937 | dt: 166.17 ms | tokens/sec: 36.97 | norm: 1.82\n",
      "step : 3069 | loss: 2.17570161819458 | dt: 166.85 ms | tokens/sec: 36.82 | norm: 2.07\n",
      "step : 3070 | loss: 2.160834789276123 | dt: 165.80 ms | tokens/sec: 37.06 | norm: 1.76\n",
      "step : 3071 | loss: 2.0373997688293457 | dt: 165.73 ms | tokens/sec: 37.07 | norm: 1.73\n",
      "step : 3072 | loss: 2.084867000579834 | dt: 165.85 ms | tokens/sec: 37.05 | norm: 1.69\n",
      "step : 3073 | loss: 2.228604793548584 | dt: 168.15 ms | tokens/sec: 36.54 | norm: 1.83\n",
      "step : 3074 | loss: 2.338552951812744 | dt: 165.98 ms | tokens/sec: 37.02 | norm: 2.04\n",
      "step : 3075 | loss: 2.159757137298584 | dt: 166.75 ms | tokens/sec: 36.85 | norm: 1.75\n",
      "step : 3076 | loss: 2.0335192680358887 | dt: 167.30 ms | tokens/sec: 36.73 | norm: 1.83\n",
      "step : 3077 | loss: 2.0291202068328857 | dt: 165.70 ms | tokens/sec: 37.08 | norm: 1.70\n",
      "step : 3078 | loss: 1.8221309185028076 | dt: 165.94 ms | tokens/sec: 37.03 | norm: 1.63\n",
      "step : 3079 | loss: 2.282391309738159 | dt: 166.89 ms | tokens/sec: 36.81 | norm: 2.08\n",
      "step : 3080 | loss: 2.2655446529388428 | dt: 167.33 ms | tokens/sec: 36.72 | norm: 2.47\n",
      "step : 3081 | loss: 2.3950347900390625 | dt: 167.20 ms | tokens/sec: 36.75 | norm: 2.06\n",
      "step : 3082 | loss: 2.3051774501800537 | dt: 167.54 ms | tokens/sec: 36.67 | norm: 2.07\n",
      "step : 3083 | loss: 2.238912582397461 | dt: 165.59 ms | tokens/sec: 37.10 | norm: 2.14\n",
      "step : 3084 | loss: 2.0638222694396973 | dt: 165.65 ms | tokens/sec: 37.09 | norm: 1.83\n",
      "step : 3085 | loss: 2.0863072872161865 | dt: 166.47 ms | tokens/sec: 36.91 | norm: 1.71\n",
      "step : 3086 | loss: 2.0271453857421875 | dt: 166.68 ms | tokens/sec: 36.86 | norm: 1.74\n",
      "step : 3087 | loss: 2.15927791595459 | dt: 166.49 ms | tokens/sec: 36.90 | norm: 1.86\n",
      "step : 3088 | loss: 2.221827268600464 | dt: 166.55 ms | tokens/sec: 36.89 | norm: 1.99\n",
      "step : 3089 | loss: 2.1963870525360107 | dt: 165.77 ms | tokens/sec: 37.06 | norm: 2.07\n",
      "step : 3090 | loss: 2.0962650775909424 | dt: 168.23 ms | tokens/sec: 36.52 | norm: 1.97\n",
      "step : 3091 | loss: 2.153493642807007 | dt: 167.35 ms | tokens/sec: 36.71 | norm: 1.82\n",
      "step : 3092 | loss: 2.1207218170166016 | dt: 166.46 ms | tokens/sec: 36.91 | norm: 1.79\n",
      "step : 3093 | loss: 2.079827308654785 | dt: 166.88 ms | tokens/sec: 36.82 | norm: 1.87\n",
      "step : 3094 | loss: 1.9932106733322144 | dt: 166.46 ms | tokens/sec: 36.91 | norm: 1.75\n",
      "step : 3095 | loss: 2.015650510787964 | dt: 164.94 ms | tokens/sec: 37.25 | norm: 1.75\n",
      "step : 3096 | loss: 2.165776252746582 | dt: 165.75 ms | tokens/sec: 37.07 | norm: 2.07\n",
      "step : 3097 | loss: 2.234711170196533 | dt: 167.64 ms | tokens/sec: 36.65 | norm: 2.16\n",
      "step : 3098 | loss: 2.125797986984253 | dt: 165.83 ms | tokens/sec: 37.05 | norm: 2.13\n",
      "step : 3099 | loss: 2.174067974090576 | dt: 167.98 ms | tokens/sec: 36.58 | norm: 2.40\n",
      "step : 3100 | loss: 2.19675350189209 | dt: 166.25 ms | tokens/sec: 36.96 | norm: 2.40\n",
      "step : 3101 | loss: 2.0378880500793457 | dt: 165.77 ms | tokens/sec: 37.06 | norm: 1.87\n",
      "step : 3102 | loss: 2.135251045227051 | dt: 165.93 ms | tokens/sec: 37.03 | norm: 1.86\n",
      "step : 3103 | loss: 2.1977527141571045 | dt: 166.67 ms | tokens/sec: 36.86 | norm: 2.04\n",
      "step : 3104 | loss: 2.229830265045166 | dt: 165.69 ms | tokens/sec: 37.08 | norm: 2.22\n",
      "step : 3105 | loss: 2.0399587154388428 | dt: 167.52 ms | tokens/sec: 36.68 | norm: 1.90\n",
      "step : 3106 | loss: 2.2344374656677246 | dt: 166.58 ms | tokens/sec: 36.88 | norm: 1.85\n",
      "step : 3107 | loss: 2.099395275115967 | dt: 165.59 ms | tokens/sec: 37.10 | norm: 1.74\n",
      "step : 3108 | loss: 2.2433981895446777 | dt: 165.80 ms | tokens/sec: 37.06 | norm: 1.89\n",
      "step : 3109 | loss: 2.3204874992370605 | dt: 166.50 ms | tokens/sec: 36.90 | norm: 2.05\n",
      "step : 3110 | loss: 2.3676490783691406 | dt: 165.45 ms | tokens/sec: 37.14 | norm: 2.28\n",
      "step : 3111 | loss: 2.1725287437438965 | dt: 167.88 ms | tokens/sec: 36.60 | norm: 2.15\n",
      "step : 3112 | loss: 2.1599502563476562 | dt: 166.79 ms | tokens/sec: 36.84 | norm: 2.21\n",
      "step : 3113 | loss: 2.1939656734466553 | dt: 165.54 ms | tokens/sec: 37.12 | norm: 2.01\n",
      "step : 3114 | loss: 2.0930097103118896 | dt: 166.27 ms | tokens/sec: 36.95 | norm: 2.14\n",
      "step : 3115 | loss: 2.117604970932007 | dt: 166.49 ms | tokens/sec: 36.90 | norm: 1.98\n",
      "step : 3116 | loss: 2.4117627143859863 | dt: 165.49 ms | tokens/sec: 37.13 | norm: 2.32\n",
      "step : 3117 | loss: 2.345395803451538 | dt: 166.95 ms | tokens/sec: 36.80 | norm: 2.19\n",
      "step : 3118 | loss: 2.3478946685791016 | dt: 167.04 ms | tokens/sec: 36.78 | norm: 1.95\n",
      "step : 3119 | loss: 2.201964855194092 | dt: 165.53 ms | tokens/sec: 37.12 | norm: 1.84\n",
      "step : 3120 | loss: 2.1840333938598633 | dt: 165.54 ms | tokens/sec: 37.11 | norm: 1.82\n",
      "step : 3121 | loss: 2.2733819484710693 | dt: 167.22 ms | tokens/sec: 36.74 | norm: 1.80\n",
      "step : 3122 | loss: 2.154693126678467 | dt: 165.15 ms | tokens/sec: 37.20 | norm: 2.13\n",
      "step : 3123 | loss: 2.15316104888916 | dt: 167.65 ms | tokens/sec: 36.65 | norm: 1.89\n",
      "step : 3124 | loss: 2.159151077270508 | dt: 167.30 ms | tokens/sec: 36.72 | norm: 2.13\n",
      "step : 3125 | loss: 2.123155117034912 | dt: 166.70 ms | tokens/sec: 36.86 | norm: 1.99\n",
      "step : 3126 | loss: 2.011162519454956 | dt: 167.24 ms | tokens/sec: 36.74 | norm: 1.91\n",
      "step : 3127 | loss: 2.061772346496582 | dt: 168.51 ms | tokens/sec: 36.46 | norm: 2.00\n",
      "step : 3128 | loss: 2.215705633163452 | dt: 168.32 ms | tokens/sec: 36.50 | norm: 2.06\n",
      "step : 3129 | loss: 2.317391872406006 | dt: 167.45 ms | tokens/sec: 36.69 | norm: 2.23\n",
      "step : 3130 | loss: 2.1196677684783936 | dt: 168.72 ms | tokens/sec: 36.42 | norm: 1.79\n",
      "step : 3131 | loss: 1.9818041324615479 | dt: 167.22 ms | tokens/sec: 36.74 | norm: 1.70\n",
      "step : 3132 | loss: 1.9702811241149902 | dt: 166.96 ms | tokens/sec: 36.80 | norm: 1.84\n",
      "step : 3133 | loss: 1.7690222263336182 | dt: 167.62 ms | tokens/sec: 36.66 | norm: 1.56\n",
      "step : 3134 | loss: 2.198181629180908 | dt: 167.93 ms | tokens/sec: 36.59 | norm: 1.87\n",
      "step : 3135 | loss: 2.1900992393493652 | dt: 167.96 ms | tokens/sec: 36.58 | norm: 1.88\n",
      "step : 3136 | loss: 2.313828945159912 | dt: 168.70 ms | tokens/sec: 36.42 | norm: 2.18\n",
      "step : 3137 | loss: 2.244016170501709 | dt: 168.13 ms | tokens/sec: 36.54 | norm: 2.34\n",
      "step : 3138 | loss: 2.1799564361572266 | dt: 167.85 ms | tokens/sec: 36.60 | norm: 1.98\n",
      "step : 3139 | loss: 2.0187432765960693 | dt: 167.97 ms | tokens/sec: 36.58 | norm: 1.97\n",
      "step : 3140 | loss: 2.0494015216827393 | dt: 168.54 ms | tokens/sec: 36.45 | norm: 1.79\n",
      "step : 3141 | loss: 1.9978294372558594 | dt: 167.95 ms | tokens/sec: 36.58 | norm: 1.88\n",
      "step : 3142 | loss: 2.1059277057647705 | dt: 168.40 ms | tokens/sec: 36.48 | norm: 1.92\n",
      "step : 3143 | loss: 2.1726298332214355 | dt: 167.09 ms | tokens/sec: 36.77 | norm: 1.85\n",
      "step : 3144 | loss: 2.1252150535583496 | dt: 167.13 ms | tokens/sec: 36.76 | norm: 1.91\n",
      "step : 3145 | loss: 2.0604138374328613 | dt: 167.19 ms | tokens/sec: 36.75 | norm: 1.85\n",
      "step : 3146 | loss: 2.1239304542541504 | dt: 167.48 ms | tokens/sec: 36.68 | norm: 1.78\n",
      "step : 3147 | loss: 2.0753579139709473 | dt: 168.03 ms | tokens/sec: 36.57 | norm: 1.74\n",
      "step : 3148 | loss: 2.061398983001709 | dt: 167.72 ms | tokens/sec: 36.63 | norm: 2.06\n",
      "step : 3149 | loss: 1.9575828313827515 | dt: 168.96 ms | tokens/sec: 36.36 | norm: 1.96\n",
      "step : 3150 | loss: 1.9555950164794922 | dt: 168.10 ms | tokens/sec: 36.55 | norm: 1.75\n",
      "step : 3151 | loss: 2.0999505519866943 | dt: 168.40 ms | tokens/sec: 36.48 | norm: 2.01\n",
      "step : 3152 | loss: 2.1478030681610107 | dt: 167.93 ms | tokens/sec: 36.59 | norm: 1.89\n",
      "step : 3153 | loss: 2.0654358863830566 | dt: 168.39 ms | tokens/sec: 36.49 | norm: 2.05\n",
      "step : 3154 | loss: 2.077688217163086 | dt: 167.60 ms | tokens/sec: 36.66 | norm: 2.12\n",
      "step : 3155 | loss: 2.149667263031006 | dt: 167.12 ms | tokens/sec: 36.76 | norm: 2.09\n",
      "step : 3156 | loss: 1.989778995513916 | dt: 167.27 ms | tokens/sec: 36.73 | norm: 1.92\n",
      "step : 3157 | loss: 2.0880112648010254 | dt: 167.24 ms | tokens/sec: 36.74 | norm: 2.04\n",
      "step : 3158 | loss: 2.1489763259887695 | dt: 167.30 ms | tokens/sec: 36.72 | norm: 2.20\n",
      "step : 3159 | loss: 2.1782140731811523 | dt: 167.05 ms | tokens/sec: 36.78 | norm: 2.13\n",
      "step : 3160 | loss: 2.0052123069763184 | dt: 167.45 ms | tokens/sec: 36.69 | norm: 1.85\n",
      "step : 3161 | loss: 2.199464797973633 | dt: 168.48 ms | tokens/sec: 36.47 | norm: 2.03\n",
      "step : 3162 | loss: 2.053471803665161 | dt: 168.73 ms | tokens/sec: 36.41 | norm: 1.84\n",
      "step : 3163 | loss: 2.1714906692504883 | dt: 168.19 ms | tokens/sec: 36.53 | norm: 2.11\n",
      "step : 3164 | loss: 2.2752797603607178 | dt: 169.00 ms | tokens/sec: 36.35 | norm: 2.27\n",
      "step : 3165 | loss: 2.25949764251709 | dt: 167.58 ms | tokens/sec: 36.66 | norm: 2.42\n",
      "step : 3166 | loss: 2.0938467979431152 | dt: 168.27 ms | tokens/sec: 36.51 | norm: 2.10\n",
      "step : 3167 | loss: 2.079848051071167 | dt: 168.49 ms | tokens/sec: 36.46 | norm: 2.00\n",
      "step : 3168 | loss: 2.114884614944458 | dt: 166.93 ms | tokens/sec: 36.80 | norm: 1.93\n",
      "step : 3169 | loss: 2.0209801197052 | dt: 167.14 ms | tokens/sec: 36.76 | norm: 1.85\n",
      "step : 3170 | loss: 2.0892112255096436 | dt: 167.16 ms | tokens/sec: 36.75 | norm: 2.14\n",
      "step : 3171 | loss: 2.4070544242858887 | dt: 167.23 ms | tokens/sec: 36.74 | norm: 2.22\n",
      "step : 3172 | loss: 2.370633125305176 | dt: 167.08 ms | tokens/sec: 36.77 | norm: 2.29\n",
      "step : 3173 | loss: 2.3334290981292725 | dt: 168.43 ms | tokens/sec: 36.48 | norm: 2.13\n",
      "step : 3174 | loss: 2.2206478118896484 | dt: 170.33 ms | tokens/sec: 36.07 | norm: 2.07\n",
      "step : 3175 | loss: 2.1672682762145996 | dt: 169.65 ms | tokens/sec: 36.22 | norm: 1.76\n",
      "step : 3176 | loss: 2.230494499206543 | dt: 168.59 ms | tokens/sec: 36.44 | norm: 1.81\n",
      "step : 3177 | loss: 2.097561836242676 | dt: 167.69 ms | tokens/sec: 36.64 | norm: 1.76\n",
      "step : 3178 | loss: 2.0705456733703613 | dt: 168.96 ms | tokens/sec: 36.36 | norm: 1.85\n",
      "step : 3179 | loss: 2.042127847671509 | dt: 167.13 ms | tokens/sec: 36.76 | norm: 1.80\n",
      "step : 3180 | loss: 2.0330843925476074 | dt: 168.68 ms | tokens/sec: 36.42 | norm: 1.77\n",
      "step : 3181 | loss: 1.9287809133529663 | dt: 167.80 ms | tokens/sec: 36.61 | norm: 1.75\n",
      "step : 3182 | loss: 1.9849666357040405 | dt: 166.19 ms | tokens/sec: 36.97 | norm: 1.74\n",
      "step : 3183 | loss: 2.134882688522339 | dt: 167.43 ms | tokens/sec: 36.70 | norm: 1.78\n",
      "step : 3184 | loss: 2.244234085083008 | dt: 165.37 ms | tokens/sec: 37.15 | norm: 2.32\n",
      "step : 3185 | loss: 2.0489511489868164 | dt: 165.03 ms | tokens/sec: 37.23 | norm: 1.90\n",
      "step : 3186 | loss: 1.940126895904541 | dt: 167.61 ms | tokens/sec: 36.66 | norm: 1.76\n",
      "step : 3187 | loss: 1.94078528881073 | dt: 165.83 ms | tokens/sec: 37.05 | norm: 2.63\n",
      "step : 3188 | loss: 1.7257640361785889 | dt: 164.68 ms | tokens/sec: 37.31 | norm: 1.54\n",
      "step : 3189 | loss: 2.198849678039551 | dt: 166.90 ms | tokens/sec: 36.81 | norm: 2.50\n",
      "step : 3190 | loss: 2.1648805141448975 | dt: 165.99 ms | tokens/sec: 37.02 | norm: 1.92\n",
      "step : 3191 | loss: 2.253537178039551 | dt: 165.34 ms | tokens/sec: 37.16 | norm: 2.11\n",
      "step : 3192 | loss: 2.194060802459717 | dt: 168.22 ms | tokens/sec: 36.52 | norm: 2.12\n",
      "step : 3193 | loss: 2.1371543407440186 | dt: 165.77 ms | tokens/sec: 37.06 | norm: 2.31\n",
      "step : 3194 | loss: 1.9565147161483765 | dt: 165.53 ms | tokens/sec: 37.12 | norm: 1.72\n",
      "step : 3195 | loss: 1.977962851524353 | dt: 167.54 ms | tokens/sec: 36.67 | norm: 1.58\n",
      "step : 3196 | loss: 1.9329948425292969 | dt: 166.19 ms | tokens/sec: 36.97 | norm: 1.63\n",
      "step : 3197 | loss: 2.0508928298950195 | dt: 165.20 ms | tokens/sec: 37.19 | norm: 1.72\n",
      "step : 3198 | loss: 2.095714807510376 | dt: 167.91 ms | tokens/sec: 36.59 | norm: 2.06\n",
      "step : 3199 | loss: 2.087662696838379 | dt: 166.92 ms | tokens/sec: 36.81 | norm: 2.07\n",
      "step : 3200 | loss: 2.0188465118408203 | dt: 167.03 ms | tokens/sec: 36.78 | norm: 2.04\n",
      "step : 3201 | loss: 2.0952823162078857 | dt: 167.17 ms | tokens/sec: 36.75 | norm: 2.08\n",
      "step : 3202 | loss: 2.039896011352539 | dt: 165.76 ms | tokens/sec: 37.07 | norm: 2.02\n",
      "step : 3203 | loss: 2.016012191772461 | dt: 165.30 ms | tokens/sec: 37.17 | norm: 1.83\n",
      "step : 3204 | loss: 1.8880023956298828 | dt: 167.28 ms | tokens/sec: 36.73 | norm: 1.85\n",
      "step : 3205 | loss: 1.887472152709961 | dt: 166.90 ms | tokens/sec: 36.81 | norm: 1.89\n",
      "step : 3206 | loss: 2.0046653747558594 | dt: 165.61 ms | tokens/sec: 37.10 | norm: 2.17\n",
      "step : 3207 | loss: 2.0506675243377686 | dt: 167.08 ms | tokens/sec: 36.77 | norm: 1.91\n",
      "step : 3208 | loss: 2.0060501098632812 | dt: 166.08 ms | tokens/sec: 36.99 | norm: 1.92\n",
      "step : 3209 | loss: 2.001188039779663 | dt: 165.60 ms | tokens/sec: 37.10 | norm: 1.92\n",
      "step : 3210 | loss: 2.0561575889587402 | dt: 166.84 ms | tokens/sec: 36.83 | norm: 2.09\n",
      "step : 3211 | loss: 1.8979434967041016 | dt: 166.53 ms | tokens/sec: 36.89 | norm: 1.76\n",
      "step : 3212 | loss: 2.014430522918701 | dt: 165.83 ms | tokens/sec: 37.05 | norm: 1.86\n",
      "step : 3213 | loss: 2.080521821975708 | dt: 167.05 ms | tokens/sec: 36.78 | norm: 2.09\n",
      "step : 3214 | loss: 2.1099886894226074 | dt: 166.36 ms | tokens/sec: 36.93 | norm: 2.07\n",
      "step : 3215 | loss: 1.9448673725128174 | dt: 165.86 ms | tokens/sec: 37.04 | norm: 1.74\n",
      "step : 3216 | loss: 2.148482322692871 | dt: 167.02 ms | tokens/sec: 36.79 | norm: 2.13\n",
      "step : 3217 | loss: 2.0216362476348877 | dt: 166.16 ms | tokens/sec: 36.98 | norm: 2.06\n",
      "step : 3218 | loss: 2.119965076446533 | dt: 165.43 ms | tokens/sec: 37.14 | norm: 1.98\n",
      "step : 3219 | loss: 2.2107620239257812 | dt: 166.99 ms | tokens/sec: 36.79 | norm: 2.11\n",
      "step : 3220 | loss: 2.212623357772827 | dt: 168.40 ms | tokens/sec: 36.48 | norm: 2.29\n",
      "step : 3221 | loss: 2.03114914894104 | dt: 168.40 ms | tokens/sec: 36.48 | norm: 2.07\n",
      "step : 3222 | loss: 1.9957497119903564 | dt: 167.74 ms | tokens/sec: 36.63 | norm: 1.89\n",
      "step : 3223 | loss: 2.0434579849243164 | dt: 166.62 ms | tokens/sec: 36.87 | norm: 1.80\n",
      "step : 3224 | loss: 1.9318268299102783 | dt: 166.36 ms | tokens/sec: 36.93 | norm: 1.69\n",
      "step : 3225 | loss: 1.9770443439483643 | dt: 166.66 ms | tokens/sec: 36.86 | norm: 1.77\n",
      "step : 3226 | loss: 2.301661252975464 | dt: 166.20 ms | tokens/sec: 36.97 | norm: 2.58\n",
      "step : 3227 | loss: 2.26619291305542 | dt: 165.20 ms | tokens/sec: 37.19 | norm: 2.14\n",
      "step : 3228 | loss: 2.2334749698638916 | dt: 167.38 ms | tokens/sec: 36.71 | norm: 1.97\n",
      "step : 3229 | loss: 2.107797622680664 | dt: 165.85 ms | tokens/sec: 37.05 | norm: 1.93\n",
      "step : 3230 | loss: 2.0535736083984375 | dt: 168.26 ms | tokens/sec: 36.52 | norm: 1.82\n",
      "step : 3231 | loss: 2.158450126647949 | dt: 166.86 ms | tokens/sec: 36.82 | norm: 2.11\n",
      "step : 3232 | loss: 2.0426831245422363 | dt: 165.85 ms | tokens/sec: 37.05 | norm: 1.90\n",
      "step : 3233 | loss: 2.0296339988708496 | dt: 165.13 ms | tokens/sec: 37.21 | norm: 1.98\n",
      "step : 3234 | loss: 2.0261905193328857 | dt: 167.04 ms | tokens/sec: 36.78 | norm: 1.80\n",
      "step : 3235 | loss: 2.017021656036377 | dt: 165.15 ms | tokens/sec: 37.20 | norm: 1.82\n",
      "step : 3236 | loss: 1.8805739879608154 | dt: 166.99 ms | tokens/sec: 36.79 | norm: 1.97\n",
      "step : 3237 | loss: 1.9517993927001953 | dt: 166.87 ms | tokens/sec: 36.82 | norm: 1.88\n",
      "step : 3238 | loss: 2.055786609649658 | dt: 165.77 ms | tokens/sec: 37.06 | norm: 1.83\n",
      "step : 3239 | loss: 2.197502851486206 | dt: 165.74 ms | tokens/sec: 37.07 | norm: 1.98\n",
      "step : 3240 | loss: 1.9997094869613647 | dt: 166.93 ms | tokens/sec: 36.81 | norm: 1.74\n",
      "step : 3241 | loss: 1.8704116344451904 | dt: 165.97 ms | tokens/sec: 37.02 | norm: 3.64\n",
      "step : 3242 | loss: 1.911424994468689 | dt: 167.18 ms | tokens/sec: 36.75 | norm: 1.74\n",
      "step : 3243 | loss: 1.6699719429016113 | dt: 166.96 ms | tokens/sec: 36.80 | norm: 1.68\n",
      "step : 3244 | loss: 2.1488568782806396 | dt: 166.49 ms | tokens/sec: 36.90 | norm: 2.18\n",
      "step : 3245 | loss: 2.124861478805542 | dt: 166.01 ms | tokens/sec: 37.01 | norm: 2.12\n",
      "step : 3246 | loss: 2.2848334312438965 | dt: 167.21 ms | tokens/sec: 36.74 | norm: 2.54\n",
      "step : 3247 | loss: 2.2025012969970703 | dt: 166.12 ms | tokens/sec: 36.98 | norm: 2.21\n",
      "step : 3248 | loss: 2.157280921936035 | dt: 167.50 ms | tokens/sec: 36.68 | norm: 2.26\n",
      "step : 3249 | loss: 1.9348998069763184 | dt: 168.19 ms | tokens/sec: 36.53 | norm: 2.03\n",
      "step : 3250 | loss: 1.936722755432129 | dt: 166.06 ms | tokens/sec: 37.00 | norm: 1.79\n",
      "step : 3251 | loss: 1.8644822835922241 | dt: 165.82 ms | tokens/sec: 37.05 | norm: 1.85\n",
      "step : 3252 | loss: 1.9707040786743164 | dt: 166.83 ms | tokens/sec: 36.83 | norm: 1.88\n",
      "step : 3253 | loss: 2.0050406455993652 | dt: 165.66 ms | tokens/sec: 37.09 | norm: 1.94\n",
      "step : 3254 | loss: 1.9919164180755615 | dt: 165.71 ms | tokens/sec: 37.08 | norm: 1.88\n",
      "step : 3255 | loss: 1.9234789609909058 | dt: 167.95 ms | tokens/sec: 36.58 | norm: 1.60\n",
      "step : 3256 | loss: 2.0005335807800293 | dt: 165.67 ms | tokens/sec: 37.09 | norm: 1.65\n",
      "step : 3257 | loss: 1.9773544073104858 | dt: 165.84 ms | tokens/sec: 37.05 | norm: 1.86\n",
      "step : 3258 | loss: 1.9343643188476562 | dt: 167.28 ms | tokens/sec: 36.73 | norm: 1.68\n",
      "step : 3259 | loss: 1.84549081325531 | dt: 165.94 ms | tokens/sec: 37.03 | norm: 1.85\n",
      "step : 3260 | loss: 1.8485102653503418 | dt: 166.08 ms | tokens/sec: 37.00 | norm: 2.08\n",
      "step : 3261 | loss: 1.9677356481552124 | dt: 168.21 ms | tokens/sec: 36.52 | norm: 2.24\n",
      "step : 3262 | loss: 2.019685745239258 | dt: 167.50 ms | tokens/sec: 36.68 | norm: 2.16\n",
      "step : 3263 | loss: 1.9335492849349976 | dt: 165.71 ms | tokens/sec: 37.08 | norm: 1.85\n",
      "step : 3264 | loss: 1.9400041103363037 | dt: 167.12 ms | tokens/sec: 36.77 | norm: 1.81\n",
      "step : 3265 | loss: 1.978201150894165 | dt: 165.80 ms | tokens/sec: 37.06 | norm: 1.82\n",
      "step : 3266 | loss: 1.8258588314056396 | dt: 165.43 ms | tokens/sec: 37.14 | norm: 1.84\n",
      "step : 3267 | loss: 1.9183244705200195 | dt: 167.22 ms | tokens/sec: 36.74 | norm: 1.85\n",
      "step : 3268 | loss: 2.0010135173797607 | dt: 165.62 ms | tokens/sec: 37.10 | norm: 2.22\n",
      "step : 3269 | loss: 2.0077381134033203 | dt: 165.92 ms | tokens/sec: 37.03 | norm: 2.04\n",
      "step : 3270 | loss: 1.8542356491088867 | dt: 166.85 ms | tokens/sec: 36.82 | norm: 1.83\n",
      "step : 3271 | loss: 2.0547361373901367 | dt: 165.43 ms | tokens/sec: 37.14 | norm: 1.92\n",
      "step : 3272 | loss: 1.9568700790405273 | dt: 174.45 ms | tokens/sec: 35.22 | norm: 1.76\n",
      "step : 3273 | loss: 2.052877187728882 | dt: 166.19 ms | tokens/sec: 36.97 | norm: 1.90\n",
      "step : 3274 | loss: 2.1471381187438965 | dt: 166.01 ms | tokens/sec: 37.01 | norm: 2.29\n",
      "step : 3275 | loss: 2.1717028617858887 | dt: 165.78 ms | tokens/sec: 37.06 | norm: 2.59\n",
      "step : 3276 | loss: 2.006206512451172 | dt: 167.46 ms | tokens/sec: 36.69 | norm: 2.13\n",
      "step : 3277 | loss: 1.9635274410247803 | dt: 166.44 ms | tokens/sec: 36.91 | norm: 1.89\n",
      "step : 3278 | loss: 2.004267692565918 | dt: 166.41 ms | tokens/sec: 36.92 | norm: 1.97\n",
      "step : 3279 | loss: 1.8808083534240723 | dt: 166.94 ms | tokens/sec: 36.80 | norm: 1.86\n",
      "step : 3280 | loss: 1.9120135307312012 | dt: 167.66 ms | tokens/sec: 36.65 | norm: 1.97\n",
      "step : 3281 | loss: 2.22560977935791 | dt: 165.42 ms | tokens/sec: 37.14 | norm: 2.14\n",
      "step : 3282 | loss: 2.1784632205963135 | dt: 166.71 ms | tokens/sec: 36.86 | norm: 2.04\n",
      "step : 3283 | loss: 2.1449155807495117 | dt: 165.77 ms | tokens/sec: 37.06 | norm: 2.02\n",
      "step : 3284 | loss: 2.0281715393066406 | dt: 165.70 ms | tokens/sec: 37.08 | norm: 1.77\n",
      "step : 3285 | loss: 1.9910423755645752 | dt: 167.10 ms | tokens/sec: 36.77 | norm: 2.06\n",
      "step : 3286 | loss: 2.0883750915527344 | dt: 166.56 ms | tokens/sec: 36.89 | norm: 1.87\n",
      "step : 3287 | loss: 1.976965308189392 | dt: 165.66 ms | tokens/sec: 37.09 | norm: 2.01\n",
      "step : 3288 | loss: 1.972313642501831 | dt: 167.27 ms | tokens/sec: 36.73 | norm: 1.75\n",
      "step : 3289 | loss: 1.9402765035629272 | dt: 166.00 ms | tokens/sec: 37.01 | norm: 1.78\n",
      "step : 3290 | loss: 1.9272950887680054 | dt: 165.48 ms | tokens/sec: 37.13 | norm: 1.79\n",
      "step : 3291 | loss: 1.810625433921814 | dt: 167.03 ms | tokens/sec: 36.78 | norm: 1.85\n",
      "step : 3292 | loss: 1.8841791152954102 | dt: 165.92 ms | tokens/sec: 37.03 | norm: 1.99\n",
      "step : 3293 | loss: 2.0018298625946045 | dt: 167.33 ms | tokens/sec: 36.72 | norm: 2.15\n",
      "step : 3294 | loss: 2.1777827739715576 | dt: 167.45 ms | tokens/sec: 36.69 | norm: 2.24\n",
      "step : 3295 | loss: 1.9716641902923584 | dt: 166.17 ms | tokens/sec: 36.97 | norm: 1.99\n",
      "step : 3296 | loss: 1.8853693008422852 | dt: 165.82 ms | tokens/sec: 37.05 | norm: 1.97\n",
      "step : 3297 | loss: 1.8225929737091064 | dt: 167.19 ms | tokens/sec: 36.75 | norm: 1.78\n",
      "step : 3298 | loss: 1.6061595678329468 | dt: 165.76 ms | tokens/sec: 37.06 | norm: 1.62\n",
      "step : 3299 | loss: 2.0133707523345947 | dt: 168.92 ms | tokens/sec: 36.37 | norm: 1.93\n",
      "step : 3300 | loss: 1.9947103261947632 | dt: 168.03 ms | tokens/sec: 36.56 | norm: 1.92\n",
      "step : 3301 | loss: 2.119603157043457 | dt: 165.82 ms | tokens/sec: 37.05 | norm: 1.97\n",
      "step : 3302 | loss: 2.0316267013549805 | dt: 165.98 ms | tokens/sec: 37.02 | norm: 2.05\n",
      "step : 3303 | loss: 1.982190489768982 | dt: 166.86 ms | tokens/sec: 36.82 | norm: 1.82\n",
      "step : 3304 | loss: 1.8148292303085327 | dt: 166.07 ms | tokens/sec: 37.00 | norm: 1.83\n",
      "step : 3305 | loss: 1.8614864349365234 | dt: 166.23 ms | tokens/sec: 36.96 | norm: 1.77\n",
      "step : 3306 | loss: 1.8284034729003906 | dt: 167.08 ms | tokens/sec: 36.77 | norm: 2.11\n",
      "step : 3307 | loss: 1.938344955444336 | dt: 166.14 ms | tokens/sec: 36.98 | norm: 1.95\n",
      "step : 3308 | loss: 1.9881596565246582 | dt: 165.71 ms | tokens/sec: 37.08 | norm: 2.14\n",
      "step : 3309 | loss: 1.972799301147461 | dt: 167.93 ms | tokens/sec: 36.59 | norm: 2.03\n",
      "step : 3310 | loss: 1.891105055809021 | dt: 166.89 ms | tokens/sec: 36.82 | norm: 2.00\n",
      "step : 3311 | loss: 1.9312267303466797 | dt: 166.75 ms | tokens/sec: 36.84 | norm: 1.88\n",
      "step : 3312 | loss: 1.9126371145248413 | dt: 166.46 ms | tokens/sec: 36.91 | norm: 1.84\n",
      "step : 3313 | loss: 1.8581641912460327 | dt: 166.10 ms | tokens/sec: 36.99 | norm: 1.64\n",
      "step : 3314 | loss: 1.7497339248657227 | dt: 166.21 ms | tokens/sec: 36.97 | norm: 1.76\n",
      "step : 3315 | loss: 1.781229019165039 | dt: 166.90 ms | tokens/sec: 36.81 | norm: 1.92\n",
      "step : 3316 | loss: 1.8644317388534546 | dt: 165.78 ms | tokens/sec: 37.06 | norm: 1.88\n",
      "step : 3317 | loss: 1.9292876720428467 | dt: 165.60 ms | tokens/sec: 37.10 | norm: 1.86\n",
      "step : 3318 | loss: 1.8485859632492065 | dt: 168.04 ms | tokens/sec: 36.56 | norm: 1.80\n",
      "step : 3319 | loss: 1.848832130432129 | dt: 165.73 ms | tokens/sec: 37.07 | norm: 1.80\n",
      "step : 3320 | loss: 1.9114320278167725 | dt: 165.53 ms | tokens/sec: 37.12 | norm: 1.81\n",
      "step : 3321 | loss: 1.7670506238937378 | dt: 167.20 ms | tokens/sec: 36.75 | norm: 1.82\n",
      "step : 3322 | loss: 1.8781675100326538 | dt: 165.79 ms | tokens/sec: 37.06 | norm: 2.07\n",
      "step : 3323 | loss: 1.9463403224945068 | dt: 166.13 ms | tokens/sec: 36.98 | norm: 2.22\n",
      "step : 3324 | loss: 1.9760053157806396 | dt: 169.08 ms | tokens/sec: 36.34 | norm: 1.95\n",
      "step : 3325 | loss: 1.834122896194458 | dt: 165.88 ms | tokens/sec: 37.04 | norm: 1.79\n",
      "step : 3326 | loss: 2.0012881755828857 | dt: 165.41 ms | tokens/sec: 37.14 | norm: 1.90\n",
      "step : 3327 | loss: 1.8982946872711182 | dt: 166.46 ms | tokens/sec: 36.91 | norm: 1.88\n",
      "step : 3328 | loss: 1.971474528312683 | dt: 166.06 ms | tokens/sec: 37.00 | norm: 1.89\n",
      "step : 3329 | loss: 2.068389892578125 | dt: 165.96 ms | tokens/sec: 37.02 | norm: 2.17\n",
      "step : 3330 | loss: 2.082275152206421 | dt: 168.01 ms | tokens/sec: 36.57 | norm: 2.03\n",
      "step : 3331 | loss: 1.8844270706176758 | dt: 165.73 ms | tokens/sec: 37.07 | norm: 1.86\n",
      "step : 3332 | loss: 1.8688056468963623 | dt: 165.43 ms | tokens/sec: 37.14 | norm: 2.75\n",
      "step : 3333 | loss: 1.9088642597198486 | dt: 166.57 ms | tokens/sec: 36.88 | norm: 1.69\n",
      "step : 3334 | loss: 1.7939866781234741 | dt: 165.65 ms | tokens/sec: 37.09 | norm: 1.74\n",
      "step : 3335 | loss: 1.835372805595398 | dt: 165.85 ms | tokens/sec: 37.05 | norm: 1.78\n",
      "step : 3336 | loss: 2.1451494693756104 | dt: 167.34 ms | tokens/sec: 36.72 | norm: 2.25\n",
      "step : 3337 | loss: 2.1197404861450195 | dt: 166.61 ms | tokens/sec: 36.88 | norm: 2.02\n",
      "step : 3338 | loss: 2.0817408561706543 | dt: 165.51 ms | tokens/sec: 37.12 | norm: 2.01\n",
      "step : 3339 | loss: 1.9871890544891357 | dt: 167.42 ms | tokens/sec: 36.70 | norm: 2.08\n",
      "step : 3340 | loss: 1.9572877883911133 | dt: 166.06 ms | tokens/sec: 37.00 | norm: 1.91\n",
      "step : 3341 | loss: 2.0239691734313965 | dt: 166.05 ms | tokens/sec: 37.00 | norm: 1.92\n",
      "step : 3342 | loss: 1.9324524402618408 | dt: 166.60 ms | tokens/sec: 36.88 | norm: 2.18\n",
      "step : 3343 | loss: 1.8942941427230835 | dt: 166.68 ms | tokens/sec: 36.86 | norm: 1.76\n",
      "step : 3344 | loss: 1.876645803451538 | dt: 165.56 ms | tokens/sec: 37.11 | norm: 1.89\n",
      "step : 3345 | loss: 1.8842861652374268 | dt: 167.01 ms | tokens/sec: 36.79 | norm: 1.94\n",
      "step : 3346 | loss: 1.7500574588775635 | dt: 165.58 ms | tokens/sec: 37.11 | norm: 1.85\n",
      "step : 3347 | loss: 1.8247750997543335 | dt: 165.48 ms | tokens/sec: 37.13 | norm: 2.50\n",
      "step : 3348 | loss: 1.9407832622528076 | dt: 166.70 ms | tokens/sec: 36.86 | norm: 1.89\n",
      "step : 3349 | loss: 2.098827838897705 | dt: 165.59 ms | tokens/sec: 37.10 | norm: 2.12\n",
      "step : 3350 | loss: 1.9087152481079102 | dt: 165.20 ms | tokens/sec: 37.19 | norm: 2.03\n",
      "step : 3351 | loss: 1.8135175704956055 | dt: 166.29 ms | tokens/sec: 36.95 | norm: 1.96\n",
      "step : 3352 | loss: 1.7848682403564453 | dt: 164.93 ms | tokens/sec: 37.25 | norm: 1.85\n",
      "step : 3353 | loss: 1.5654921531677246 | dt: 166.80 ms | tokens/sec: 36.83 | norm: 1.75\n",
      "step : 3354 | loss: 1.965839147567749 | dt: 166.05 ms | tokens/sec: 37.00 | norm: 1.94\n",
      "step : 3355 | loss: 1.9740684032440186 | dt: 166.88 ms | tokens/sec: 36.82 | norm: 2.11\n",
      "step : 3356 | loss: 2.11923885345459 | dt: 166.05 ms | tokens/sec: 37.00 | norm: 2.31\n",
      "step : 3357 | loss: 2.0349607467651367 | dt: 165.70 ms | tokens/sec: 37.08 | norm: 2.25\n",
      "step : 3358 | loss: 2.001180410385132 | dt: 165.18 ms | tokens/sec: 37.20 | norm: 2.28\n",
      "step : 3359 | loss: 1.8250648975372314 | dt: 167.60 ms | tokens/sec: 36.66 | norm: 2.06\n",
      "step : 3360 | loss: 1.8264541625976562 | dt: 165.83 ms | tokens/sec: 37.05 | norm: 1.82\n",
      "step : 3361 | loss: 1.7666653394699097 | dt: 166.01 ms | tokens/sec: 37.01 | norm: 1.72\n",
      "step : 3362 | loss: 1.8783674240112305 | dt: 166.89 ms | tokens/sec: 36.81 | norm: 1.71\n",
      "step : 3363 | loss: 1.8995546102523804 | dt: 166.62 ms | tokens/sec: 36.87 | norm: 2.31\n",
      "step : 3364 | loss: 1.8851850032806396 | dt: 166.37 ms | tokens/sec: 36.93 | norm: 1.93\n",
      "step : 3365 | loss: 1.8251540660858154 | dt: 166.65 ms | tokens/sec: 36.87 | norm: 1.96\n",
      "step : 3366 | loss: 1.8859237432479858 | dt: 166.70 ms | tokens/sec: 36.86 | norm: 1.90\n",
      "step : 3367 | loss: 1.8602155447006226 | dt: 165.95 ms | tokens/sec: 37.02 | norm: 1.90\n",
      "step : 3368 | loss: 1.8172401189804077 | dt: 166.72 ms | tokens/sec: 36.85 | norm: 1.84\n",
      "step : 3369 | loss: 1.7506036758422852 | dt: 167.05 ms | tokens/sec: 36.78 | norm: 2.03\n",
      "step : 3370 | loss: 1.7647483348846436 | dt: 165.83 ms | tokens/sec: 37.05 | norm: 2.33\n",
      "step : 3371 | loss: 1.8644893169403076 | dt: 167.25 ms | tokens/sec: 36.73 | norm: 2.43\n",
      "step : 3372 | loss: 1.9015882015228271 | dt: 166.73 ms | tokens/sec: 36.85 | norm: 2.23\n",
      "step : 3373 | loss: 1.7969577312469482 | dt: 166.32 ms | tokens/sec: 36.94 | norm: 1.95\n",
      "step : 3374 | loss: 1.8073136806488037 | dt: 168.33 ms | tokens/sec: 36.50 | norm: 2.14\n",
      "step : 3375 | loss: 1.8307985067367554 | dt: 167.03 ms | tokens/sec: 36.78 | norm: 2.15\n",
      "step : 3376 | loss: 1.7142817974090576 | dt: 165.15 ms | tokens/sec: 37.20 | norm: 1.80\n",
      "step : 3377 | loss: 1.81405770778656 | dt: 166.61 ms | tokens/sec: 36.88 | norm: 1.76\n",
      "step : 3378 | loss: 1.8698365688323975 | dt: 167.56 ms | tokens/sec: 36.67 | norm: 2.16\n",
      "step : 3379 | loss: 1.909785270690918 | dt: 165.76 ms | tokens/sec: 37.07 | norm: 3.61\n",
      "step : 3380 | loss: 1.7645683288574219 | dt: 168.46 ms | tokens/sec: 36.47 | norm: 1.85\n",
      "step : 3381 | loss: 1.9399827718734741 | dt: 166.24 ms | tokens/sec: 36.96 | norm: 2.13\n",
      "step : 3382 | loss: 1.837810754776001 | dt: 165.26 ms | tokens/sec: 37.18 | norm: 1.81\n",
      "step : 3383 | loss: 1.9327863454818726 | dt: 167.40 ms | tokens/sec: 36.70 | norm: 2.13\n",
      "step : 3384 | loss: 2.044793128967285 | dt: 167.27 ms | tokens/sec: 36.73 | norm: 2.17\n",
      "step : 3385 | loss: 2.0391335487365723 | dt: 164.86 ms | tokens/sec: 37.27 | norm: 2.15\n",
      "step : 3386 | loss: 1.8435109853744507 | dt: 166.17 ms | tokens/sec: 36.98 | norm: 2.03\n",
      "step : 3387 | loss: 1.8528211116790771 | dt: 166.82 ms | tokens/sec: 36.83 | norm: 2.03\n",
      "step : 3388 | loss: 1.853187918663025 | dt: 165.86 ms | tokens/sec: 37.04 | norm: 1.96\n",
      "step : 3389 | loss: 1.7391866445541382 | dt: 166.63 ms | tokens/sec: 36.87 | norm: 1.86\n",
      "step : 3390 | loss: 1.7516465187072754 | dt: 166.99 ms | tokens/sec: 36.79 | norm: 1.83\n",
      "step : 3391 | loss: 2.0691299438476562 | dt: 165.99 ms | tokens/sec: 37.01 | norm: 2.19\n",
      "step : 3392 | loss: 2.036512851715088 | dt: 165.94 ms | tokens/sec: 37.02 | norm: 2.00\n",
      "step : 3393 | loss: 2.0056815147399902 | dt: 168.16 ms | tokens/sec: 36.54 | norm: 2.10\n",
      "step : 3394 | loss: 1.8953478336334229 | dt: 166.10 ms | tokens/sec: 36.99 | norm: 1.89\n",
      "step : 3395 | loss: 1.872659683227539 | dt: 167.34 ms | tokens/sec: 36.71 | norm: 1.94\n",
      "step : 3396 | loss: 1.955637812614441 | dt: 166.34 ms | tokens/sec: 36.94 | norm: 2.13\n",
      "step : 3397 | loss: 1.868672251701355 | dt: 166.04 ms | tokens/sec: 37.00 | norm: 1.92\n",
      "step : 3398 | loss: 1.8322672843933105 | dt: 165.70 ms | tokens/sec: 37.08 | norm: 1.97\n",
      "step : 3399 | loss: 1.8296172618865967 | dt: 168.02 ms | tokens/sec: 36.57 | norm: 2.15\n",
      "step : 3400 | loss: 1.8218762874603271 | dt: 166.25 ms | tokens/sec: 36.96 | norm: 1.97\n",
      "step : 3401 | loss: 1.6783002614974976 | dt: 167.70 ms | tokens/sec: 36.64 | norm: 1.94\n",
      "step : 3402 | loss: 1.791617751121521 | dt: 167.26 ms | tokens/sec: 36.73 | norm: 1.76\n",
      "step : 3403 | loss: 1.8572285175323486 | dt: 165.39 ms | tokens/sec: 37.15 | norm: 1.95\n",
      "step : 3404 | loss: 1.993992567062378 | dt: 165.96 ms | tokens/sec: 37.02 | norm: 2.17\n",
      "step : 3405 | loss: 1.8157323598861694 | dt: 167.14 ms | tokens/sec: 36.76 | norm: 2.02\n",
      "step : 3406 | loss: 1.7225675582885742 | dt: 165.86 ms | tokens/sec: 37.04 | norm: 1.93\n",
      "step : 3407 | loss: 1.7147921323776245 | dt: 167.04 ms | tokens/sec: 36.78 | norm: 1.93\n",
      "step : 3408 | loss: 1.5057029724121094 | dt: 166.79 ms | tokens/sec: 36.84 | norm: 1.88\n",
      "step : 3409 | loss: 1.8963359594345093 | dt: 165.96 ms | tokens/sec: 37.02 | norm: 1.95\n",
      "step : 3410 | loss: 1.9016079902648926 | dt: 165.71 ms | tokens/sec: 37.08 | norm: 2.03\n",
      "step : 3411 | loss: 2.0319902896881104 | dt: 167.30 ms | tokens/sec: 36.73 | norm: 2.15\n",
      "step : 3412 | loss: 1.9646730422973633 | dt: 166.28 ms | tokens/sec: 36.95 | norm: 2.17\n",
      "step : 3413 | loss: 1.8953945636749268 | dt: 166.95 ms | tokens/sec: 36.80 | norm: 2.25\n",
      "step : 3414 | loss: 1.7330632209777832 | dt: 166.69 ms | tokens/sec: 36.86 | norm: 1.86\n",
      "step : 3415 | loss: 1.748093605041504 | dt: 166.02 ms | tokens/sec: 37.01 | norm: 1.71\n",
      "step : 3416 | loss: 1.707870364189148 | dt: 165.86 ms | tokens/sec: 37.04 | norm: 1.84\n",
      "step : 3417 | loss: 1.7982308864593506 | dt: 166.63 ms | tokens/sec: 36.87 | norm: 1.86\n",
      "step : 3418 | loss: 1.8529210090637207 | dt: 166.97 ms | tokens/sec: 36.80 | norm: 1.94\n",
      "step : 3419 | loss: 1.863276720046997 | dt: 167.06 ms | tokens/sec: 36.78 | norm: 2.04\n",
      "step : 3420 | loss: 1.7785547971725464 | dt: 166.86 ms | tokens/sec: 36.82 | norm: 2.03\n",
      "step : 3421 | loss: 1.8436321020126343 | dt: 166.10 ms | tokens/sec: 36.99 | norm: 1.86\n",
      "step : 3422 | loss: 1.8103959560394287 | dt: 165.83 ms | tokens/sec: 37.05 | norm: 2.05\n",
      "step : 3423 | loss: 1.7463468313217163 | dt: 167.41 ms | tokens/sec: 36.70 | norm: 1.81\n",
      "step : 3424 | loss: 1.6524291038513184 | dt: 166.65 ms | tokens/sec: 36.87 | norm: 1.85\n",
      "step : 3425 | loss: 1.7012766599655151 | dt: 169.47 ms | tokens/sec: 36.26 | norm: 1.86\n",
      "step : 3426 | loss: 1.7789819240570068 | dt: 166.88 ms | tokens/sec: 36.82 | norm: 2.33\n",
      "step : 3427 | loss: 1.8612744808197021 | dt: 165.22 ms | tokens/sec: 37.19 | norm: 2.13\n",
      "step : 3428 | loss: 1.7668805122375488 | dt: 165.35 ms | tokens/sec: 37.16 | norm: 2.31\n",
      "step : 3429 | loss: 1.7865140438079834 | dt: 166.39 ms | tokens/sec: 36.92 | norm: 2.01\n",
      "step : 3430 | loss: 1.824702262878418 | dt: 165.72 ms | tokens/sec: 37.08 | norm: 1.96\n",
      "step : 3431 | loss: 1.6861512660980225 | dt: 167.41 ms | tokens/sec: 36.70 | norm: 2.14\n",
      "step : 3432 | loss: 1.7746013402938843 | dt: 166.84 ms | tokens/sec: 36.83 | norm: 1.97\n",
      "step : 3433 | loss: 1.8365730047225952 | dt: 166.02 ms | tokens/sec: 37.01 | norm: 2.13\n",
      "step : 3434 | loss: 1.9162330627441406 | dt: 165.92 ms | tokens/sec: 37.03 | norm: 2.14\n",
      "step : 3435 | loss: 1.7044991254806519 | dt: 166.71 ms | tokens/sec: 36.85 | norm: 1.85\n",
      "step : 3436 | loss: 1.8649519681930542 | dt: 165.97 ms | tokens/sec: 37.02 | norm: 1.95\n",
      "step : 3437 | loss: 1.7568578720092773 | dt: 167.35 ms | tokens/sec: 36.71 | norm: 1.87\n",
      "step : 3438 | loss: 1.8485921621322632 | dt: 166.76 ms | tokens/sec: 36.84 | norm: 1.83\n",
      "step : 3439 | loss: 1.9634511470794678 | dt: 165.77 ms | tokens/sec: 37.06 | norm: 2.02\n",
      "step : 3440 | loss: 1.9517635107040405 | dt: 166.08 ms | tokens/sec: 36.99 | norm: 2.04\n",
      "step : 3441 | loss: 1.7694957256317139 | dt: 167.37 ms | tokens/sec: 36.71 | norm: 2.19\n",
      "step : 3442 | loss: 1.8095946311950684 | dt: 166.18 ms | tokens/sec: 36.97 | norm: 2.18\n",
      "step : 3443 | loss: 1.8301703929901123 | dt: 170.19 ms | tokens/sec: 36.10 | norm: 2.19\n",
      "step : 3444 | loss: 1.718165397644043 | dt: 166.98 ms | tokens/sec: 36.79 | norm: 2.03\n",
      "step : 3445 | loss: 1.7281463146209717 | dt: 164.61 ms | tokens/sec: 37.33 | norm: 2.71\n",
      "step : 3446 | loss: 2.052460193634033 | dt: 165.43 ms | tokens/sec: 37.14 | norm: 2.29\n",
      "step : 3447 | loss: 2.011439800262451 | dt: 166.66 ms | tokens/sec: 36.87 | norm: 2.21\n",
      "step : 3448 | loss: 1.9564250707626343 | dt: 165.86 ms | tokens/sec: 37.04 | norm: 2.11\n",
      "step : 3449 | loss: 1.851793646812439 | dt: 167.71 ms | tokens/sec: 36.63 | norm: 1.99\n",
      "step : 3450 | loss: 1.8325446844100952 | dt: 166.77 ms | tokens/sec: 36.84 | norm: 1.92\n",
      "step : 3451 | loss: 1.896660566329956 | dt: 165.83 ms | tokens/sec: 37.05 | norm: 1.79\n",
      "step : 3452 | loss: 1.7835744619369507 | dt: 166.32 ms | tokens/sec: 36.94 | norm: 1.69\n",
      "step : 3453 | loss: 1.782505989074707 | dt: 166.77 ms | tokens/sec: 36.84 | norm: 1.92\n",
      "step : 3454 | loss: 1.7531242370605469 | dt: 165.91 ms | tokens/sec: 37.03 | norm: 1.84\n",
      "step : 3455 | loss: 1.7457053661346436 | dt: 167.14 ms | tokens/sec: 36.76 | norm: 1.94\n",
      "step : 3456 | loss: 1.6268929243087769 | dt: 167.62 ms | tokens/sec: 36.66 | norm: 1.71\n",
      "step : 3457 | loss: 1.723634123802185 | dt: 166.05 ms | tokens/sec: 37.00 | norm: 1.91\n",
      "step : 3458 | loss: 1.7979049682617188 | dt: 166.05 ms | tokens/sec: 37.00 | norm: 1.83\n",
      "step : 3459 | loss: 1.9537867307662964 | dt: 166.91 ms | tokens/sec: 36.81 | norm: 2.24\n",
      "step : 3460 | loss: 1.7910442352294922 | dt: 165.60 ms | tokens/sec: 37.10 | norm: 2.23\n",
      "step : 3461 | loss: 1.6765851974487305 | dt: 167.01 ms | tokens/sec: 36.79 | norm: 1.99\n",
      "step : 3462 | loss: 1.6637248992919922 | dt: 167.58 ms | tokens/sec: 36.66 | norm: 2.06\n",
      "step : 3463 | loss: 1.4497870206832886 | dt: 165.91 ms | tokens/sec: 37.03 | norm: 1.76\n",
      "step : 3464 | loss: 1.7897056341171265 | dt: 165.92 ms | tokens/sec: 37.03 | norm: 2.00\n",
      "step : 3465 | loss: 1.81182861328125 | dt: 167.26 ms | tokens/sec: 36.73 | norm: 1.95\n",
      "step : 3466 | loss: 1.9327490329742432 | dt: 166.58 ms | tokens/sec: 36.88 | norm: 2.30\n",
      "step : 3467 | loss: 1.871309757232666 | dt: 166.69 ms | tokens/sec: 36.86 | norm: 2.10\n",
      "step : 3468 | loss: 1.8245381116867065 | dt: 167.65 ms | tokens/sec: 36.65 | norm: 1.83\n",
      "step : 3469 | loss: 1.6559298038482666 | dt: 166.13 ms | tokens/sec: 36.98 | norm: 1.82\n",
      "step : 3470 | loss: 1.677978754043579 | dt: 165.57 ms | tokens/sec: 37.11 | norm: 1.71\n",
      "step : 3471 | loss: 1.642404556274414 | dt: 166.90 ms | tokens/sec: 36.81 | norm: 1.82\n",
      "step : 3472 | loss: 1.7424777746200562 | dt: 166.45 ms | tokens/sec: 36.91 | norm: 1.81\n",
      "step : 3473 | loss: 1.7813485860824585 | dt: 166.81 ms | tokens/sec: 36.83 | norm: 1.81\n",
      "step : 3474 | loss: 1.7986682653427124 | dt: 167.63 ms | tokens/sec: 36.65 | norm: 2.31\n",
      "step : 3475 | loss: 1.7145285606384277 | dt: 166.07 ms | tokens/sec: 37.00 | norm: 2.05\n",
      "step : 3476 | loss: 1.7770379781723022 | dt: 165.62 ms | tokens/sec: 37.10 | norm: 1.79\n",
      "step : 3477 | loss: 1.7592138051986694 | dt: 166.90 ms | tokens/sec: 36.81 | norm: 2.02\n",
      "step : 3478 | loss: 1.6756538152694702 | dt: 165.98 ms | tokens/sec: 37.02 | norm: 1.93\n",
      "step : 3479 | loss: 1.5985996723175049 | dt: 166.88 ms | tokens/sec: 36.82 | norm: 1.98\n",
      "step : 3480 | loss: 1.6442407369613647 | dt: 167.81 ms | tokens/sec: 36.61 | norm: 1.75\n",
      "step : 3481 | loss: 1.7292547225952148 | dt: 167.85 ms | tokens/sec: 36.60 | norm: 2.01\n",
      "step : 3482 | loss: 1.7751388549804688 | dt: 166.25 ms | tokens/sec: 36.96 | norm: 2.27\n",
      "step : 3483 | loss: 1.6941072940826416 | dt: 165.84 ms | tokens/sec: 37.05 | norm: 1.99\n",
      "step : 3484 | loss: 1.69010329246521 | dt: 165.64 ms | tokens/sec: 37.09 | norm: 1.97\n",
      "step : 3485 | loss: 1.7196881771087646 | dt: 166.62 ms | tokens/sec: 36.87 | norm: 1.83\n",
      "step : 3486 | loss: 1.614457130432129 | dt: 166.92 ms | tokens/sec: 36.81 | norm: 1.99\n",
      "step : 3487 | loss: 1.68655526638031 | dt: 166.30 ms | tokens/sec: 36.95 | norm: 2.03\n",
      "step : 3488 | loss: 1.7574384212493896 | dt: 165.85 ms | tokens/sec: 37.05 | norm: 2.16\n",
      "step : 3489 | loss: 1.830665946006775 | dt: 167.07 ms | tokens/sec: 36.77 | norm: 2.09\n",
      "step : 3490 | loss: 1.6510531902313232 | dt: 165.68 ms | tokens/sec: 37.08 | norm: 1.77\n",
      "step : 3491 | loss: 1.8173177242279053 | dt: 166.93 ms | tokens/sec: 36.81 | norm: 2.06\n",
      "step : 3492 | loss: 1.709202766418457 | dt: 166.91 ms | tokens/sec: 36.81 | norm: 1.87\n",
      "step : 3493 | loss: 1.8183887004852295 | dt: 168.86 ms | tokens/sec: 36.39 | norm: 2.05\n",
      "step : 3494 | loss: 1.9398868083953857 | dt: 166.54 ms | tokens/sec: 36.89 | norm: 2.50\n",
      "step : 3495 | loss: 1.932541847229004 | dt: 165.83 ms | tokens/sec: 37.05 | norm: 2.39\n",
      "step : 3496 | loss: 1.7616064548492432 | dt: 165.89 ms | tokens/sec: 37.04 | norm: 2.16\n",
      "step : 3497 | loss: 1.7503411769866943 | dt: 166.62 ms | tokens/sec: 36.88 | norm: 2.27\n",
      "step : 3498 | loss: 1.7691128253936768 | dt: 166.67 ms | tokens/sec: 36.86 | norm: 1.89\n",
      "step : 3499 | loss: 1.648834466934204 | dt: 165.73 ms | tokens/sec: 37.07 | norm: 2.00\n",
      "step : 3500 | loss: 1.6798237562179565 | dt: 166.15 ms | tokens/sec: 36.98 | norm: 2.00\n",
      "step : 3501 | loss: 1.9646680355072021 | dt: 166.86 ms | tokens/sec: 36.82 | norm: 2.40\n",
      "step : 3502 | loss: 1.9359668493270874 | dt: 166.00 ms | tokens/sec: 37.01 | norm: 2.13\n",
      "step : 3503 | loss: 1.893096685409546 | dt: 167.09 ms | tokens/sec: 36.77 | norm: 2.43\n",
      "step : 3504 | loss: 1.7977464199066162 | dt: 166.88 ms | tokens/sec: 36.82 | norm: 1.99\n",
      "step : 3505 | loss: 1.760761022567749 | dt: 166.36 ms | tokens/sec: 36.93 | norm: 1.76\n",
      "step : 3506 | loss: 1.8420060873031616 | dt: 167.29 ms | tokens/sec: 36.73 | norm: 2.14\n",
      "step : 3507 | loss: 1.7349761724472046 | dt: 167.22 ms | tokens/sec: 36.74 | norm: 1.97\n",
      "step : 3508 | loss: 1.7368266582489014 | dt: 166.26 ms | tokens/sec: 36.95 | norm: 2.00\n",
      "step : 3509 | loss: 1.7144054174423218 | dt: 166.81 ms | tokens/sec: 36.83 | norm: 1.98\n",
      "step : 3510 | loss: 1.6965577602386475 | dt: 167.10 ms | tokens/sec: 36.77 | norm: 1.90\n",
      "step : 3511 | loss: 1.56927490234375 | dt: 165.83 ms | tokens/sec: 37.05 | norm: 1.76\n",
      "step : 3512 | loss: 1.6916555166244507 | dt: 166.43 ms | tokens/sec: 36.92 | norm: 1.92\n",
      "step : 3513 | loss: 1.7318227291107178 | dt: 167.01 ms | tokens/sec: 36.79 | norm: 1.88\n",
      "step : 3514 | loss: 1.8639037609100342 | dt: 166.87 ms | tokens/sec: 36.82 | norm: 2.08\n",
      "step : 3515 | loss: 1.7186110019683838 | dt: 167.94 ms | tokens/sec: 36.59 | norm: 1.96\n",
      "step : 3516 | loss: 1.604173183441162 | dt: 167.15 ms | tokens/sec: 36.76 | norm: 1.77\n",
      "step : 3517 | loss: 1.5949599742889404 | dt: 165.46 ms | tokens/sec: 37.13 | norm: 2.00\n",
      "step : 3518 | loss: 1.4014067649841309 | dt: 167.62 ms | tokens/sec: 36.65 | norm: 1.61\n",
      "step : 3519 | loss: 1.7341521978378296 | dt: 166.92 ms | tokens/sec: 36.81 | norm: 2.12\n",
      "step : 3520 | loss: 1.7501838207244873 | dt: 166.00 ms | tokens/sec: 37.01 | norm: 2.00\n",
      "step : 3521 | loss: 1.8508355617523193 | dt: 167.45 ms | tokens/sec: 36.69 | norm: 2.01\n",
      "step : 3522 | loss: 1.815660834312439 | dt: 165.75 ms | tokens/sec: 37.07 | norm: 2.38\n",
      "step : 3523 | loss: 1.732566237449646 | dt: 165.15 ms | tokens/sec: 37.20 | norm: 1.83\n",
      "step : 3524 | loss: 1.6063168048858643 | dt: 165.65 ms | tokens/sec: 37.09 | norm: 1.94\n",
      "step : 3525 | loss: 1.6161221265792847 | dt: 166.92 ms | tokens/sec: 36.81 | norm: 1.68\n",
      "step : 3526 | loss: 1.572094202041626 | dt: 165.71 ms | tokens/sec: 37.08 | norm: 1.77\n",
      "step : 3527 | loss: 1.6675456762313843 | dt: 166.67 ms | tokens/sec: 36.86 | norm: 1.75\n",
      "step : 3528 | loss: 1.7046568393707275 | dt: 167.87 ms | tokens/sec: 36.60 | norm: 2.10\n",
      "step : 3529 | loss: 1.7237619161605835 | dt: 166.65 ms | tokens/sec: 36.87 | norm: 1.80\n",
      "step : 3530 | loss: 1.6553163528442383 | dt: 167.98 ms | tokens/sec: 36.58 | norm: 1.77\n",
      "step : 3531 | loss: 1.701566219329834 | dt: 168.06 ms | tokens/sec: 36.56 | norm: 1.88\n",
      "step : 3532 | loss: 1.6796315908432007 | dt: 168.16 ms | tokens/sec: 36.54 | norm: 1.85\n",
      "step : 3533 | loss: 1.6060527563095093 | dt: 168.15 ms | tokens/sec: 36.54 | norm: 1.91\n",
      "step : 3534 | loss: 1.5152595043182373 | dt: 169.03 ms | tokens/sec: 36.35 | norm: 1.77\n",
      "step : 3535 | loss: 1.5404374599456787 | dt: 168.88 ms | tokens/sec: 36.38 | norm: 1.74\n",
      "step : 3536 | loss: 1.6178185939788818 | dt: 168.46 ms | tokens/sec: 36.47 | norm: 1.83\n",
      "step : 3537 | loss: 1.6877416372299194 | dt: 167.81 ms | tokens/sec: 36.61 | norm: 1.93\n",
      "step : 3538 | loss: 1.611581563949585 | dt: 168.34 ms | tokens/sec: 36.50 | norm: 1.94\n",
      "step : 3539 | loss: 1.6028989553451538 | dt: 168.14 ms | tokens/sec: 36.54 | norm: 1.89\n",
      "step : 3540 | loss: 1.6318917274475098 | dt: 167.29 ms | tokens/sec: 36.73 | norm: 1.80\n",
      "step : 3541 | loss: 1.5410417318344116 | dt: 167.58 ms | tokens/sec: 36.66 | norm: 1.85\n",
      "step : 3542 | loss: 1.6298635005950928 | dt: 167.80 ms | tokens/sec: 36.62 | norm: 1.82\n",
      "step : 3543 | loss: 1.695525050163269 | dt: 168.09 ms | tokens/sec: 36.55 | norm: 2.06\n",
      "step : 3544 | loss: 1.7545900344848633 | dt: 167.53 ms | tokens/sec: 36.67 | norm: 2.02\n",
      "step : 3545 | loss: 1.5922744274139404 | dt: 168.74 ms | tokens/sec: 36.41 | norm: 1.83\n",
      "step : 3546 | loss: 1.7552932500839233 | dt: 168.88 ms | tokens/sec: 36.38 | norm: 2.01\n",
      "step : 3547 | loss: 1.6551542282104492 | dt: 168.16 ms | tokens/sec: 36.54 | norm: 1.97\n",
      "step : 3548 | loss: 1.7231037616729736 | dt: 168.54 ms | tokens/sec: 36.45 | norm: 1.82\n",
      "step : 3549 | loss: 1.8259119987487793 | dt: 168.79 ms | tokens/sec: 36.40 | norm: 1.80\n",
      "step : 3550 | loss: 1.8117520809173584 | dt: 168.92 ms | tokens/sec: 36.37 | norm: 2.27\n",
      "step : 3551 | loss: 1.6507246494293213 | dt: 167.79 ms | tokens/sec: 36.62 | norm: 2.09\n",
      "step : 3552 | loss: 1.6825902462005615 | dt: 168.09 ms | tokens/sec: 36.55 | norm: 1.86\n",
      "step : 3553 | loss: 1.6855380535125732 | dt: 166.52 ms | tokens/sec: 36.90 | norm: 1.90\n",
      "step : 3554 | loss: 1.5748250484466553 | dt: 167.54 ms | tokens/sec: 36.67 | norm: 1.86\n",
      "step : 3555 | loss: 1.6059259176254272 | dt: 167.94 ms | tokens/sec: 36.58 | norm: 1.77\n",
      "step : 3556 | loss: 1.9134467840194702 | dt: 169.03 ms | tokens/sec: 36.35 | norm: 2.43\n",
      "step : 3557 | loss: 1.8768401145935059 | dt: 168.44 ms | tokens/sec: 36.48 | norm: 2.15\n",
      "step : 3558 | loss: 1.840468168258667 | dt: 168.05 ms | tokens/sec: 36.56 | norm: 2.02\n",
      "step : 3559 | loss: 1.7378435134887695 | dt: 166.88 ms | tokens/sec: 36.82 | norm: 2.01\n",
      "step : 3560 | loss: 1.7000129222869873 | dt: 168.76 ms | tokens/sec: 36.41 | norm: 1.80\n",
      "step : 3561 | loss: 1.7836779356002808 | dt: 167.96 ms | tokens/sec: 36.58 | norm: 1.98\n",
      "step : 3562 | loss: 1.6795600652694702 | dt: 168.33 ms | tokens/sec: 36.50 | norm: 2.11\n",
      "step : 3563 | loss: 1.6862115859985352 | dt: 167.23 ms | tokens/sec: 36.74 | norm: 1.84\n",
      "step : 3564 | loss: 1.6511528491973877 | dt: 168.39 ms | tokens/sec: 36.49 | norm: 1.89\n",
      "step : 3565 | loss: 1.6487061977386475 | dt: 168.16 ms | tokens/sec: 36.54 | norm: 1.95\n",
      "step : 3566 | loss: 1.5011696815490723 | dt: 168.87 ms | tokens/sec: 36.38 | norm: 1.86\n",
      "step : 3567 | loss: 1.6110126972198486 | dt: 168.16 ms | tokens/sec: 36.54 | norm: 1.82\n",
      "step : 3568 | loss: 1.6758298873901367 | dt: 169.11 ms | tokens/sec: 36.33 | norm: 2.10\n",
      "step : 3569 | loss: 1.8169500827789307 | dt: 168.46 ms | tokens/sec: 36.47 | norm: 2.18\n",
      "step : 3570 | loss: 1.6563377380371094 | dt: 168.56 ms | tokens/sec: 36.45 | norm: 2.25\n",
      "step : 3571 | loss: 1.5517181158065796 | dt: 168.11 ms | tokens/sec: 36.55 | norm: 2.01\n",
      "step : 3572 | loss: 1.5463838577270508 | dt: 167.95 ms | tokens/sec: 36.58 | norm: 2.19\n",
      "step : 3573 | loss: 1.3441734313964844 | dt: 167.39 ms | tokens/sec: 36.70 | norm: 1.58\n",
      "step : 3574 | loss: 1.6949409246444702 | dt: 168.44 ms | tokens/sec: 36.48 | norm: 2.04\n",
      "step : 3575 | loss: 1.7005326747894287 | dt: 168.28 ms | tokens/sec: 36.51 | norm: 2.12\n",
      "step : 3576 | loss: 1.8115642070770264 | dt: 169.02 ms | tokens/sec: 36.35 | norm: 2.03\n",
      "step : 3577 | loss: 1.764582633972168 | dt: 168.71 ms | tokens/sec: 36.42 | norm: 2.34\n",
      "step : 3578 | loss: 1.6715577840805054 | dt: 168.37 ms | tokens/sec: 36.49 | norm: 2.07\n",
      "step : 3579 | loss: 1.5521730184555054 | dt: 168.47 ms | tokens/sec: 36.47 | norm: 2.22\n",
      "step : 3580 | loss: 1.5623753070831299 | dt: 168.07 ms | tokens/sec: 36.56 | norm: 1.75\n",
      "step : 3581 | loss: 1.5201395750045776 | dt: 167.37 ms | tokens/sec: 36.71 | norm: 2.10\n",
      "step : 3582 | loss: 1.611975073814392 | dt: 167.98 ms | tokens/sec: 36.58 | norm: 1.89\n",
      "step : 3583 | loss: 1.6372270584106445 | dt: 167.62 ms | tokens/sec: 36.65 | norm: 1.88\n",
      "step : 3584 | loss: 1.6440562009811401 | dt: 168.01 ms | tokens/sec: 36.57 | norm: 2.09\n",
      "step : 3585 | loss: 1.5663783550262451 | dt: 168.01 ms | tokens/sec: 36.57 | norm: 1.89\n",
      "step : 3586 | loss: 1.623368263244629 | dt: 168.78 ms | tokens/sec: 36.40 | norm: 1.75\n",
      "step : 3587 | loss: 1.6059188842773438 | dt: 170.09 ms | tokens/sec: 36.12 | norm: 2.32\n",
      "step : 3588 | loss: 1.554231882095337 | dt: 169.29 ms | tokens/sec: 36.29 | norm: 3.53\n",
      "step : 3589 | loss: 1.457075834274292 | dt: 168.73 ms | tokens/sec: 36.41 | norm: 1.74\n",
      "step : 3590 | loss: 1.4977692365646362 | dt: 168.33 ms | tokens/sec: 36.50 | norm: 1.85\n",
      "step : 3591 | loss: 1.5707147121429443 | dt: 167.89 ms | tokens/sec: 36.60 | norm: 2.01\n",
      "step : 3592 | loss: 1.6593387126922607 | dt: 168.18 ms | tokens/sec: 36.53 | norm: 2.26\n",
      "step : 3593 | loss: 1.5588635206222534 | dt: 169.46 ms | tokens/sec: 36.26 | norm: 1.88\n",
      "step : 3594 | loss: 1.5590213537216187 | dt: 168.94 ms | tokens/sec: 36.37 | norm: 2.20\n",
      "step : 3595 | loss: 1.5735419988632202 | dt: 168.52 ms | tokens/sec: 36.46 | norm: 1.87\n",
      "step : 3596 | loss: 1.4724130630493164 | dt: 168.42 ms | tokens/sec: 36.48 | norm: 1.81\n",
      "step : 3597 | loss: 1.5526208877563477 | dt: 168.42 ms | tokens/sec: 36.48 | norm: 2.05\n",
      "step : 3598 | loss: 1.6150339841842651 | dt: 168.13 ms | tokens/sec: 36.54 | norm: 2.01\n",
      "step : 3599 | loss: 1.6700137853622437 | dt: 169.08 ms | tokens/sec: 36.34 | norm: 1.98\n",
      "step : 3600 | loss: 1.5140807628631592 | dt: 168.72 ms | tokens/sec: 36.42 | norm: 2.41\n",
      "step : 3601 | loss: 1.6791322231292725 | dt: 168.58 ms | tokens/sec: 36.45 | norm: 2.01\n",
      "step : 3602 | loss: 1.5947644710540771 | dt: 168.90 ms | tokens/sec: 36.38 | norm: 2.01\n",
      "step : 3603 | loss: 1.6508958339691162 | dt: 168.49 ms | tokens/sec: 36.46 | norm: 1.92\n",
      "step : 3604 | loss: 1.7569386959075928 | dt: 167.84 ms | tokens/sec: 36.61 | norm: 2.14\n",
      "step : 3605 | loss: 1.7532356977462769 | dt: 169.32 ms | tokens/sec: 36.29 | norm: 2.18\n",
      "step : 3606 | loss: 1.6057742834091187 | dt: 165.93 ms | tokens/sec: 37.03 | norm: 2.00\n",
      "step : 3607 | loss: 1.610031008720398 | dt: 167.05 ms | tokens/sec: 36.78 | norm: 2.16\n",
      "step : 3608 | loss: 1.6161965131759644 | dt: 166.15 ms | tokens/sec: 36.98 | norm: 1.92\n",
      "step : 3609 | loss: 1.512467384338379 | dt: 167.58 ms | tokens/sec: 36.66 | norm: 1.88\n",
      "step : 3610 | loss: 1.537270426750183 | dt: 167.44 ms | tokens/sec: 36.69 | norm: 1.96\n",
      "step : 3611 | loss: 1.848055124282837 | dt: 166.17 ms | tokens/sec: 36.97 | norm: 2.21\n",
      "step : 3612 | loss: 1.7871263027191162 | dt: 166.80 ms | tokens/sec: 36.84 | norm: 1.97\n",
      "step : 3613 | loss: 1.7453043460845947 | dt: 167.26 ms | tokens/sec: 36.73 | norm: 2.30\n",
      "step : 3614 | loss: 1.6547784805297852 | dt: 167.70 ms | tokens/sec: 36.64 | norm: 2.25\n",
      "step : 3615 | loss: 1.6257469654083252 | dt: 167.69 ms | tokens/sec: 36.64 | norm: 1.88\n",
      "step : 3616 | loss: 1.70855712890625 | dt: 167.30 ms | tokens/sec: 36.73 | norm: 2.02\n",
      "step : 3617 | loss: 1.621106505393982 | dt: 168.77 ms | tokens/sec: 36.40 | norm: 2.04\n",
      "step : 3618 | loss: 1.614670753479004 | dt: 169.73 ms | tokens/sec: 36.20 | norm: 1.91\n",
      "step : 3619 | loss: 1.606867790222168 | dt: 167.98 ms | tokens/sec: 36.58 | norm: 1.96\n",
      "step : 3620 | loss: 1.600825309753418 | dt: 168.33 ms | tokens/sec: 36.50 | norm: 2.29\n",
      "step : 3621 | loss: 1.4537129402160645 | dt: 168.90 ms | tokens/sec: 36.38 | norm: 1.97\n",
      "step : 3622 | loss: 1.546592116355896 | dt: 168.65 ms | tokens/sec: 36.43 | norm: 1.88\n",
      "step : 3623 | loss: 1.6101305484771729 | dt: 168.53 ms | tokens/sec: 36.46 | norm: 1.83\n",
      "step : 3624 | loss: 1.7488874197006226 | dt: 168.52 ms | tokens/sec: 36.46 | norm: 2.16\n",
      "step : 3625 | loss: 1.6170648336410522 | dt: 167.98 ms | tokens/sec: 36.58 | norm: 2.10\n",
      "step : 3626 | loss: 1.5037673711776733 | dt: 168.17 ms | tokens/sec: 36.54 | norm: 1.85\n",
      "step : 3627 | loss: 1.5045955181121826 | dt: 168.96 ms | tokens/sec: 36.36 | norm: 2.05\n",
      "step : 3628 | loss: 1.2938532829284668 | dt: 168.33 ms | tokens/sec: 36.50 | norm: 1.73\n",
      "step : 3629 | loss: 1.6436294317245483 | dt: 168.39 ms | tokens/sec: 36.49 | norm: 2.17\n",
      "step : 3630 | loss: 1.6564834117889404 | dt: 169.76 ms | tokens/sec: 36.19 | norm: 2.31\n",
      "step : 3631 | loss: 1.7762397527694702 | dt: 168.19 ms | tokens/sec: 36.53 | norm: 2.21\n",
      "step : 3632 | loss: 1.7518887519836426 | dt: 167.92 ms | tokens/sec: 36.59 | norm: 2.36\n",
      "step : 3633 | loss: 1.6752026081085205 | dt: 167.52 ms | tokens/sec: 36.68 | norm: 2.21\n",
      "step : 3634 | loss: 1.5262985229492188 | dt: 167.30 ms | tokens/sec: 36.72 | norm: 2.11\n",
      "step : 3635 | loss: 1.520297884941101 | dt: 168.62 ms | tokens/sec: 36.44 | norm: 1.92\n",
      "step : 3636 | loss: 1.4803694486618042 | dt: 168.72 ms | tokens/sec: 36.42 | norm: 1.99\n",
      "step : 3637 | loss: 1.5724117755889893 | dt: 169.26 ms | tokens/sec: 36.30 | norm: 1.87\n",
      "step : 3638 | loss: 1.5716708898544312 | dt: 168.17 ms | tokens/sec: 36.54 | norm: 1.98\n",
      "step : 3639 | loss: 1.6004064083099365 | dt: 168.13 ms | tokens/sec: 36.54 | norm: 1.90\n",
      "step : 3640 | loss: 1.5167951583862305 | dt: 167.96 ms | tokens/sec: 36.58 | norm: 1.95\n",
      "step : 3641 | loss: 1.5729917287826538 | dt: 168.61 ms | tokens/sec: 36.44 | norm: 1.96\n",
      "step : 3642 | loss: 1.596355676651001 | dt: 168.18 ms | tokens/sec: 36.53 | norm: 2.00\n",
      "step : 3643 | loss: 1.546069860458374 | dt: 167.62 ms | tokens/sec: 36.65 | norm: 1.93\n",
      "step : 3644 | loss: 1.4058265686035156 | dt: 166.96 ms | tokens/sec: 36.80 | norm: 1.85\n",
      "step : 3645 | loss: 1.4432847499847412 | dt: 167.32 ms | tokens/sec: 36.72 | norm: 1.84\n",
      "step : 3646 | loss: 1.5151736736297607 | dt: 168.24 ms | tokens/sec: 36.52 | norm: 2.04\n",
      "step : 3647 | loss: 1.5832065343856812 | dt: 168.23 ms | tokens/sec: 36.52 | norm: 2.04\n",
      "step : 3648 | loss: 1.4834821224212646 | dt: 168.24 ms | tokens/sec: 36.52 | norm: 1.95\n",
      "step : 3649 | loss: 1.5017870664596558 | dt: 170.79 ms | tokens/sec: 35.97 | norm: 1.92\n",
      "step : 3650 | loss: 1.5125293731689453 | dt: 168.85 ms | tokens/sec: 36.39 | norm: 1.71\n",
      "step : 3651 | loss: 1.4303264617919922 | dt: 168.90 ms | tokens/sec: 36.38 | norm: 1.91\n",
      "step : 3652 | loss: 1.5267181396484375 | dt: 167.51 ms | tokens/sec: 36.68 | norm: 1.97\n",
      "step : 3653 | loss: 1.5827174186706543 | dt: 168.11 ms | tokens/sec: 36.55 | norm: 2.16\n",
      "step : 3654 | loss: 1.6397349834442139 | dt: 168.64 ms | tokens/sec: 36.43 | norm: 2.13\n",
      "step : 3655 | loss: 1.4984849691390991 | dt: 170.20 ms | tokens/sec: 36.10 | norm: 1.96\n",
      "step : 3656 | loss: 1.6355823278427124 | dt: 169.41 ms | tokens/sec: 36.27 | norm: 2.17\n",
      "step : 3657 | loss: 1.542184591293335 | dt: 169.63 ms | tokens/sec: 36.22 | norm: 1.91\n",
      "step : 3658 | loss: 1.5915172100067139 | dt: 169.30 ms | tokens/sec: 36.29 | norm: 1.83\n",
      "step : 3659 | loss: 1.7044514417648315 | dt: 168.40 ms | tokens/sec: 36.48 | norm: 2.00\n",
      "step : 3660 | loss: 1.6805965900421143 | dt: 169.14 ms | tokens/sec: 36.32 | norm: 2.08\n",
      "step : 3661 | loss: 1.5278103351593018 | dt: 170.44 ms | tokens/sec: 36.05 | norm: 2.07\n",
      "step : 3662 | loss: 1.5630762577056885 | dt: 169.35 ms | tokens/sec: 36.28 | norm: 2.04\n",
      "step : 3663 | loss: 1.5657129287719727 | dt: 170.16 ms | tokens/sec: 36.11 | norm: 2.04\n",
      "step : 3664 | loss: 1.4679327011108398 | dt: 169.49 ms | tokens/sec: 36.25 | norm: 2.03\n",
      "step : 3665 | loss: 1.4892299175262451 | dt: 168.96 ms | tokens/sec: 36.36 | norm: 2.02\n",
      "step : 3666 | loss: 1.7924957275390625 | dt: 169.53 ms | tokens/sec: 36.24 | norm: 2.34\n",
      "step : 3667 | loss: 1.7404330968856812 | dt: 171.22 ms | tokens/sec: 35.88 | norm: 2.25\n",
      "step : 3668 | loss: 1.7021565437316895 | dt: 169.65 ms | tokens/sec: 36.22 | norm: 2.13\n",
      "step : 3669 | loss: 1.6144622564315796 | dt: 169.68 ms | tokens/sec: 36.21 | norm: 2.24\n",
      "step : 3670 | loss: 1.5717376470565796 | dt: 169.36 ms | tokens/sec: 36.28 | norm: 1.93\n",
      "step : 3671 | loss: 1.6434320211410522 | dt: 169.11 ms | tokens/sec: 36.33 | norm: 1.92\n",
      "step : 3672 | loss: 1.5469506978988647 | dt: 170.52 ms | tokens/sec: 36.03 | norm: 1.86\n",
      "step : 3673 | loss: 1.5440305471420288 | dt: 172.96 ms | tokens/sec: 35.52 | norm: 2.01\n",
      "step : 3674 | loss: 1.5364078283309937 | dt: 170.23 ms | tokens/sec: 36.09 | norm: 1.87\n",
      "step : 3675 | loss: 1.540173053741455 | dt: 171.05 ms | tokens/sec: 35.92 | norm: 1.88\n",
      "step : 3676 | loss: 1.3991917371749878 | dt: 170.77 ms | tokens/sec: 35.98 | norm: 1.93\n",
      "step : 3677 | loss: 1.4823787212371826 | dt: 170.51 ms | tokens/sec: 36.03 | norm: 1.96\n",
      "step : 3678 | loss: 1.5416104793548584 | dt: 169.75 ms | tokens/sec: 36.20 | norm: 2.06\n",
      "step : 3679 | loss: 1.7150952816009521 | dt: 170.41 ms | tokens/sec: 36.06 | norm: 2.19\n",
      "step : 3680 | loss: 1.5701522827148438 | dt: 171.35 ms | tokens/sec: 35.86 | norm: 2.17\n",
      "step : 3681 | loss: 1.4513510465621948 | dt: 169.84 ms | tokens/sec: 36.17 | norm: 2.13\n",
      "step : 3682 | loss: 1.452006220817566 | dt: 169.86 ms | tokens/sec: 36.17 | norm: 1.99\n",
      "step : 3683 | loss: 1.2443486452102661 | dt: 169.67 ms | tokens/sec: 36.21 | norm: 1.91\n",
      "step : 3684 | loss: 1.5748424530029297 | dt: 173.26 ms | tokens/sec: 35.46 | norm: 2.04\n",
      "step : 3685 | loss: 1.59691321849823 | dt: 169.38 ms | tokens/sec: 36.27 | norm: 2.21\n",
      "step : 3686 | loss: 1.6943089962005615 | dt: 170.19 ms | tokens/sec: 36.10 | norm: 2.16\n",
      "step : 3687 | loss: 1.6534507274627686 | dt: 170.01 ms | tokens/sec: 36.14 | norm: 2.41\n",
      "step : 3688 | loss: 1.5917904376983643 | dt: 171.11 ms | tokens/sec: 35.91 | norm: 2.06\n",
      "step : 3689 | loss: 1.460700273513794 | dt: 170.97 ms | tokens/sec: 35.94 | norm: 1.98\n",
      "step : 3690 | loss: 1.4655275344848633 | dt: 170.95 ms | tokens/sec: 35.94 | norm: 1.86\n",
      "step : 3691 | loss: 1.4320772886276245 | dt: 169.57 ms | tokens/sec: 36.23 | norm: 1.94\n",
      "step : 3692 | loss: 1.5104941129684448 | dt: 171.35 ms | tokens/sec: 35.86 | norm: 1.99\n",
      "step : 3693 | loss: 1.5412315130233765 | dt: 170.29 ms | tokens/sec: 36.08 | norm: 2.20\n",
      "step : 3694 | loss: 1.5567162036895752 | dt: 169.94 ms | tokens/sec: 36.15 | norm: 2.03\n",
      "step : 3695 | loss: 1.4916398525238037 | dt: 169.18 ms | tokens/sec: 36.32 | norm: 2.17\n",
      "step : 3696 | loss: 1.5582307577133179 | dt: 169.91 ms | tokens/sec: 36.16 | norm: 2.10\n",
      "step : 3697 | loss: 1.545501470565796 | dt: 171.51 ms | tokens/sec: 35.82 | norm: 1.93\n",
      "step : 3698 | loss: 1.492516279220581 | dt: 169.99 ms | tokens/sec: 36.14 | norm: 2.04\n",
      "step : 3699 | loss: 1.3412911891937256 | dt: 170.44 ms | tokens/sec: 36.05 | norm: 1.78\n",
      "step : 3700 | loss: 1.383372187614441 | dt: 169.29 ms | tokens/sec: 36.29 | norm: 1.83\n",
      "step : 3701 | loss: 1.4492743015289307 | dt: 170.28 ms | tokens/sec: 36.08 | norm: 1.90\n",
      "step : 3702 | loss: 1.5300339460372925 | dt: 170.29 ms | tokens/sec: 36.08 | norm: 1.96\n",
      "step : 3703 | loss: 1.4465317726135254 | dt: 170.80 ms | tokens/sec: 35.97 | norm: 1.91\n",
      "step : 3704 | loss: 1.452813982963562 | dt: 170.47 ms | tokens/sec: 36.04 | norm: 1.93\n",
      "step : 3705 | loss: 1.4647517204284668 | dt: 170.12 ms | tokens/sec: 36.12 | norm: 1.85\n",
      "step : 3706 | loss: 1.3953907489776611 | dt: 170.73 ms | tokens/sec: 35.99 | norm: 1.85\n",
      "step : 3707 | loss: 1.4796322584152222 | dt: 169.84 ms | tokens/sec: 36.18 | norm: 1.84\n",
      "step : 3708 | loss: 1.5312576293945312 | dt: 170.32 ms | tokens/sec: 36.07 | norm: 2.21\n",
      "step : 3709 | loss: 1.5946226119995117 | dt: 170.46 ms | tokens/sec: 36.04 | norm: 2.17\n",
      "step : 3710 | loss: 1.4589691162109375 | dt: 171.52 ms | tokens/sec: 35.82 | norm: 1.88\n",
      "step : 3711 | loss: 1.594369888305664 | dt: 170.62 ms | tokens/sec: 36.01 | norm: 2.04\n",
      "step : 3712 | loss: 1.4878225326538086 | dt: 170.62 ms | tokens/sec: 36.01 | norm: 1.95\n",
      "step : 3713 | loss: 1.5322105884552002 | dt: 169.47 ms | tokens/sec: 36.26 | norm: 1.96\n",
      "step : 3714 | loss: 1.6407016515731812 | dt: 170.39 ms | tokens/sec: 36.06 | norm: 1.91\n",
      "step : 3715 | loss: 1.6246442794799805 | dt: 171.00 ms | tokens/sec: 35.93 | norm: 2.27\n",
      "step : 3716 | loss: 1.4615745544433594 | dt: 173.50 ms | tokens/sec: 35.41 | norm: 2.20\n",
      "step : 3717 | loss: 1.5044727325439453 | dt: 171.07 ms | tokens/sec: 35.92 | norm: 2.00\n",
      "step : 3718 | loss: 1.5008305311203003 | dt: 171.22 ms | tokens/sec: 35.88 | norm: 1.96\n",
      "step : 3719 | loss: 1.413332223892212 | dt: 171.30 ms | tokens/sec: 35.87 | norm: 2.50\n",
      "step : 3720 | loss: 1.4271725416183472 | dt: 169.76 ms | tokens/sec: 36.19 | norm: 1.89\n",
      "step : 3721 | loss: 1.733182430267334 | dt: 170.32 ms | tokens/sec: 36.07 | norm: 2.41\n",
      "step : 3722 | loss: 1.6828489303588867 | dt: 170.81 ms | tokens/sec: 35.97 | norm: 2.35\n",
      "step : 3723 | loss: 1.656445026397705 | dt: 171.70 ms | tokens/sec: 35.78 | norm: 2.37\n",
      "step : 3724 | loss: 1.5917222499847412 | dt: 170.28 ms | tokens/sec: 36.08 | norm: 2.17\n",
      "step : 3725 | loss: 1.534935474395752 | dt: 173.32 ms | tokens/sec: 35.45 | norm: 1.98\n",
      "step : 3726 | loss: 1.5989360809326172 | dt: 172.90 ms | tokens/sec: 35.53 | norm: 1.98\n",
      "step : 3727 | loss: 1.5170972347259521 | dt: 171.49 ms | tokens/sec: 35.83 | norm: 2.13\n",
      "step : 3728 | loss: 1.515167236328125 | dt: 172.72 ms | tokens/sec: 35.57 | norm: 1.88\n",
      "step : 3729 | loss: 1.5012316703796387 | dt: 171.54 ms | tokens/sec: 35.82 | norm: 1.89\n",
      "step : 3730 | loss: 1.5028884410858154 | dt: 172.22 ms | tokens/sec: 35.68 | norm: 2.02\n",
      "step : 3731 | loss: 1.362707495689392 | dt: 172.80 ms | tokens/sec: 35.55 | norm: 1.92\n",
      "step : 3732 | loss: 1.4495748281478882 | dt: 171.95 ms | tokens/sec: 35.73 | norm: 2.12\n",
      "step : 3733 | loss: 1.4866912364959717 | dt: 173.44 ms | tokens/sec: 35.42 | norm: 1.89\n",
      "step : 3734 | loss: 1.6486129760742188 | dt: 172.74 ms | tokens/sec: 35.57 | norm: 2.23\n",
      "step : 3735 | loss: 1.5240018367767334 | dt: 171.77 ms | tokens/sec: 35.77 | norm: 2.28\n",
      "step : 3736 | loss: 1.3977868556976318 | dt: 174.04 ms | tokens/sec: 35.30 | norm: 1.89\n",
      "step : 3737 | loss: 1.4082716703414917 | dt: 172.60 ms | tokens/sec: 35.60 | norm: 1.98\n",
      "step : 3738 | loss: 1.2081159353256226 | dt: 171.27 ms | tokens/sec: 35.87 | norm: 1.91\n",
      "step : 3739 | loss: 1.521343469619751 | dt: 173.31 ms | tokens/sec: 35.45 | norm: 2.28\n",
      "step : 3740 | loss: 1.5678895711898804 | dt: 173.61 ms | tokens/sec: 35.39 | norm: 2.40\n",
      "step : 3741 | loss: 1.6688655614852905 | dt: 171.97 ms | tokens/sec: 35.73 | norm: 2.53\n",
      "step : 3742 | loss: 1.6318033933639526 | dt: 172.48 ms | tokens/sec: 35.62 | norm: 2.47\n",
      "step : 3743 | loss: 1.550581693649292 | dt: 172.01 ms | tokens/sec: 35.72 | norm: 2.18\n",
      "step : 3744 | loss: 1.429262399673462 | dt: 172.60 ms | tokens/sec: 35.60 | norm: 2.17\n",
      "step : 3745 | loss: 1.4194390773773193 | dt: 172.40 ms | tokens/sec: 35.64 | norm: 2.17\n",
      "step : 3746 | loss: 1.4058231115341187 | dt: 171.75 ms | tokens/sec: 35.77 | norm: 2.19\n",
      "step : 3747 | loss: 1.4827733039855957 | dt: 172.69 ms | tokens/sec: 35.58 | norm: 2.06\n",
      "step : 3748 | loss: 1.5178674459457397 | dt: 171.67 ms | tokens/sec: 35.79 | norm: 2.14\n",
      "step : 3749 | loss: 1.5363719463348389 | dt: 171.68 ms | tokens/sec: 35.79 | norm: 2.19\n",
      "step : 3750 | loss: 1.4734206199645996 | dt: 171.84 ms | tokens/sec: 35.75 | norm: 2.14\n",
      "step : 3751 | loss: 1.5299367904663086 | dt: 171.85 ms | tokens/sec: 35.75 | norm: 2.10\n",
      "step : 3752 | loss: 1.5097355842590332 | dt: 171.49 ms | tokens/sec: 35.83 | norm: 2.18\n",
      "step : 3753 | loss: 1.4426474571228027 | dt: 171.69 ms | tokens/sec: 35.79 | norm: 2.16\n",
      "step : 3754 | loss: 1.3107353448867798 | dt: 171.45 ms | tokens/sec: 35.84 | norm: 1.98\n",
      "step : 3755 | loss: 1.3413991928100586 | dt: 172.89 ms | tokens/sec: 35.54 | norm: 1.98\n",
      "step : 3756 | loss: 1.4185373783111572 | dt: 171.09 ms | tokens/sec: 35.91 | norm: 2.10\n",
      "step : 3757 | loss: 1.4961556196212769 | dt: 170.71 ms | tokens/sec: 35.99 | norm: 2.28\n",
      "step : 3758 | loss: 1.4058111906051636 | dt: 172.89 ms | tokens/sec: 35.54 | norm: 2.14\n",
      "step : 3759 | loss: 1.3960412740707397 | dt: 172.62 ms | tokens/sec: 35.59 | norm: 2.02\n",
      "step : 3760 | loss: 1.399661898612976 | dt: 170.88 ms | tokens/sec: 35.96 | norm: 2.01\n",
      "step : 3761 | loss: 1.3394477367401123 | dt: 172.11 ms | tokens/sec: 35.70 | norm: 1.93\n",
      "step : 3762 | loss: 1.4174894094467163 | dt: 171.34 ms | tokens/sec: 35.86 | norm: 2.10\n",
      "step : 3763 | loss: 1.4809716939926147 | dt: 170.66 ms | tokens/sec: 36.00 | norm: 2.23\n",
      "step : 3764 | loss: 1.5321025848388672 | dt: 171.61 ms | tokens/sec: 35.80 | norm: 2.21\n",
      "step : 3765 | loss: 1.4087142944335938 | dt: 172.63 ms | tokens/sec: 35.59 | norm: 1.96\n",
      "step : 3766 | loss: 1.5413119792938232 | dt: 170.44 ms | tokens/sec: 36.05 | norm: 2.12\n",
      "step : 3767 | loss: 1.452271819114685 | dt: 170.31 ms | tokens/sec: 36.07 | norm: 1.87\n",
      "step : 3768 | loss: 1.493772268295288 | dt: 171.42 ms | tokens/sec: 35.84 | norm: 1.98\n",
      "step : 3769 | loss: 1.6055458784103394 | dt: 171.82 ms | tokens/sec: 35.76 | norm: 2.19\n",
      "step : 3770 | loss: 1.6056649684906006 | dt: 170.19 ms | tokens/sec: 36.10 | norm: 2.34\n",
      "step : 3771 | loss: 1.4339693784713745 | dt: 171.77 ms | tokens/sec: 35.77 | norm: 2.33\n",
      "step : 3772 | loss: 1.4641530513763428 | dt: 172.07 ms | tokens/sec: 35.71 | norm: 2.06\n",
      "step : 3773 | loss: 1.4512561559677124 | dt: 171.94 ms | tokens/sec: 35.73 | norm: 2.16\n",
      "step : 3774 | loss: 1.3727338314056396 | dt: 171.70 ms | tokens/sec: 35.78 | norm: 2.15\n",
      "step : 3775 | loss: 1.3638895750045776 | dt: 171.44 ms | tokens/sec: 35.84 | norm: 2.24\n",
      "step : 3776 | loss: 1.669478416442871 | dt: 170.94 ms | tokens/sec: 35.94 | norm: 2.26\n",
      "step : 3777 | loss: 1.623168706893921 | dt: 172.21 ms | tokens/sec: 35.68 | norm: 2.38\n",
      "step : 3778 | loss: 1.5985153913497925 | dt: 171.85 ms | tokens/sec: 35.75 | norm: 2.77\n",
      "step : 3779 | loss: 1.5247929096221924 | dt: 171.48 ms | tokens/sec: 35.83 | norm: 2.06\n",
      "step : 3780 | loss: 1.4679893255233765 | dt: 171.18 ms | tokens/sec: 35.89 | norm: 1.94\n",
      "step : 3781 | loss: 1.5382202863693237 | dt: 171.54 ms | tokens/sec: 35.82 | norm: 2.07\n",
      "step : 3782 | loss: 1.4651774168014526 | dt: 172.04 ms | tokens/sec: 35.71 | norm: 2.07\n",
      "step : 3783 | loss: 1.4640843868255615 | dt: 167.75 ms | tokens/sec: 36.63 | norm: 2.13\n",
      "step : 3784 | loss: 1.4276201725006104 | dt: 161.03 ms | tokens/sec: 38.15 | norm: 2.04\n",
      "step : 3785 | loss: 1.4290707111358643 | dt: 154.17 ms | tokens/sec: 39.85 | norm: 1.90\n",
      "step : 3786 | loss: 1.2988228797912598 | dt: 154.15 ms | tokens/sec: 39.86 | norm: 2.05\n",
      "step : 3787 | loss: 1.4020674228668213 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 1.96\n",
      "step : 3788 | loss: 1.4405994415283203 | dt: 154.21 ms | tokens/sec: 39.84 | norm: 2.01\n",
      "step : 3789 | loss: 1.601815938949585 | dt: 154.33 ms | tokens/sec: 39.81 | norm: 2.22\n",
      "step : 3790 | loss: 1.4786657094955444 | dt: 155.80 ms | tokens/sec: 39.44 | norm: 2.13\n",
      "step : 3791 | loss: 1.3481882810592651 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 2.08\n",
      "step : 3792 | loss: 1.345163106918335 | dt: 154.03 ms | tokens/sec: 39.89 | norm: 2.07\n",
      "step : 3793 | loss: 1.1543582677841187 | dt: 153.77 ms | tokens/sec: 39.96 | norm: 1.76\n",
      "step : 3794 | loss: 1.4631879329681396 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.12\n",
      "step : 3795 | loss: 1.495757818222046 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.12\n",
      "step : 3796 | loss: 1.5928010940551758 | dt: 155.10 ms | tokens/sec: 39.61 | norm: 2.31\n",
      "step : 3797 | loss: 1.5624053478240967 | dt: 156.58 ms | tokens/sec: 39.24 | norm: 2.36\n",
      "step : 3798 | loss: 1.4811580181121826 | dt: 154.12 ms | tokens/sec: 39.86 | norm: 2.07\n",
      "step : 3799 | loss: 1.3632380962371826 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 1.98\n",
      "step : 3800 | loss: 1.3725802898406982 | dt: 154.18 ms | tokens/sec: 39.85 | norm: 2.02\n",
      "step : 3801 | loss: 1.331629991531372 | dt: 153.87 ms | tokens/sec: 39.93 | norm: 1.90\n",
      "step : 3802 | loss: 1.4020774364471436 | dt: 153.94 ms | tokens/sec: 39.91 | norm: 2.06\n",
      "step : 3803 | loss: 1.4190518856048584 | dt: 155.43 ms | tokens/sec: 39.53 | norm: 2.04\n",
      "step : 3804 | loss: 1.4444636106491089 | dt: 154.59 ms | tokens/sec: 39.74 | norm: 2.05\n",
      "step : 3805 | loss: 1.4016666412353516 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.30\n",
      "step : 3806 | loss: 1.4749269485473633 | dt: 154.17 ms | tokens/sec: 39.85 | norm: 2.13\n",
      "step : 3807 | loss: 1.4714629650115967 | dt: 154.18 ms | tokens/sec: 39.85 | norm: 2.21\n",
      "step : 3808 | loss: 1.4082121849060059 | dt: 154.16 ms | tokens/sec: 39.85 | norm: 2.01\n",
      "step : 3809 | loss: 1.2780852317810059 | dt: 154.61 ms | tokens/sec: 39.74 | norm: 1.95\n",
      "step : 3810 | loss: 1.3031387329101562 | dt: 154.07 ms | tokens/sec: 39.88 | norm: 2.00\n",
      "step : 3811 | loss: 1.360288381576538 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.35\n",
      "step : 3812 | loss: 1.4483239650726318 | dt: 154.18 ms | tokens/sec: 39.85 | norm: 2.17\n",
      "step : 3813 | loss: 1.3576972484588623 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.15\n",
      "step : 3814 | loss: 1.3360217809677124 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 1.95\n",
      "step : 3815 | loss: 1.3674572706222534 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 1.95\n",
      "step : 3816 | loss: 1.2889046669006348 | dt: 154.86 ms | tokens/sec: 39.67 | norm: 1.99\n",
      "step : 3817 | loss: 1.369354248046875 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 2.01\n",
      "step : 3818 | loss: 1.436765432357788 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.25\n",
      "step : 3819 | loss: 1.5029914379119873 | dt: 154.03 ms | tokens/sec: 39.89 | norm: 2.35\n",
      "step : 3820 | loss: 1.3710401058197021 | dt: 154.20 ms | tokens/sec: 39.84 | norm: 2.07\n",
      "step : 3821 | loss: 1.500382423400879 | dt: 154.13 ms | tokens/sec: 39.86 | norm: 2.25\n",
      "step : 3822 | loss: 1.3979418277740479 | dt: 154.97 ms | tokens/sec: 39.65 | norm: 2.01\n",
      "step : 3823 | loss: 1.4502894878387451 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.18\n",
      "step : 3824 | loss: 1.5580700635910034 | dt: 154.13 ms | tokens/sec: 39.86 | norm: 2.12\n",
      "step : 3825 | loss: 1.5533854961395264 | dt: 153.81 ms | tokens/sec: 39.95 | norm: 2.34\n",
      "step : 3826 | loss: 1.3927218914031982 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.06\n",
      "step : 3827 | loss: 1.4188001155853271 | dt: 153.89 ms | tokens/sec: 39.93 | norm: 1.96\n",
      "step : 3828 | loss: 1.4217976331710815 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 1.93\n",
      "step : 3829 | loss: 1.3462884426116943 | dt: 154.91 ms | tokens/sec: 39.66 | norm: 2.08\n",
      "step : 3830 | loss: 1.348048210144043 | dt: 154.12 ms | tokens/sec: 39.87 | norm: 2.15\n",
      "step : 3831 | loss: 1.6380071640014648 | dt: 153.91 ms | tokens/sec: 39.92 | norm: 2.42\n",
      "step : 3832 | loss: 1.604867696762085 | dt: 154.09 ms | tokens/sec: 39.87 | norm: 2.41\n",
      "step : 3833 | loss: 1.570932388305664 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.36\n",
      "step : 3834 | loss: 1.4790904521942139 | dt: 154.31 ms | tokens/sec: 39.82 | norm: 2.23\n",
      "step : 3835 | loss: 1.4128823280334473 | dt: 154.99 ms | tokens/sec: 39.64 | norm: 2.01\n",
      "step : 3836 | loss: 1.4929088354110718 | dt: 154.43 ms | tokens/sec: 39.78 | norm: 2.38\n",
      "step : 3837 | loss: 1.4132556915283203 | dt: 153.86 ms | tokens/sec: 39.93 | norm: 2.23\n",
      "step : 3838 | loss: 1.423933982849121 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 1.90\n",
      "step : 3839 | loss: 1.3868980407714844 | dt: 153.81 ms | tokens/sec: 39.95 | norm: 1.97\n",
      "step : 3840 | loss: 1.3728415966033936 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 1.90\n",
      "step : 3841 | loss: 1.2514686584472656 | dt: 153.80 ms | tokens/sec: 39.95 | norm: 1.97\n",
      "step : 3842 | loss: 1.354260802268982 | dt: 155.06 ms | tokens/sec: 39.62 | norm: 2.14\n",
      "step : 3843 | loss: 1.3862864971160889 | dt: 154.04 ms | tokens/sec: 39.89 | norm: 1.99\n",
      "step : 3844 | loss: 1.5415157079696655 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.37\n",
      "step : 3845 | loss: 1.4252705574035645 | dt: 153.89 ms | tokens/sec: 39.92 | norm: 2.08\n",
      "step : 3846 | loss: 1.3049322366714478 | dt: 154.07 ms | tokens/sec: 39.88 | norm: 1.92\n",
      "step : 3847 | loss: 1.323641300201416 | dt: 153.94 ms | tokens/sec: 39.91 | norm: 2.01\n",
      "step : 3848 | loss: 1.1194672584533691 | dt: 154.94 ms | tokens/sec: 39.66 | norm: 1.75\n",
      "step : 3849 | loss: 1.4354031085968018 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.65\n",
      "step : 3850 | loss: 1.4526957273483276 | dt: 154.33 ms | tokens/sec: 39.81 | norm: 2.33\n",
      "step : 3851 | loss: 1.5506047010421753 | dt: 154.17 ms | tokens/sec: 39.85 | norm: 2.17\n",
      "step : 3852 | loss: 1.4944970607757568 | dt: 154.28 ms | tokens/sec: 39.82 | norm: 2.20\n",
      "step : 3853 | loss: 1.413736343383789 | dt: 154.02 ms | tokens/sec: 39.89 | norm: 2.11\n",
      "step : 3854 | loss: 1.299807071685791 | dt: 154.24 ms | tokens/sec: 39.83 | norm: 2.14\n",
      "step : 3855 | loss: 1.322224497795105 | dt: 154.66 ms | tokens/sec: 39.73 | norm: 1.94\n",
      "step : 3856 | loss: 1.2951467037200928 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.00\n",
      "step : 3857 | loss: 1.3472145795822144 | dt: 153.81 ms | tokens/sec: 39.95 | norm: 2.12\n",
      "step : 3858 | loss: 1.3723009824752808 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.25\n",
      "step : 3859 | loss: 1.4024598598480225 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.19\n",
      "step : 3860 | loss: 1.363693118095398 | dt: 154.12 ms | tokens/sec: 39.87 | norm: 2.16\n",
      "step : 3861 | loss: 1.4021120071411133 | dt: 154.76 ms | tokens/sec: 39.70 | norm: 2.80\n",
      "step : 3862 | loss: 1.405519723892212 | dt: 154.26 ms | tokens/sec: 39.83 | norm: 2.03\n",
      "step : 3863 | loss: 1.3404266834259033 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.01\n",
      "step : 3864 | loss: 1.219107747077942 | dt: 154.09 ms | tokens/sec: 39.87 | norm: 2.10\n",
      "step : 3865 | loss: 1.247658133506775 | dt: 154.04 ms | tokens/sec: 39.89 | norm: 2.04\n",
      "step : 3866 | loss: 1.3100674152374268 | dt: 154.25 ms | tokens/sec: 39.83 | norm: 2.26\n",
      "step : 3867 | loss: 1.3870395421981812 | dt: 154.19 ms | tokens/sec: 39.85 | norm: 2.12\n",
      "step : 3868 | loss: 1.2934322357177734 | dt: 154.80 ms | tokens/sec: 39.69 | norm: 2.12\n",
      "step : 3869 | loss: 1.2660397291183472 | dt: 153.94 ms | tokens/sec: 39.91 | norm: 2.09\n",
      "step : 3870 | loss: 1.312028169631958 | dt: 154.08 ms | tokens/sec: 39.87 | norm: 2.05\n",
      "step : 3871 | loss: 1.2353861331939697 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 1.91\n",
      "step : 3872 | loss: 1.3185244798660278 | dt: 153.94 ms | tokens/sec: 39.91 | norm: 2.13\n",
      "step : 3873 | loss: 1.384265661239624 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 2.31\n",
      "step : 3874 | loss: 1.4617528915405273 | dt: 154.90 ms | tokens/sec: 39.66 | norm: 2.32\n",
      "step : 3875 | loss: 1.3349469900131226 | dt: 153.89 ms | tokens/sec: 39.92 | norm: 2.04\n",
      "step : 3876 | loss: 1.444602370262146 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.22\n",
      "step : 3877 | loss: 1.3447685241699219 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.04\n",
      "step : 3878 | loss: 1.4047181606292725 | dt: 154.09 ms | tokens/sec: 39.87 | norm: 2.08\n",
      "step : 3879 | loss: 1.522231936454773 | dt: 153.86 ms | tokens/sec: 39.93 | norm: 2.25\n",
      "step : 3880 | loss: 1.507609248161316 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.51\n",
      "step : 3881 | loss: 1.3547303676605225 | dt: 154.78 ms | tokens/sec: 39.70 | norm: 2.42\n",
      "step : 3882 | loss: 1.3732551336288452 | dt: 154.48 ms | tokens/sec: 39.77 | norm: 2.19\n",
      "step : 3883 | loss: 1.363867163658142 | dt: 153.89 ms | tokens/sec: 39.93 | norm: 2.12\n",
      "step : 3884 | loss: 1.2961084842681885 | dt: 154.22 ms | tokens/sec: 39.84 | norm: 2.18\n",
      "step : 3885 | loss: 1.3066422939300537 | dt: 154.26 ms | tokens/sec: 39.83 | norm: 2.26\n",
      "step : 3886 | loss: 1.5924805402755737 | dt: 154.39 ms | tokens/sec: 39.80 | norm: 2.46\n",
      "step : 3887 | loss: 1.5519932508468628 | dt: 154.76 ms | tokens/sec: 39.70 | norm: 2.16\n",
      "step : 3888 | loss: 1.5204896926879883 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.23\n",
      "step : 3889 | loss: 1.4503087997436523 | dt: 153.86 ms | tokens/sec: 39.93 | norm: 2.08\n",
      "step : 3890 | loss: 1.383357286453247 | dt: 153.94 ms | tokens/sec: 39.91 | norm: 2.22\n",
      "step : 3891 | loss: 1.473315954208374 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.35\n",
      "step : 3892 | loss: 1.3892511129379272 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.22\n",
      "step : 3893 | loss: 1.3887556791305542 | dt: 153.82 ms | tokens/sec: 39.94 | norm: 2.23\n",
      "step : 3894 | loss: 1.367711067199707 | dt: 154.88 ms | tokens/sec: 39.67 | norm: 2.18\n",
      "step : 3895 | loss: 1.3366822004318237 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.18\n",
      "step : 3896 | loss: 1.2317246198654175 | dt: 153.93 ms | tokens/sec: 39.92 | norm: 2.24\n",
      "step : 3897 | loss: 1.3438293933868408 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.31\n",
      "step : 3898 | loss: 1.362382411956787 | dt: 154.22 ms | tokens/sec: 39.84 | norm: 2.38\n",
      "step : 3899 | loss: 1.5221405029296875 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.44\n",
      "step : 3900 | loss: 1.3953619003295898 | dt: 154.64 ms | tokens/sec: 39.73 | norm: 2.34\n",
      "step : 3901 | loss: 1.2717608213424683 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.08\n",
      "step : 3902 | loss: 1.2854769229888916 | dt: 154.09 ms | tokens/sec: 39.87 | norm: 2.20\n",
      "step : 3903 | loss: 1.0819478034973145 | dt: 153.94 ms | tokens/sec: 39.91 | norm: 1.87\n",
      "step : 3904 | loss: 1.4001083374023438 | dt: 154.19 ms | tokens/sec: 39.85 | norm: 2.44\n",
      "step : 3905 | loss: 1.411454439163208 | dt: 154.21 ms | tokens/sec: 39.84 | norm: 2.13\n",
      "step : 3906 | loss: 1.4964592456817627 | dt: 154.38 ms | tokens/sec: 39.80 | norm: 2.16\n",
      "step : 3907 | loss: 1.4492000341415405 | dt: 154.52 ms | tokens/sec: 39.76 | norm: 2.63\n",
      "step : 3908 | loss: 1.3735606670379639 | dt: 154.09 ms | tokens/sec: 39.87 | norm: 2.16\n",
      "step : 3909 | loss: 1.2921174764633179 | dt: 153.94 ms | tokens/sec: 39.91 | norm: 2.05\n",
      "step : 3910 | loss: 1.2713803052902222 | dt: 153.94 ms | tokens/sec: 39.91 | norm: 2.07\n",
      "step : 3911 | loss: 1.2596821784973145 | dt: 153.86 ms | tokens/sec: 39.93 | norm: 2.05\n",
      "step : 3912 | loss: 1.3098647594451904 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.09\n",
      "step : 3913 | loss: 1.331407070159912 | dt: 154.73 ms | tokens/sec: 39.71 | norm: 2.11\n",
      "step : 3914 | loss: 1.3485682010650635 | dt: 154.20 ms | tokens/sec: 39.84 | norm: 2.12\n",
      "step : 3915 | loss: 1.290317416191101 | dt: 153.94 ms | tokens/sec: 39.91 | norm: 1.97\n",
      "step : 3916 | loss: 1.3754892349243164 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.20\n",
      "step : 3917 | loss: 1.3321430683135986 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.02\n",
      "step : 3918 | loss: 1.2796744108200073 | dt: 154.30 ms | tokens/sec: 39.82 | norm: 1.85\n",
      "step : 3919 | loss: 1.1614272594451904 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.01\n",
      "step : 3920 | loss: 1.1891825199127197 | dt: 154.83 ms | tokens/sec: 39.68 | norm: 2.03\n",
      "step : 3921 | loss: 1.2439959049224854 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.13\n",
      "step : 3922 | loss: 1.320535659790039 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 1.94\n",
      "step : 3923 | loss: 1.2388485670089722 | dt: 154.19 ms | tokens/sec: 39.85 | norm: 2.09\n",
      "step : 3924 | loss: 1.2367808818817139 | dt: 154.16 ms | tokens/sec: 39.86 | norm: 2.11\n",
      "step : 3925 | loss: 1.2558252811431885 | dt: 154.25 ms | tokens/sec: 39.83 | norm: 2.05\n",
      "step : 3926 | loss: 1.1945343017578125 | dt: 154.97 ms | tokens/sec: 39.65 | norm: 1.97\n",
      "step : 3927 | loss: 1.2949565649032593 | dt: 154.04 ms | tokens/sec: 39.89 | norm: 2.24\n",
      "step : 3928 | loss: 1.34145188331604 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.38\n",
      "step : 3929 | loss: 1.4185380935668945 | dt: 154.28 ms | tokens/sec: 39.82 | norm: 2.53\n",
      "step : 3930 | loss: 1.293503999710083 | dt: 154.20 ms | tokens/sec: 39.85 | norm: 2.22\n",
      "step : 3931 | loss: 1.4099922180175781 | dt: 153.85 ms | tokens/sec: 39.93 | norm: 2.36\n",
      "step : 3932 | loss: 1.2932499647140503 | dt: 154.02 ms | tokens/sec: 39.89 | norm: 2.04\n",
      "step : 3933 | loss: 1.3641490936279297 | dt: 154.71 ms | tokens/sec: 39.71 | norm: 2.08\n",
      "step : 3934 | loss: 1.4642547369003296 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.08\n",
      "step : 3935 | loss: 1.4470247030258179 | dt: 153.83 ms | tokens/sec: 39.94 | norm: 2.34\n",
      "step : 3936 | loss: 1.2960925102233887 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.07\n",
      "step : 3937 | loss: 1.3182271718978882 | dt: 154.07 ms | tokens/sec: 39.88 | norm: 2.10\n",
      "step : 3938 | loss: 1.3222880363464355 | dt: 154.09 ms | tokens/sec: 39.87 | norm: 2.15\n",
      "step : 3939 | loss: 1.257790446281433 | dt: 154.68 ms | tokens/sec: 39.72 | norm: 2.12\n",
      "step : 3940 | loss: 1.2659305334091187 | dt: 154.19 ms | tokens/sec: 39.85 | norm: 2.07\n",
      "step : 3941 | loss: 1.5504449605941772 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.51\n",
      "step : 3942 | loss: 1.514406442642212 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.87\n",
      "step : 3943 | loss: 1.4701611995697021 | dt: 153.91 ms | tokens/sec: 39.92 | norm: 2.62\n",
      "step : 3944 | loss: 1.40487802028656 | dt: 154.07 ms | tokens/sec: 39.88 | norm: 2.55\n",
      "step : 3945 | loss: 1.353358507156372 | dt: 153.84 ms | tokens/sec: 39.94 | norm: 2.52\n",
      "step : 3946 | loss: 1.4133762121200562 | dt: 154.75 ms | tokens/sec: 39.70 | norm: 2.26\n",
      "step : 3947 | loss: 1.3407124280929565 | dt: 154.08 ms | tokens/sec: 39.87 | norm: 2.29\n",
      "step : 3948 | loss: 1.3517316579818726 | dt: 153.87 ms | tokens/sec: 39.93 | norm: 2.21\n",
      "step : 3949 | loss: 1.3187816143035889 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.14\n",
      "step : 3950 | loss: 1.321054220199585 | dt: 154.32 ms | tokens/sec: 39.81 | norm: 2.48\n",
      "step : 3951 | loss: 1.210012435913086 | dt: 153.80 ms | tokens/sec: 39.95 | norm: 2.35\n",
      "step : 3952 | loss: 1.3201359510421753 | dt: 154.61 ms | tokens/sec: 39.74 | norm: 2.47\n",
      "step : 3953 | loss: 1.3431580066680908 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.42\n",
      "step : 3954 | loss: 1.5121500492095947 | dt: 154.15 ms | tokens/sec: 39.86 | norm: 2.57\n",
      "step : 3955 | loss: 1.3883821964263916 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.43\n",
      "step : 3956 | loss: 1.2594960927963257 | dt: 154.20 ms | tokens/sec: 39.85 | norm: 2.16\n",
      "step : 3957 | loss: 1.2694756984710693 | dt: 154.20 ms | tokens/sec: 39.85 | norm: 2.44\n",
      "step : 3958 | loss: 1.0743255615234375 | dt: 154.14 ms | tokens/sec: 39.86 | norm: 1.97\n",
      "step : 3959 | loss: 1.3801705837249756 | dt: 154.58 ms | tokens/sec: 39.75 | norm: 2.32\n",
      "step : 3960 | loss: 1.3897705078125 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.33\n",
      "step : 3961 | loss: 1.472843050956726 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.66\n",
      "step : 3962 | loss: 1.4444947242736816 | dt: 153.86 ms | tokens/sec: 39.93 | norm: 2.40\n",
      "step : 3963 | loss: 1.342668056488037 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.21\n",
      "step : 3964 | loss: 1.2703611850738525 | dt: 154.22 ms | tokens/sec: 39.84 | norm: 2.17\n",
      "step : 3965 | loss: 1.247202754020691 | dt: 154.67 ms | tokens/sec: 39.72 | norm: 2.13\n",
      "step : 3966 | loss: 1.2201321125030518 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.09\n",
      "step : 3967 | loss: 1.275383472442627 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.21\n",
      "step : 3968 | loss: 1.3090543746948242 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 2.19\n",
      "step : 3969 | loss: 1.3105300664901733 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 2.26\n",
      "step : 3970 | loss: 1.2651135921478271 | dt: 154.31 ms | tokens/sec: 39.82 | norm: 2.05\n",
      "step : 3971 | loss: 1.3550199270248413 | dt: 155.30 ms | tokens/sec: 39.56 | norm: 2.23\n",
      "step : 3972 | loss: 1.3274458646774292 | dt: 154.19 ms | tokens/sec: 39.85 | norm: 2.07\n",
      "step : 3973 | loss: 1.2620599269866943 | dt: 153.85 ms | tokens/sec: 39.94 | norm: 2.07\n",
      "step : 3974 | loss: 1.1434438228607178 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.15\n",
      "step : 3975 | loss: 1.1633877754211426 | dt: 154.31 ms | tokens/sec: 39.82 | norm: 2.09\n",
      "step : 3976 | loss: 1.211273193359375 | dt: 154.16 ms | tokens/sec: 39.85 | norm: 2.33\n",
      "step : 3977 | loss: 1.2972605228424072 | dt: 153.84 ms | tokens/sec: 39.94 | norm: 2.22\n",
      "step : 3978 | loss: 1.2110017538070679 | dt: 154.76 ms | tokens/sec: 39.70 | norm: 2.13\n",
      "step : 3979 | loss: 1.1912091970443726 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 2.44\n",
      "step : 3980 | loss: 1.222710132598877 | dt: 155.14 ms | tokens/sec: 39.60 | norm: 2.07\n",
      "step : 3981 | loss: 1.150169849395752 | dt: 153.93 ms | tokens/sec: 39.91 | norm: 2.07\n",
      "step : 3982 | loss: 1.2508299350738525 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.31\n",
      "step : 3983 | loss: 1.3130046129226685 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.23\n",
      "step : 3984 | loss: 1.3763186931610107 | dt: 154.70 ms | tokens/sec: 39.72 | norm: 2.35\n",
      "step : 3985 | loss: 1.263702630996704 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.16\n",
      "step : 3986 | loss: 1.3710178136825562 | dt: 154.32 ms | tokens/sec: 39.81 | norm: 2.21\n",
      "step : 3987 | loss: 1.28074312210083 | dt: 154.14 ms | tokens/sec: 39.86 | norm: 2.20\n",
      "step : 3988 | loss: 1.3287456035614014 | dt: 154.03 ms | tokens/sec: 39.89 | norm: 2.36\n",
      "step : 3989 | loss: 1.4287693500518799 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.21\n",
      "step : 3990 | loss: 1.4079046249389648 | dt: 154.13 ms | tokens/sec: 39.86 | norm: 2.28\n",
      "step : 3991 | loss: 1.2536633014678955 | dt: 154.69 ms | tokens/sec: 39.72 | norm: 2.07\n",
      "step : 3992 | loss: 1.2774949073791504 | dt: 154.09 ms | tokens/sec: 39.87 | norm: 2.04\n",
      "step : 3993 | loss: 1.2759898900985718 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.01\n",
      "step : 3994 | loss: 1.206931710243225 | dt: 154.15 ms | tokens/sec: 39.86 | norm: 1.99\n",
      "step : 3995 | loss: 1.218152642250061 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.10\n",
      "step : 3996 | loss: 1.4831489324569702 | dt: 154.30 ms | tokens/sec: 39.82 | norm: 2.36\n",
      "step : 3997 | loss: 1.470139503479004 | dt: 155.03 ms | tokens/sec: 39.63 | norm: 2.35\n",
      "step : 3998 | loss: 1.4296717643737793 | dt: 154.13 ms | tokens/sec: 39.86 | norm: 2.56\n",
      "step : 3999 | loss: 1.3605483770370483 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.30\n",
      "step : 4000 | loss: 1.298509120941162 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.19\n",
      "step : 4001 | loss: 1.3565280437469482 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.01\n",
      "step : 4002 | loss: 1.290658950805664 | dt: 154.23 ms | tokens/sec: 39.84 | norm: 2.28\n",
      "step : 4003 | loss: 1.3045048713684082 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.03\n",
      "step : 4004 | loss: 1.2607316970825195 | dt: 154.88 ms | tokens/sec: 39.67 | norm: 2.09\n",
      "step : 4005 | loss: 1.2699673175811768 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.17\n",
      "step : 4006 | loss: 1.1556031703948975 | dt: 154.02 ms | tokens/sec: 39.89 | norm: 2.16\n",
      "step : 4007 | loss: 1.2580785751342773 | dt: 154.20 ms | tokens/sec: 39.85 | norm: 2.34\n",
      "step : 4008 | loss: 1.2943583726882935 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.39\n",
      "step : 4009 | loss: 1.4506564140319824 | dt: 154.09 ms | tokens/sec: 39.87 | norm: 2.57\n",
      "step : 4010 | loss: 1.3242530822753906 | dt: 154.91 ms | tokens/sec: 39.66 | norm: 2.53\n",
      "step : 4011 | loss: 1.192330241203308 | dt: 154.04 ms | tokens/sec: 39.89 | norm: 2.04\n",
      "step : 4012 | loss: 1.2232413291931152 | dt: 153.93 ms | tokens/sec: 39.91 | norm: 2.14\n",
      "step : 4013 | loss: 1.0276180505752563 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.11\n",
      "step : 4014 | loss: 1.3313508033752441 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.54\n",
      "step : 4015 | loss: 1.337890625 | dt: 153.86 ms | tokens/sec: 39.93 | norm: 2.35\n",
      "step : 4016 | loss: 1.4310367107391357 | dt: 154.02 ms | tokens/sec: 39.89 | norm: 2.49\n",
      "step : 4017 | loss: 1.403656005859375 | dt: 154.95 ms | tokens/sec: 39.65 | norm: 2.65\n",
      "step : 4018 | loss: 1.3146624565124512 | dt: 154.32 ms | tokens/sec: 39.81 | norm: 2.22\n",
      "step : 4019 | loss: 1.2403477430343628 | dt: 153.84 ms | tokens/sec: 39.94 | norm: 2.51\n",
      "step : 4020 | loss: 1.235315203666687 | dt: 154.30 ms | tokens/sec: 39.82 | norm: 2.08\n",
      "step : 4021 | loss: 1.1989152431488037 | dt: 154.26 ms | tokens/sec: 39.83 | norm: 2.18\n",
      "step : 4022 | loss: 1.2517536878585815 | dt: 154.51 ms | tokens/sec: 39.76 | norm: 2.20\n",
      "step : 4023 | loss: 1.270906686782837 | dt: 154.65 ms | tokens/sec: 39.73 | norm: 2.09\n",
      "step : 4024 | loss: 1.2811964750289917 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.21\n",
      "step : 4025 | loss: 1.2084555625915527 | dt: 153.84 ms | tokens/sec: 39.94 | norm: 2.08\n",
      "step : 4026 | loss: 1.2977417707443237 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.12\n",
      "step : 4027 | loss: 1.271140217781067 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.08\n",
      "step : 4028 | loss: 1.2033538818359375 | dt: 154.15 ms | tokens/sec: 39.86 | norm: 2.21\n",
      "step : 4029 | loss: 1.0936139822006226 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.00\n",
      "step : 4030 | loss: 1.1098788976669312 | dt: 155.03 ms | tokens/sec: 39.63 | norm: 2.19\n",
      "step : 4031 | loss: 1.1608567237854004 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.42\n",
      "step : 4032 | loss: 1.2478055953979492 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.45\n",
      "step : 4033 | loss: 1.182528018951416 | dt: 153.83 ms | tokens/sec: 39.94 | norm: 2.27\n",
      "step : 4034 | loss: 1.1807410717010498 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.18\n",
      "step : 4035 | loss: 1.1983603239059448 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 2.39\n",
      "step : 4036 | loss: 1.1339014768600464 | dt: 154.69 ms | tokens/sec: 39.72 | norm: 2.30\n",
      "step : 4037 | loss: 1.233015775680542 | dt: 154.20 ms | tokens/sec: 39.84 | norm: 2.12\n",
      "step : 4038 | loss: 1.285359501838684 | dt: 154.30 ms | tokens/sec: 39.82 | norm: 2.33\n",
      "step : 4039 | loss: 1.3449721336364746 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.22\n",
      "step : 4040 | loss: 1.2474614381790161 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.25\n",
      "step : 4041 | loss: 1.3331341743469238 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.13\n",
      "step : 4042 | loss: 1.2401692867279053 | dt: 154.12 ms | tokens/sec: 39.86 | norm: 2.27\n",
      "step : 4043 | loss: 1.298722743988037 | dt: 154.81 ms | tokens/sec: 39.69 | norm: 2.32\n",
      "step : 4044 | loss: 1.362598180770874 | dt: 154.24 ms | tokens/sec: 39.83 | norm: 2.32\n",
      "step : 4045 | loss: 1.3405091762542725 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.20\n",
      "step : 4046 | loss: 1.1860328912734985 | dt: 154.08 ms | tokens/sec: 39.88 | norm: 2.09\n",
      "step : 4047 | loss: 1.2237505912780762 | dt: 153.85 ms | tokens/sec: 39.93 | norm: 2.01\n",
      "step : 4048 | loss: 1.233054518699646 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.16\n",
      "step : 4049 | loss: 1.1519560813903809 | dt: 154.82 ms | tokens/sec: 39.68 | norm: 1.86\n",
      "step : 4050 | loss: 1.1715037822723389 | dt: 154.07 ms | tokens/sec: 39.88 | norm: 1.97\n",
      "step : 4051 | loss: 1.4445874691009521 | dt: 153.91 ms | tokens/sec: 39.92 | norm: 2.58\n",
      "step : 4052 | loss: 1.4286887645721436 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.36\n",
      "step : 4053 | loss: 1.3770735263824463 | dt: 154.13 ms | tokens/sec: 39.86 | norm: 2.37\n",
      "step : 4054 | loss: 1.314582347869873 | dt: 154.16 ms | tokens/sec: 39.86 | norm: 2.69\n",
      "step : 4055 | loss: 1.2667640447616577 | dt: 153.93 ms | tokens/sec: 39.91 | norm: 2.04\n",
      "step : 4056 | loss: 1.311824917793274 | dt: 154.83 ms | tokens/sec: 39.68 | norm: 2.18\n",
      "step : 4057 | loss: 1.2665684223175049 | dt: 153.87 ms | tokens/sec: 39.93 | norm: 2.87\n",
      "step : 4058 | loss: 1.259264349937439 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.39\n",
      "step : 4059 | loss: 1.210019826889038 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 1.96\n",
      "step : 4060 | loss: 1.2210053205490112 | dt: 154.04 ms | tokens/sec: 39.89 | norm: 2.14\n",
      "step : 4061 | loss: 1.1100796461105347 | dt: 153.87 ms | tokens/sec: 39.93 | norm: 2.17\n",
      "step : 4062 | loss: 1.2271944284439087 | dt: 154.92 ms | tokens/sec: 39.66 | norm: 2.20\n",
      "step : 4063 | loss: 1.2466896772384644 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.30\n",
      "step : 4064 | loss: 1.396527647972107 | dt: 153.94 ms | tokens/sec: 39.91 | norm: 2.42\n",
      "step : 4065 | loss: 1.2751352787017822 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.31\n",
      "step : 4066 | loss: 1.1440985202789307 | dt: 154.46 ms | tokens/sec: 39.78 | norm: 2.13\n",
      "step : 4067 | loss: 1.184324026107788 | dt: 154.18 ms | tokens/sec: 39.85 | norm: 2.23\n",
      "step : 4068 | loss: 0.9895720481872559 | dt: 154.37 ms | tokens/sec: 39.80 | norm: 1.91\n",
      "step : 4069 | loss: 1.2949737310409546 | dt: 154.68 ms | tokens/sec: 39.72 | norm: 2.43\n",
      "step : 4070 | loss: 1.2938331365585327 | dt: 153.93 ms | tokens/sec: 39.92 | norm: 2.35\n",
      "step : 4071 | loss: 1.4023232460021973 | dt: 153.84 ms | tokens/sec: 39.94 | norm: 2.57\n",
      "step : 4072 | loss: 1.3720898628234863 | dt: 154.20 ms | tokens/sec: 39.84 | norm: 2.64\n",
      "step : 4073 | loss: 1.270582675933838 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.29\n",
      "step : 4074 | loss: 1.1861412525177002 | dt: 154.09 ms | tokens/sec: 39.87 | norm: 2.28\n",
      "step : 4075 | loss: 1.1756527423858643 | dt: 154.58 ms | tokens/sec: 39.75 | norm: 2.12\n",
      "step : 4076 | loss: 1.1539136171340942 | dt: 154.12 ms | tokens/sec: 39.87 | norm: 2.15\n",
      "step : 4077 | loss: 1.2022051811218262 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.69\n",
      "step : 4078 | loss: 1.2072757482528687 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.01\n",
      "step : 4079 | loss: 1.228227138519287 | dt: 154.20 ms | tokens/sec: 39.85 | norm: 2.15\n",
      "step : 4080 | loss: 1.1687953472137451 | dt: 154.57 ms | tokens/sec: 39.75 | norm: 2.09\n",
      "step : 4081 | loss: 1.2511334419250488 | dt: 154.21 ms | tokens/sec: 39.84 | norm: 2.23\n",
      "step : 4082 | loss: 1.2225500345230103 | dt: 154.67 ms | tokens/sec: 39.72 | norm: 2.23\n",
      "step : 4083 | loss: 1.1516672372817993 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.04\n",
      "step : 4084 | loss: 1.0464756488800049 | dt: 154.14 ms | tokens/sec: 39.86 | norm: 2.04\n",
      "step : 4085 | loss: 1.0713145732879639 | dt: 153.86 ms | tokens/sec: 39.93 | norm: 2.04\n",
      "step : 4086 | loss: 1.137345314025879 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.26\n",
      "step : 4087 | loss: 1.1997509002685547 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.20\n",
      "step : 4088 | loss: 1.1179715394973755 | dt: 154.83 ms | tokens/sec: 39.68 | norm: 2.20\n",
      "step : 4089 | loss: 1.1129558086395264 | dt: 154.16 ms | tokens/sec: 39.86 | norm: 2.24\n",
      "step : 4090 | loss: 1.1523088216781616 | dt: 154.29 ms | tokens/sec: 39.82 | norm: 2.46\n",
      "step : 4091 | loss: 1.0894114971160889 | dt: 154.15 ms | tokens/sec: 39.86 | norm: 2.38\n",
      "step : 4092 | loss: 1.164299726486206 | dt: 154.37 ms | tokens/sec: 39.80 | norm: 2.33\n",
      "step : 4093 | loss: 1.21490478515625 | dt: 154.14 ms | tokens/sec: 39.86 | norm: 2.27\n",
      "step : 4094 | loss: 1.284801959991455 | dt: 154.25 ms | tokens/sec: 39.83 | norm: 2.42\n",
      "step : 4095 | loss: 1.1913158893585205 | dt: 154.57 ms | tokens/sec: 39.75 | norm: 2.16\n",
      "step : 4096 | loss: 1.2951223850250244 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 2.46\n",
      "step : 4097 | loss: 1.2166006565093994 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.26\n",
      "step : 4098 | loss: 1.2762596607208252 | dt: 153.89 ms | tokens/sec: 39.93 | norm: 2.68\n",
      "step : 4099 | loss: 1.3520034551620483 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.36\n",
      "step : 4100 | loss: 1.3221049308776855 | dt: 154.03 ms | tokens/sec: 39.89 | norm: 2.43\n",
      "step : 4101 | loss: 1.1636313199996948 | dt: 154.78 ms | tokens/sec: 39.70 | norm: 2.34\n",
      "step : 4102 | loss: 1.199331283569336 | dt: 154.18 ms | tokens/sec: 39.85 | norm: 2.23\n",
      "step : 4103 | loss: 1.2085140943527222 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.21\n",
      "step : 4104 | loss: 1.1328682899475098 | dt: 154.38 ms | tokens/sec: 39.80 | norm: 2.18\n",
      "step : 4105 | loss: 1.1305149793624878 | dt: 154.24 ms | tokens/sec: 39.83 | norm: 2.12\n",
      "step : 4106 | loss: 1.3841850757598877 | dt: 154.21 ms | tokens/sec: 39.84 | norm: 2.39\n",
      "step : 4107 | loss: 1.3629392385482788 | dt: 154.13 ms | tokens/sec: 39.86 | norm: 2.27\n",
      "step : 4108 | loss: 1.318558931350708 | dt: 154.82 ms | tokens/sec: 39.68 | norm: 2.20\n",
      "step : 4109 | loss: 1.2638444900512695 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.08\n",
      "step : 4110 | loss: 1.2108720541000366 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.10\n",
      "step : 4111 | loss: 1.2518703937530518 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.05\n",
      "step : 4112 | loss: 1.2142404317855835 | dt: 153.89 ms | tokens/sec: 39.92 | norm: 2.14\n",
      "step : 4113 | loss: 1.2102116346359253 | dt: 153.80 ms | tokens/sec: 39.95 | norm: 1.96\n",
      "step : 4114 | loss: 1.158557415008545 | dt: 154.77 ms | tokens/sec: 39.70 | norm: 2.06\n",
      "step : 4115 | loss: 1.16339111328125 | dt: 154.36 ms | tokens/sec: 39.80 | norm: 2.15\n",
      "step : 4116 | loss: 1.0602668523788452 | dt: 154.32 ms | tokens/sec: 39.81 | norm: 2.06\n",
      "step : 4117 | loss: 1.1755642890930176 | dt: 153.84 ms | tokens/sec: 39.94 | norm: 2.29\n",
      "step : 4118 | loss: 1.1901007890701294 | dt: 154.04 ms | tokens/sec: 39.89 | norm: 2.23\n",
      "step : 4119 | loss: 1.3342323303222656 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.26\n",
      "step : 4120 | loss: 1.233722448348999 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.31\n",
      "step : 4121 | loss: 1.0968283414840698 | dt: 154.65 ms | tokens/sec: 39.73 | norm: 2.02\n",
      "step : 4122 | loss: 1.1372612714767456 | dt: 154.07 ms | tokens/sec: 39.88 | norm: 2.12\n",
      "step : 4123 | loss: 0.9522767066955566 | dt: 153.94 ms | tokens/sec: 39.91 | norm: 1.98\n",
      "step : 4124 | loss: 1.236032485961914 | dt: 154.15 ms | tokens/sec: 39.86 | norm: 2.34\n",
      "step : 4125 | loss: 1.2425613403320312 | dt: 154.24 ms | tokens/sec: 39.83 | norm: 2.14\n",
      "step : 4126 | loss: 1.3496026992797852 | dt: 154.32 ms | tokens/sec: 39.81 | norm: 2.57\n",
      "step : 4127 | loss: 1.3283295631408691 | dt: 154.78 ms | tokens/sec: 39.69 | norm: 2.69\n",
      "step : 4128 | loss: 1.2207204103469849 | dt: 154.28 ms | tokens/sec: 39.82 | norm: 2.44\n",
      "step : 4129 | loss: 1.1519056558609009 | dt: 153.94 ms | tokens/sec: 39.91 | norm: 2.37\n",
      "step : 4130 | loss: 1.1467961072921753 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.35\n",
      "step : 4131 | loss: 1.1205917596817017 | dt: 153.86 ms | tokens/sec: 39.93 | norm: 2.28\n",
      "step : 4132 | loss: 1.1820749044418335 | dt: 154.04 ms | tokens/sec: 39.89 | norm: 2.10\n",
      "step : 4133 | loss: 1.1721872091293335 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.23\n",
      "step : 4134 | loss: 1.1941909790039062 | dt: 154.66 ms | tokens/sec: 39.73 | norm: 2.18\n",
      "step : 4135 | loss: 1.1390199661254883 | dt: 153.91 ms | tokens/sec: 39.92 | norm: 2.13\n",
      "step : 4136 | loss: 1.2230448722839355 | dt: 154.03 ms | tokens/sec: 39.89 | norm: 2.27\n",
      "step : 4137 | loss: 1.1861600875854492 | dt: 154.16 ms | tokens/sec: 39.85 | norm: 2.16\n",
      "step : 4138 | loss: 1.1075327396392822 | dt: 154.41 ms | tokens/sec: 39.79 | norm: 1.99\n",
      "step : 4139 | loss: 0.9948408007621765 | dt: 154.52 ms | tokens/sec: 39.76 | norm: 1.93\n",
      "step : 4140 | loss: 1.0203534364700317 | dt: 154.90 ms | tokens/sec: 39.66 | norm: 2.39\n",
      "step : 4141 | loss: 1.0810256004333496 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.23\n",
      "step : 4142 | loss: 1.134070634841919 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 2.18\n",
      "step : 4143 | loss: 1.0787935256958008 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.21\n",
      "step : 4144 | loss: 1.0784850120544434 | dt: 154.08 ms | tokens/sec: 39.87 | norm: 2.30\n",
      "step : 4145 | loss: 1.1244943141937256 | dt: 153.83 ms | tokens/sec: 39.94 | norm: 2.47\n",
      "step : 4146 | loss: 1.0655573606491089 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.40\n",
      "step : 4147 | loss: 1.1417583227157593 | dt: 154.51 ms | tokens/sec: 39.77 | norm: 2.24\n",
      "step : 4148 | loss: 1.1873797178268433 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.62\n",
      "step : 4149 | loss: 1.2395508289337158 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.42\n",
      "step : 4150 | loss: 1.162571907043457 | dt: 154.04 ms | tokens/sec: 39.89 | norm: 2.42\n",
      "step : 4151 | loss: 1.2591993808746338 | dt: 154.08 ms | tokens/sec: 39.88 | norm: 2.62\n",
      "step : 4152 | loss: 1.181887149810791 | dt: 154.19 ms | tokens/sec: 39.85 | norm: 2.33\n",
      "step : 4153 | loss: 1.2466931343078613 | dt: 155.05 ms | tokens/sec: 39.63 | norm: 2.62\n",
      "step : 4154 | loss: 1.32083261013031 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.33\n",
      "step : 4155 | loss: 1.274718999862671 | dt: 153.85 ms | tokens/sec: 39.93 | norm: 2.40\n",
      "step : 4156 | loss: 1.128097414970398 | dt: 154.14 ms | tokens/sec: 39.86 | norm: 2.28\n",
      "step : 4157 | loss: 1.1523427963256836 | dt: 154.18 ms | tokens/sec: 39.85 | norm: 2.44\n",
      "step : 4158 | loss: 1.180737853050232 | dt: 154.33 ms | tokens/sec: 39.81 | norm: 2.19\n",
      "step : 4159 | loss: 1.1062512397766113 | dt: 154.55 ms | tokens/sec: 39.75 | norm: 2.33\n",
      "step : 4160 | loss: 1.1090013980865479 | dt: 154.30 ms | tokens/sec: 39.82 | norm: 2.29\n",
      "step : 4161 | loss: 1.3706138134002686 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.78\n",
      "step : 4162 | loss: 1.3318638801574707 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.43\n",
      "step : 4163 | loss: 1.297513484954834 | dt: 154.02 ms | tokens/sec: 39.89 | norm: 2.82\n",
      "step : 4164 | loss: 1.2249420881271362 | dt: 154.29 ms | tokens/sec: 39.82 | norm: 2.12\n",
      "step : 4165 | loss: 1.1710643768310547 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.39\n",
      "step : 4166 | loss: 1.2098371982574463 | dt: 154.74 ms | tokens/sec: 39.71 | norm: 2.15\n",
      "step : 4167 | loss: 1.1675552129745483 | dt: 153.93 ms | tokens/sec: 39.91 | norm: 2.61\n",
      "step : 4168 | loss: 1.1655700206756592 | dt: 153.89 ms | tokens/sec: 39.93 | norm: 2.05\n",
      "step : 4169 | loss: 1.1273436546325684 | dt: 153.82 ms | tokens/sec: 39.94 | norm: 2.07\n",
      "step : 4170 | loss: 1.13133704662323 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.02\n",
      "step : 4171 | loss: 1.0189573764801025 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.22\n",
      "step : 4172 | loss: 1.125882625579834 | dt: 154.84 ms | tokens/sec: 39.68 | norm: 2.19\n",
      "step : 4173 | loss: 1.1470261812210083 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.20\n",
      "step : 4174 | loss: 1.2855827808380127 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.44\n",
      "step : 4175 | loss: 1.1813843250274658 | dt: 154.12 ms | tokens/sec: 39.87 | norm: 2.36\n",
      "step : 4176 | loss: 1.045560598373413 | dt: 154.09 ms | tokens/sec: 39.87 | norm: 2.00\n",
      "step : 4177 | loss: 1.079476237297058 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.07\n",
      "step : 4178 | loss: 0.8993291854858398 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 1.87\n",
      "step : 4179 | loss: 1.1847162246704102 | dt: 154.51 ms | tokens/sec: 39.76 | norm: 2.35\n",
      "step : 4180 | loss: 1.2014539241790771 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 2.56\n",
      "step : 4181 | loss: 1.3083202838897705 | dt: 153.93 ms | tokens/sec: 39.92 | norm: 2.36\n",
      "step : 4182 | loss: 1.2909635305404663 | dt: 154.25 ms | tokens/sec: 39.83 | norm: 2.63\n",
      "step : 4183 | loss: 1.2017263174057007 | dt: 154.09 ms | tokens/sec: 39.87 | norm: 2.70\n",
      "step : 4184 | loss: 1.1094168424606323 | dt: 154.23 ms | tokens/sec: 39.84 | norm: 2.22\n",
      "step : 4185 | loss: 1.1186240911483765 | dt: 154.62 ms | tokens/sec: 39.74 | norm: 2.16\n",
      "step : 4186 | loss: 1.0845377445220947 | dt: 154.33 ms | tokens/sec: 39.81 | norm: 2.19\n",
      "step : 4187 | loss: 1.1452386379241943 | dt: 153.93 ms | tokens/sec: 39.91 | norm: 2.25\n",
      "step : 4188 | loss: 1.1410017013549805 | dt: 154.08 ms | tokens/sec: 39.88 | norm: 2.29\n",
      "step : 4189 | loss: 1.1625632047653198 | dt: 154.21 ms | tokens/sec: 39.84 | norm: 2.15\n",
      "step : 4190 | loss: 1.095920205116272 | dt: 154.23 ms | tokens/sec: 39.84 | norm: 2.20\n",
      "step : 4191 | loss: 1.1889173984527588 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.39\n",
      "step : 4192 | loss: 1.1486167907714844 | dt: 155.10 ms | tokens/sec: 39.61 | norm: 2.40\n",
      "step : 4193 | loss: 1.0783953666687012 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 1.96\n",
      "step : 4194 | loss: 0.9543935656547546 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 1.98\n",
      "step : 4195 | loss: 0.9908692240715027 | dt: 154.28 ms | tokens/sec: 39.82 | norm: 2.06\n",
      "step : 4196 | loss: 1.0414930582046509 | dt: 154.43 ms | tokens/sec: 39.78 | norm: 2.29\n",
      "step : 4197 | loss: 1.093113660812378 | dt: 154.08 ms | tokens/sec: 39.87 | norm: 2.11\n",
      "step : 4198 | loss: 1.032604455947876 | dt: 155.21 ms | tokens/sec: 39.58 | norm: 2.12\n",
      "step : 4199 | loss: 1.025842547416687 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.10\n",
      "step : 4200 | loss: 1.074202299118042 | dt: 153.87 ms | tokens/sec: 39.93 | norm: 2.03\n",
      "step : 4201 | loss: 1.0266695022583008 | dt: 153.84 ms | tokens/sec: 39.94 | norm: 2.06\n",
      "step : 4202 | loss: 1.08955979347229 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 2.20\n",
      "step : 4203 | loss: 1.1449604034423828 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.57\n",
      "step : 4204 | loss: 1.2035472393035889 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.39\n",
      "step : 4205 | loss: 1.1202139854431152 | dt: 154.77 ms | tokens/sec: 39.70 | norm: 2.53\n",
      "step : 4206 | loss: 1.2254199981689453 | dt: 154.34 ms | tokens/sec: 39.81 | norm: 2.53\n",
      "step : 4207 | loss: 1.1558759212493896 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.36\n",
      "step : 4208 | loss: 1.2252107858657837 | dt: 154.40 ms | tokens/sec: 39.79 | norm: 2.86\n",
      "step : 4209 | loss: 1.2850580215454102 | dt: 154.12 ms | tokens/sec: 39.87 | norm: 2.55\n",
      "step : 4210 | loss: 1.2558164596557617 | dt: 154.23 ms | tokens/sec: 39.84 | norm: 2.84\n",
      "step : 4211 | loss: 1.0971732139587402 | dt: 154.73 ms | tokens/sec: 39.71 | norm: 2.38\n",
      "step : 4212 | loss: 1.138113260269165 | dt: 154.08 ms | tokens/sec: 39.87 | norm: 2.32\n",
      "step : 4213 | loss: 1.148645281791687 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.32\n",
      "step : 4214 | loss: 1.0750116109848022 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.20\n",
      "step : 4215 | loss: 1.0767221450805664 | dt: 154.04 ms | tokens/sec: 39.89 | norm: 2.25\n",
      "step : 4216 | loss: 1.3372429609298706 | dt: 154.23 ms | tokens/sec: 39.84 | norm: 2.97\n",
      "step : 4217 | loss: 1.3128330707550049 | dt: 153.81 ms | tokens/sec: 39.94 | norm: 2.70\n",
      "step : 4218 | loss: 1.2686814069747925 | dt: 154.72 ms | tokens/sec: 39.71 | norm: 2.56\n",
      "step : 4219 | loss: 1.1979787349700928 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.47\n",
      "step : 4220 | loss: 1.1585510969161987 | dt: 154.07 ms | tokens/sec: 39.88 | norm: 2.23\n",
      "step : 4221 | loss: 1.1880903244018555 | dt: 154.27 ms | tokens/sec: 39.83 | norm: 2.41\n",
      "step : 4222 | loss: 1.1648497581481934 | dt: 154.26 ms | tokens/sec: 39.83 | norm: 2.50\n",
      "step : 4223 | loss: 1.144171953201294 | dt: 154.14 ms | tokens/sec: 39.86 | norm: 2.15\n",
      "step : 4224 | loss: 1.0891122817993164 | dt: 154.62 ms | tokens/sec: 39.74 | norm: 2.03\n",
      "step : 4225 | loss: 1.0952425003051758 | dt: 153.94 ms | tokens/sec: 39.91 | norm: 2.35\n",
      "step : 4226 | loss: 0.9814264178276062 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.23\n",
      "step : 4227 | loss: 1.0954384803771973 | dt: 154.02 ms | tokens/sec: 39.89 | norm: 2.16\n",
      "step : 4228 | loss: 1.1027849912643433 | dt: 154.18 ms | tokens/sec: 39.85 | norm: 2.19\n",
      "step : 4229 | loss: 1.2536453008651733 | dt: 153.89 ms | tokens/sec: 39.92 | norm: 2.39\n",
      "step : 4230 | loss: 1.134278416633606 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 2.25\n",
      "step : 4231 | loss: 1.0129058361053467 | dt: 155.01 ms | tokens/sec: 39.64 | norm: 2.02\n",
      "step : 4232 | loss: 1.039229393005371 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.20\n",
      "step : 4233 | loss: 0.8642641305923462 | dt: 153.85 ms | tokens/sec: 39.93 | norm: 1.87\n",
      "step : 4234 | loss: 1.153550148010254 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 2.40\n",
      "step : 4235 | loss: 1.1766178607940674 | dt: 154.02 ms | tokens/sec: 39.89 | norm: 2.35\n",
      "step : 4236 | loss: 1.2529617547988892 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.35\n",
      "step : 4237 | loss: 1.2402937412261963 | dt: 154.91 ms | tokens/sec: 39.66 | norm: 2.65\n",
      "step : 4238 | loss: 1.151731014251709 | dt: 154.13 ms | tokens/sec: 39.86 | norm: 2.25\n",
      "step : 4239 | loss: 1.0705314874649048 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.12\n",
      "step : 4240 | loss: 1.0793646574020386 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.12\n",
      "step : 4241 | loss: 1.0409460067749023 | dt: 154.12 ms | tokens/sec: 39.86 | norm: 1.98\n",
      "step : 4242 | loss: 1.1044858694076538 | dt: 154.38 ms | tokens/sec: 39.80 | norm: 2.15\n",
      "step : 4243 | loss: 1.1031959056854248 | dt: 154.08 ms | tokens/sec: 39.88 | norm: 2.32\n",
      "step : 4244 | loss: 1.1127227544784546 | dt: 154.69 ms | tokens/sec: 39.72 | norm: 2.05\n",
      "step : 4245 | loss: 1.064690351486206 | dt: 153.87 ms | tokens/sec: 39.93 | norm: 2.07\n",
      "step : 4246 | loss: 1.1526269912719727 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.10\n",
      "step : 4247 | loss: 1.121489405632019 | dt: 153.85 ms | tokens/sec: 39.93 | norm: 2.29\n",
      "step : 4248 | loss: 1.0300941467285156 | dt: 154.02 ms | tokens/sec: 39.89 | norm: 2.14\n",
      "step : 4249 | loss: 0.9247711896896362 | dt: 154.15 ms | tokens/sec: 39.86 | norm: 2.08\n",
      "step : 4250 | loss: 0.9544767141342163 | dt: 154.89 ms | tokens/sec: 39.67 | norm: 1.96\n",
      "step : 4251 | loss: 1.0171473026275635 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.32\n",
      "step : 4252 | loss: 1.0616137981414795 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.46\n",
      "step : 4253 | loss: 0.9941115379333496 | dt: 153.82 ms | tokens/sec: 39.94 | norm: 2.11\n",
      "step : 4254 | loss: 0.9977070689201355 | dt: 154.57 ms | tokens/sec: 39.75 | norm: 2.08\n",
      "step : 4255 | loss: 1.0380051136016846 | dt: 154.18 ms | tokens/sec: 39.85 | norm: 2.11\n",
      "step : 4256 | loss: 0.9741595983505249 | dt: 154.26 ms | tokens/sec: 39.83 | norm: 2.17\n",
      "step : 4257 | loss: 1.0505478382110596 | dt: 154.90 ms | tokens/sec: 39.66 | norm: 2.11\n",
      "step : 4258 | loss: 1.107623815536499 | dt: 154.28 ms | tokens/sec: 39.82 | norm: 2.32\n",
      "step : 4259 | loss: 1.1467375755310059 | dt: 153.80 ms | tokens/sec: 39.95 | norm: 2.14\n",
      "step : 4260 | loss: 1.083674669265747 | dt: 153.93 ms | tokens/sec: 39.92 | norm: 2.87\n",
      "step : 4261 | loss: 1.165416955947876 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.41\n",
      "step : 4262 | loss: 1.109249234199524 | dt: 154.23 ms | tokens/sec: 39.84 | norm: 2.27\n",
      "step : 4263 | loss: 1.1836986541748047 | dt: 154.85 ms | tokens/sec: 39.68 | norm: 2.41\n",
      "step : 4264 | loss: 1.2405493259429932 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.35\n",
      "step : 4265 | loss: 1.2163900136947632 | dt: 153.91 ms | tokens/sec: 39.92 | norm: 2.56\n",
      "step : 4266 | loss: 1.0738533735275269 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.42\n",
      "step : 4267 | loss: 1.1086010932922363 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.49\n",
      "step : 4268 | loss: 1.1273125410079956 | dt: 154.17 ms | tokens/sec: 39.85 | norm: 2.53\n",
      "step : 4269 | loss: 1.0477080345153809 | dt: 154.18 ms | tokens/sec: 39.85 | norm: 2.95\n",
      "step : 4270 | loss: 1.0492669343948364 | dt: 154.80 ms | tokens/sec: 39.69 | norm: 2.42\n",
      "step : 4271 | loss: 1.3205870389938354 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.88\n",
      "step : 4272 | loss: 1.290440559387207 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.59\n",
      "step : 4273 | loss: 1.2293946743011475 | dt: 153.89 ms | tokens/sec: 39.92 | norm: 2.66\n",
      "step : 4274 | loss: 1.1682325601577759 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.53\n",
      "step : 4275 | loss: 1.1235780715942383 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.30\n",
      "step : 4276 | loss: 1.153760313987732 | dt: 154.83 ms | tokens/sec: 39.68 | norm: 2.30\n",
      "step : 4277 | loss: 1.1340340375900269 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.45\n",
      "step : 4278 | loss: 1.1178615093231201 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.48\n",
      "step : 4279 | loss: 1.066477656364441 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.27\n",
      "step : 4280 | loss: 1.074695110321045 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.38\n",
      "step : 4281 | loss: 0.9710159301757812 | dt: 153.81 ms | tokens/sec: 39.94 | norm: 2.17\n",
      "step : 4282 | loss: 1.072357177734375 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.19\n",
      "step : 4283 | loss: 1.083751916885376 | dt: 154.88 ms | tokens/sec: 39.67 | norm: 2.29\n",
      "step : 4284 | loss: 1.2329665422439575 | dt: 154.36 ms | tokens/sec: 39.80 | norm: 2.87\n",
      "step : 4285 | loss: 1.133510947227478 | dt: 153.87 ms | tokens/sec: 39.93 | norm: 2.51\n",
      "step : 4286 | loss: 0.9977555274963379 | dt: 154.21 ms | tokens/sec: 39.84 | norm: 2.16\n",
      "step : 4287 | loss: 1.0270017385482788 | dt: 154.23 ms | tokens/sec: 39.84 | norm: 2.18\n",
      "step : 4288 | loss: 0.8570293188095093 | dt: 154.18 ms | tokens/sec: 39.85 | norm: 2.18\n",
      "step : 4289 | loss: 1.1382699012756348 | dt: 154.72 ms | tokens/sec: 39.71 | norm: 2.74\n",
      "step : 4290 | loss: 1.1664409637451172 | dt: 154.15 ms | tokens/sec: 39.86 | norm: 2.69\n",
      "step : 4291 | loss: 1.212908148765564 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.52\n",
      "step : 4292 | loss: 1.2239038944244385 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.66\n",
      "step : 4293 | loss: 1.1310086250305176 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.49\n",
      "step : 4294 | loss: 1.0430008172988892 | dt: 154.30 ms | tokens/sec: 39.82 | norm: 2.47\n",
      "step : 4295 | loss: 1.0638227462768555 | dt: 153.83 ms | tokens/sec: 39.94 | norm: 2.27\n",
      "step : 4296 | loss: 1.0330758094787598 | dt: 154.67 ms | tokens/sec: 39.72 | norm: 2.26\n",
      "step : 4297 | loss: 1.084789752960205 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 2.27\n",
      "step : 4298 | loss: 1.0956385135650635 | dt: 154.08 ms | tokens/sec: 39.87 | norm: 2.34\n",
      "step : 4299 | loss: 1.1010181903839111 | dt: 154.09 ms | tokens/sec: 39.87 | norm: 2.38\n",
      "step : 4300 | loss: 1.0595417022705078 | dt: 154.17 ms | tokens/sec: 39.85 | norm: 2.33\n",
      "step : 4301 | loss: 1.1387609243392944 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 2.27\n",
      "step : 4302 | loss: 1.107062816619873 | dt: 154.84 ms | tokens/sec: 39.68 | norm: 2.15\n",
      "step : 4303 | loss: 1.019088864326477 | dt: 154.12 ms | tokens/sec: 39.86 | norm: 2.09\n",
      "step : 4304 | loss: 0.9101588129997253 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.25\n",
      "step : 4305 | loss: 0.9277531504631042 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.01\n",
      "step : 4306 | loss: 0.9846051931381226 | dt: 154.19 ms | tokens/sec: 39.85 | norm: 2.41\n",
      "step : 4307 | loss: 1.0470144748687744 | dt: 153.93 ms | tokens/sec: 39.91 | norm: 2.25\n",
      "step : 4308 | loss: 0.9736859202384949 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.10\n",
      "step : 4309 | loss: 0.9689935445785522 | dt: 154.81 ms | tokens/sec: 39.69 | norm: 2.28\n",
      "step : 4310 | loss: 1.008150577545166 | dt: 154.27 ms | tokens/sec: 39.83 | norm: 2.21\n",
      "step : 4311 | loss: 0.9479572772979736 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.27\n",
      "step : 4312 | loss: 1.0132791996002197 | dt: 154.29 ms | tokens/sec: 39.82 | norm: 2.24\n",
      "step : 4313 | loss: 1.0697849988937378 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.33\n",
      "step : 4314 | loss: 1.1175414323806763 | dt: 154.26 ms | tokens/sec: 39.83 | norm: 2.38\n",
      "step : 4315 | loss: 1.0707426071166992 | dt: 154.84 ms | tokens/sec: 39.68 | norm: 2.12\n",
      "step : 4316 | loss: 1.1284925937652588 | dt: 154.23 ms | tokens/sec: 39.84 | norm: 2.18\n",
      "step : 4317 | loss: 1.075822353363037 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.31\n",
      "step : 4318 | loss: 1.1347033977508545 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.42\n",
      "step : 4319 | loss: 1.1922974586486816 | dt: 154.09 ms | tokens/sec: 39.87 | norm: 2.24\n",
      "step : 4320 | loss: 1.1671278476715088 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.40\n",
      "step : 4321 | loss: 1.0287827253341675 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.30\n",
      "step : 4322 | loss: 1.066282033920288 | dt: 154.55 ms | tokens/sec: 39.75 | norm: 2.25\n",
      "step : 4323 | loss: 1.085752010345459 | dt: 153.87 ms | tokens/sec: 39.93 | norm: 2.31\n",
      "step : 4324 | loss: 1.0209168195724487 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.34\n",
      "step : 4325 | loss: 1.0157898664474487 | dt: 154.17 ms | tokens/sec: 39.85 | norm: 2.57\n",
      "step : 4326 | loss: 1.2732657194137573 | dt: 154.33 ms | tokens/sec: 39.81 | norm: 2.66\n",
      "step : 4327 | loss: 1.2336817979812622 | dt: 154.20 ms | tokens/sec: 39.84 | norm: 2.53\n",
      "step : 4328 | loss: 1.1848496198654175 | dt: 154.98 ms | tokens/sec: 39.64 | norm: 2.49\n",
      "step : 4329 | loss: 1.1309247016906738 | dt: 153.84 ms | tokens/sec: 39.94 | norm: 2.27\n",
      "step : 4330 | loss: 1.0847495794296265 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.22\n",
      "step : 4331 | loss: 1.107405185699463 | dt: 153.89 ms | tokens/sec: 39.92 | norm: 2.18\n",
      "step : 4332 | loss: 1.0909695625305176 | dt: 154.03 ms | tokens/sec: 39.89 | norm: 2.18\n",
      "step : 4333 | loss: 1.0864671468734741 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 2.14\n",
      "step : 4334 | loss: 1.0288491249084473 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.06\n",
      "step : 4335 | loss: 1.043283462524414 | dt: 154.84 ms | tokens/sec: 39.68 | norm: 2.37\n",
      "step : 4336 | loss: 0.9251787066459656 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.12\n",
      "step : 4337 | loss: 1.0303821563720703 | dt: 153.80 ms | tokens/sec: 39.95 | norm: 2.18\n",
      "step : 4338 | loss: 1.0400843620300293 | dt: 154.26 ms | tokens/sec: 39.83 | norm: 2.58\n",
      "step : 4339 | loss: 1.1936259269714355 | dt: 154.27 ms | tokens/sec: 39.83 | norm: 2.60\n",
      "step : 4340 | loss: 1.1015733480453491 | dt: 154.54 ms | tokens/sec: 39.76 | norm: 2.56\n",
      "step : 4341 | loss: 0.9755716323852539 | dt: 154.74 ms | tokens/sec: 39.71 | norm: 2.38\n",
      "step : 4342 | loss: 1.0045886039733887 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.42\n",
      "step : 4343 | loss: 0.8331195712089539 | dt: 153.78 ms | tokens/sec: 39.95 | norm: 2.03\n",
      "step : 4344 | loss: 1.117932915687561 | dt: 153.89 ms | tokens/sec: 39.93 | norm: 2.85\n",
      "step : 4345 | loss: 1.1571111679077148 | dt: 153.86 ms | tokens/sec: 39.93 | norm: 2.74\n",
      "step : 4346 | loss: 1.1958062648773193 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.55\n",
      "step : 4347 | loss: 1.2014524936676025 | dt: 154.07 ms | tokens/sec: 39.88 | norm: 2.95\n",
      "step : 4348 | loss: 1.113702654838562 | dt: 154.64 ms | tokens/sec: 39.73 | norm: 2.56\n",
      "step : 4349 | loss: 1.0302326679229736 | dt: 153.89 ms | tokens/sec: 39.93 | norm: 2.48\n",
      "step : 4350 | loss: 1.0440521240234375 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.33\n",
      "step : 4351 | loss: 1.0061373710632324 | dt: 154.15 ms | tokens/sec: 39.86 | norm: 2.21\n",
      "step : 4352 | loss: 1.0649999380111694 | dt: 154.43 ms | tokens/sec: 39.78 | norm: 2.28\n",
      "step : 4353 | loss: 1.0701918601989746 | dt: 154.16 ms | tokens/sec: 39.85 | norm: 2.53\n",
      "step : 4354 | loss: 1.0831552743911743 | dt: 154.94 ms | tokens/sec: 39.65 | norm: 2.34\n",
      "step : 4355 | loss: 1.0420972108840942 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.12\n",
      "step : 4356 | loss: 1.1237995624542236 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.42\n",
      "step : 4357 | loss: 1.0870345830917358 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.42\n",
      "step : 4358 | loss: 1.0135278701782227 | dt: 153.89 ms | tokens/sec: 39.93 | norm: 2.32\n",
      "step : 4359 | loss: 0.9005140066146851 | dt: 153.86 ms | tokens/sec: 39.93 | norm: 2.14\n",
      "step : 4360 | loss: 0.913979172706604 | dt: 155.02 ms | tokens/sec: 39.63 | norm: 2.14\n",
      "step : 4361 | loss: 0.9679608345031738 | dt: 154.74 ms | tokens/sec: 39.70 | norm: 2.34\n",
      "step : 4362 | loss: 1.0136736631393433 | dt: 154.17 ms | tokens/sec: 39.85 | norm: 2.25\n",
      "step : 4363 | loss: 0.9514912962913513 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.33\n",
      "step : 4364 | loss: 0.9434317350387573 | dt: 153.89 ms | tokens/sec: 39.93 | norm: 2.31\n",
      "step : 4365 | loss: 0.9893215894699097 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.29\n",
      "step : 4366 | loss: 0.9247432947158813 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.17\n",
      "step : 4367 | loss: 0.9999515414237976 | dt: 154.80 ms | tokens/sec: 39.69 | norm: 2.16\n",
      "step : 4368 | loss: 1.0403327941894531 | dt: 154.20 ms | tokens/sec: 39.85 | norm: 2.48\n",
      "step : 4369 | loss: 1.0867904424667358 | dt: 155.83 ms | tokens/sec: 39.43 | norm: 2.57\n",
      "step : 4370 | loss: 1.0357892513275146 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 2.31\n",
      "step : 4371 | loss: 1.0959219932556152 | dt: 154.02 ms | tokens/sec: 39.89 | norm: 2.47\n",
      "step : 4372 | loss: 1.0524976253509521 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.45\n",
      "step : 4373 | loss: 1.100041151046753 | dt: 154.74 ms | tokens/sec: 39.70 | norm: 2.43\n",
      "step : 4374 | loss: 1.1558070182800293 | dt: 154.34 ms | tokens/sec: 39.81 | norm: 2.30\n",
      "step : 4375 | loss: 1.1359838247299194 | dt: 153.85 ms | tokens/sec: 39.94 | norm: 2.46\n",
      "step : 4376 | loss: 0.9926006197929382 | dt: 153.93 ms | tokens/sec: 39.91 | norm: 2.27\n",
      "step : 4377 | loss: 1.0280075073242188 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.30\n",
      "step : 4378 | loss: 1.0449106693267822 | dt: 154.07 ms | tokens/sec: 39.88 | norm: 2.27\n",
      "step : 4379 | loss: 0.9877409934997559 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.28\n",
      "step : 4380 | loss: 0.9878063201904297 | dt: 154.85 ms | tokens/sec: 39.68 | norm: 2.26\n",
      "step : 4381 | loss: 1.2382882833480835 | dt: 153.94 ms | tokens/sec: 39.91 | norm: 2.64\n",
      "step : 4382 | loss: 1.1969571113586426 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.49\n",
      "step : 4383 | loss: 1.154395580291748 | dt: 154.04 ms | tokens/sec: 39.89 | norm: 2.50\n",
      "step : 4384 | loss: 1.1058027744293213 | dt: 154.16 ms | tokens/sec: 39.85 | norm: 2.46\n",
      "step : 4385 | loss: 1.0465596914291382 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.33\n",
      "step : 4386 | loss: 1.0733706951141357 | dt: 155.09 ms | tokens/sec: 39.62 | norm: 2.34\n",
      "step : 4387 | loss: 1.0520503520965576 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.24\n",
      "step : 4388 | loss: 1.0552771091461182 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.19\n",
      "step : 4389 | loss: 0.9864396452903748 | dt: 153.76 ms | tokens/sec: 39.96 | norm: 2.04\n",
      "step : 4390 | loss: 1.0053163766860962 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.27\n",
      "step : 4391 | loss: 0.8833953738212585 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.22\n",
      "step : 4392 | loss: 0.9961422681808472 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.23\n",
      "step : 4393 | loss: 1.0010313987731934 | dt: 154.92 ms | tokens/sec: 39.66 | norm: 2.16\n",
      "step : 4394 | loss: 1.158226490020752 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.81\n",
      "step : 4395 | loss: 1.0766953229904175 | dt: 154.07 ms | tokens/sec: 39.88 | norm: 2.43\n",
      "step : 4396 | loss: 0.949397087097168 | dt: 154.03 ms | tokens/sec: 39.89 | norm: 2.14\n",
      "step : 4397 | loss: 0.9731222987174988 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.26\n",
      "step : 4398 | loss: 0.8089653849601746 | dt: 154.04 ms | tokens/sec: 39.89 | norm: 2.09\n",
      "step : 4399 | loss: 1.0807005167007446 | dt: 154.76 ms | tokens/sec: 39.70 | norm: 2.54\n",
      "step : 4400 | loss: 1.12666916847229 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 2.73\n",
      "step : 4401 | loss: 1.1672534942626953 | dt: 153.89 ms | tokens/sec: 39.93 | norm: 2.45\n",
      "step : 4402 | loss: 1.1687166690826416 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 2.76\n",
      "step : 4403 | loss: 1.0657286643981934 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.63\n",
      "step : 4404 | loss: 0.9930830001831055 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.35\n",
      "step : 4405 | loss: 0.9977037906646729 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 2.49\n",
      "step : 4406 | loss: 0.9632046222686768 | dt: 155.02 ms | tokens/sec: 39.63 | norm: 2.26\n",
      "step : 4407 | loss: 1.030907154083252 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.35\n",
      "step : 4408 | loss: 1.0311943292617798 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.45\n",
      "step : 4409 | loss: 1.0509083271026611 | dt: 154.15 ms | tokens/sec: 39.86 | norm: 2.31\n",
      "step : 4410 | loss: 1.009211778640747 | dt: 154.60 ms | tokens/sec: 39.74 | norm: 2.30\n",
      "step : 4411 | loss: 1.0921337604522705 | dt: 154.92 ms | tokens/sec: 39.66 | norm: 2.27\n",
      "step : 4412 | loss: 1.0727314949035645 | dt: 155.12 ms | tokens/sec: 39.61 | norm: 2.65\n",
      "step : 4413 | loss: 0.9865524172782898 | dt: 154.03 ms | tokens/sec: 39.89 | norm: 2.24\n",
      "step : 4414 | loss: 0.875860333442688 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.36\n",
      "step : 4415 | loss: 0.8868623971939087 | dt: 153.86 ms | tokens/sec: 39.93 | norm: 2.28\n",
      "step : 4416 | loss: 0.9385292530059814 | dt: 154.38 ms | tokens/sec: 39.80 | norm: 2.22\n",
      "step : 4417 | loss: 0.9954109191894531 | dt: 153.85 ms | tokens/sec: 39.93 | norm: 2.41\n",
      "step : 4418 | loss: 0.9281036853790283 | dt: 153.94 ms | tokens/sec: 39.91 | norm: 2.51\n",
      "step : 4419 | loss: 0.9264012575149536 | dt: 154.71 ms | tokens/sec: 39.71 | norm: 2.06\n",
      "step : 4420 | loss: 0.9672118425369263 | dt: 154.26 ms | tokens/sec: 39.83 | norm: 2.24\n",
      "step : 4421 | loss: 0.9012082815170288 | dt: 153.81 ms | tokens/sec: 39.95 | norm: 2.16\n",
      "step : 4422 | loss: 0.9779312014579773 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.68\n",
      "step : 4423 | loss: 1.0155922174453735 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.62\n",
      "step : 4424 | loss: 1.0684508085250854 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.47\n",
      "step : 4425 | loss: 1.0158238410949707 | dt: 154.94 ms | tokens/sec: 39.65 | norm: 2.22\n",
      "step : 4426 | loss: 1.0864375829696655 | dt: 154.27 ms | tokens/sec: 39.83 | norm: 2.74\n",
      "step : 4427 | loss: 1.030496597290039 | dt: 153.93 ms | tokens/sec: 39.91 | norm: 2.35\n",
      "step : 4428 | loss: 1.0730246305465698 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.44\n",
      "step : 4429 | loss: 1.1563239097595215 | dt: 153.85 ms | tokens/sec: 39.93 | norm: 2.58\n",
      "step : 4430 | loss: 1.1226918697357178 | dt: 154.02 ms | tokens/sec: 39.89 | norm: 2.44\n",
      "step : 4431 | loss: 0.9811479449272156 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.46\n",
      "step : 4432 | loss: 1.0238913297653198 | dt: 154.85 ms | tokens/sec: 39.68 | norm: 2.36\n",
      "step : 4433 | loss: 1.0412774085998535 | dt: 154.03 ms | tokens/sec: 39.89 | norm: 2.29\n",
      "step : 4434 | loss: 0.9673721790313721 | dt: 154.02 ms | tokens/sec: 39.89 | norm: 2.38\n",
      "step : 4435 | loss: 0.9609567523002625 | dt: 153.84 ms | tokens/sec: 39.94 | norm: 2.36\n",
      "step : 4436 | loss: 1.2061094045639038 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.70\n",
      "step : 4437 | loss: 1.164680004119873 | dt: 154.07 ms | tokens/sec: 39.88 | norm: 2.49\n",
      "step : 4438 | loss: 1.1143686771392822 | dt: 155.06 ms | tokens/sec: 39.62 | norm: 2.51\n",
      "step : 4439 | loss: 1.0698070526123047 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.28\n",
      "step : 4440 | loss: 1.0177204608917236 | dt: 154.31 ms | tokens/sec: 39.82 | norm: 2.38\n",
      "step : 4441 | loss: 1.0448473691940308 | dt: 153.82 ms | tokens/sec: 39.94 | norm: 2.33\n",
      "step : 4442 | loss: 1.0187591314315796 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.33\n",
      "step : 4443 | loss: 1.0274847745895386 | dt: 154.13 ms | tokens/sec: 39.86 | norm: 2.67\n",
      "step : 4444 | loss: 0.9711701273918152 | dt: 154.27 ms | tokens/sec: 39.83 | norm: 2.43\n",
      "step : 4445 | loss: 0.9834136366844177 | dt: 154.71 ms | tokens/sec: 39.71 | norm: 2.23\n",
      "step : 4446 | loss: 0.8812779188156128 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 2.37\n",
      "step : 4447 | loss: 0.9790670275688171 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.23\n",
      "step : 4448 | loss: 0.9732030630111694 | dt: 153.91 ms | tokens/sec: 39.92 | norm: 2.24\n",
      "step : 4449 | loss: 1.1486515998840332 | dt: 153.86 ms | tokens/sec: 39.93 | norm: 2.60\n",
      "step : 4450 | loss: 1.0557971000671387 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.49\n",
      "step : 4451 | loss: 0.9211055040359497 | dt: 154.84 ms | tokens/sec: 39.68 | norm: 2.22\n",
      "step : 4452 | loss: 0.941851794719696 | dt: 154.19 ms | tokens/sec: 39.85 | norm: 2.43\n",
      "step : 4453 | loss: 0.7779017686843872 | dt: 153.87 ms | tokens/sec: 39.93 | norm: 2.24\n",
      "step : 4454 | loss: 1.0295871496200562 | dt: 154.04 ms | tokens/sec: 39.89 | norm: 2.64\n",
      "step : 4455 | loss: 1.0627957582473755 | dt: 154.03 ms | tokens/sec: 39.89 | norm: 2.42\n",
      "step : 4456 | loss: 1.1106538772583008 | dt: 154.16 ms | tokens/sec: 39.85 | norm: 2.49\n",
      "step : 4457 | loss: 1.110139012336731 | dt: 154.12 ms | tokens/sec: 39.87 | norm: 2.62\n",
      "step : 4458 | loss: 1.0218867063522339 | dt: 154.71 ms | tokens/sec: 39.71 | norm: 2.44\n",
      "step : 4459 | loss: 0.9546552896499634 | dt: 154.03 ms | tokens/sec: 39.89 | norm: 2.19\n",
      "step : 4460 | loss: 0.9516565203666687 | dt: 154.24 ms | tokens/sec: 39.83 | norm: 2.27\n",
      "step : 4461 | loss: 0.9114577174186707 | dt: 154.14 ms | tokens/sec: 39.86 | norm: 2.25\n",
      "step : 4462 | loss: 0.984611988067627 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.39\n",
      "step : 4463 | loss: 0.9976214170455933 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.52\n",
      "step : 4464 | loss: 0.9970171451568604 | dt: 155.08 ms | tokens/sec: 39.62 | norm: 2.31\n",
      "step : 4465 | loss: 0.9616610407829285 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.15\n",
      "step : 4466 | loss: 1.0425186157226562 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.30\n",
      "step : 4467 | loss: 1.0212477445602417 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.50\n",
      "step : 4468 | loss: 0.9306164979934692 | dt: 154.27 ms | tokens/sec: 39.83 | norm: 2.09\n",
      "step : 4469 | loss: 0.8320389986038208 | dt: 154.07 ms | tokens/sec: 39.88 | norm: 2.10\n",
      "step : 4470 | loss: 0.8373183012008667 | dt: 154.24 ms | tokens/sec: 39.84 | norm: 2.07\n",
      "step : 4471 | loss: 0.8868616819381714 | dt: 154.70 ms | tokens/sec: 39.71 | norm: 2.35\n",
      "step : 4472 | loss: 0.9495919942855835 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.29\n",
      "step : 4473 | loss: 0.8852121233940125 | dt: 153.79 ms | tokens/sec: 39.95 | norm: 2.23\n",
      "step : 4474 | loss: 0.8646413087844849 | dt: 153.93 ms | tokens/sec: 39.91 | norm: 2.17\n",
      "step : 4475 | loss: 0.907227635383606 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 2.22\n",
      "step : 4476 | loss: 0.8393795490264893 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.10\n",
      "step : 4477 | loss: 0.9261937141418457 | dt: 154.69 ms | tokens/sec: 39.72 | norm: 2.19\n",
      "step : 4478 | loss: 0.9813816547393799 | dt: 154.07 ms | tokens/sec: 39.88 | norm: 2.59\n",
      "step : 4479 | loss: 1.0188186168670654 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.86\n",
      "step : 4480 | loss: 0.963061511516571 | dt: 154.08 ms | tokens/sec: 39.88 | norm: 2.58\n",
      "step : 4481 | loss: 1.0382931232452393 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.33\n",
      "step : 4482 | loss: 0.9819281101226807 | dt: 154.23 ms | tokens/sec: 39.84 | norm: 2.38\n",
      "step : 4483 | loss: 1.030582308769226 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.31\n",
      "step : 4484 | loss: 1.1051796674728394 | dt: 154.95 ms | tokens/sec: 39.65 | norm: 2.52\n",
      "step : 4485 | loss: 1.0606026649475098 | dt: 154.07 ms | tokens/sec: 39.88 | norm: 2.57\n",
      "step : 4486 | loss: 0.9374339580535889 | dt: 154.26 ms | tokens/sec: 39.83 | norm: 2.55\n",
      "step : 4487 | loss: 0.967678427696228 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.24\n",
      "step : 4488 | loss: 1.0069034099578857 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.41\n",
      "step : 4489 | loss: 0.934837281703949 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.17\n",
      "step : 4490 | loss: 0.9336044788360596 | dt: 154.67 ms | tokens/sec: 39.72 | norm: 2.27\n",
      "step : 4491 | loss: 1.1861581802368164 | dt: 153.85 ms | tokens/sec: 39.94 | norm: 2.76\n",
      "step : 4492 | loss: 1.1323952674865723 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.48\n",
      "step : 4493 | loss: 1.0757484436035156 | dt: 153.93 ms | tokens/sec: 39.92 | norm: 2.24\n",
      "step : 4494 | loss: 1.0349243879318237 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.32\n",
      "step : 4495 | loss: 0.9853291511535645 | dt: 154.04 ms | tokens/sec: 39.88 | norm: 2.39\n",
      "step : 4496 | loss: 1.0103199481964111 | dt: 154.23 ms | tokens/sec: 39.84 | norm: 2.63\n",
      "step : 4497 | loss: 0.9771443605422974 | dt: 154.66 ms | tokens/sec: 39.73 | norm: 2.13\n",
      "step : 4498 | loss: 0.9926835298538208 | dt: 154.04 ms | tokens/sec: 39.89 | norm: 2.15\n",
      "step : 4499 | loss: 0.9247395396232605 | dt: 153.91 ms | tokens/sec: 39.92 | norm: 2.14\n",
      "step : 4500 | loss: 0.9376786947250366 | dt: 154.19 ms | tokens/sec: 39.85 | norm: 2.28\n",
      "step : 4501 | loss: 0.8306023478507996 | dt: 154.54 ms | tokens/sec: 39.76 | norm: 2.18\n",
      "step : 4502 | loss: 0.9288101196289062 | dt: 154.20 ms | tokens/sec: 39.84 | norm: 2.45\n",
      "step : 4503 | loss: 0.9284873008728027 | dt: 154.85 ms | tokens/sec: 39.68 | norm: 2.33\n",
      "step : 4504 | loss: 1.1078038215637207 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.55\n",
      "step : 4505 | loss: 1.014425277709961 | dt: 153.82 ms | tokens/sec: 39.94 | norm: 2.47\n",
      "step : 4506 | loss: 0.8962957262992859 | dt: 153.97 ms | tokens/sec: 39.91 | norm: 2.39\n",
      "step : 4507 | loss: 0.9273273944854736 | dt: 154.08 ms | tokens/sec: 39.87 | norm: 2.38\n",
      "step : 4508 | loss: 0.7538710832595825 | dt: 154.25 ms | tokens/sec: 39.83 | norm: 2.03\n",
      "step : 4509 | loss: 1.0061748027801514 | dt: 153.86 ms | tokens/sec: 39.93 | norm: 2.52\n",
      "step : 4510 | loss: 1.04530930519104 | dt: 155.04 ms | tokens/sec: 39.63 | norm: 2.66\n",
      "step : 4511 | loss: 1.091902256011963 | dt: 153.86 ms | tokens/sec: 39.93 | norm: 2.71\n",
      "step : 4512 | loss: 1.0809247493743896 | dt: 153.93 ms | tokens/sec: 39.91 | norm: 2.60\n",
      "step : 4513 | loss: 0.9968473315238953 | dt: 154.15 ms | tokens/sec: 39.86 | norm: 2.40\n",
      "step : 4514 | loss: 0.9232401847839355 | dt: 154.34 ms | tokens/sec: 39.81 | norm: 2.42\n",
      "step : 4515 | loss: 0.9323524236679077 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 2.45\n",
      "step : 4516 | loss: 0.8787760138511658 | dt: 154.89 ms | tokens/sec: 39.67 | norm: 2.23\n",
      "step : 4517 | loss: 0.9496027827262878 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.31\n",
      "step : 4518 | loss: 0.9474180936813354 | dt: 153.93 ms | tokens/sec: 39.92 | norm: 2.51\n",
      "step : 4519 | loss: 0.962195873260498 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.33\n",
      "step : 4520 | loss: 0.9302365183830261 | dt: 154.14 ms | tokens/sec: 39.86 | norm: 2.27\n",
      "step : 4521 | loss: 1.0079491138458252 | dt: 153.93 ms | tokens/sec: 39.91 | norm: 2.47\n",
      "step : 4522 | loss: 0.9960154891014099 | dt: 153.89 ms | tokens/sec: 39.92 | norm: 2.52\n",
      "step : 4523 | loss: 0.8997504711151123 | dt: 154.74 ms | tokens/sec: 39.71 | norm: 2.44\n",
      "step : 4524 | loss: 0.8121761083602905 | dt: 154.07 ms | tokens/sec: 39.88 | norm: 2.25\n",
      "step : 4525 | loss: 0.8123499751091003 | dt: 155.28 ms | tokens/sec: 39.57 | norm: 2.29\n",
      "step : 4526 | loss: 0.8674352169036865 | dt: 154.38 ms | tokens/sec: 39.80 | norm: 2.46\n",
      "step : 4527 | loss: 0.9141709804534912 | dt: 153.94 ms | tokens/sec: 39.91 | norm: 2.25\n",
      "step : 4528 | loss: 0.8409978747367859 | dt: 154.07 ms | tokens/sec: 39.88 | norm: 2.23\n",
      "step : 4529 | loss: 0.8260413408279419 | dt: 155.03 ms | tokens/sec: 39.63 | norm: 2.08\n",
      "step : 4530 | loss: 0.8668661117553711 | dt: 154.21 ms | tokens/sec: 39.84 | norm: 2.19\n",
      "step : 4531 | loss: 0.7977147102355957 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.15\n",
      "step : 4532 | loss: 0.8815616965293884 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.01\n",
      "step : 4533 | loss: 0.9212526082992554 | dt: 154.12 ms | tokens/sec: 39.87 | norm: 2.18\n",
      "step : 4534 | loss: 0.9820534586906433 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.45\n",
      "step : 4535 | loss: 0.913958728313446 | dt: 153.91 ms | tokens/sec: 39.92 | norm: 2.07\n",
      "step : 4536 | loss: 0.9781951904296875 | dt: 154.70 ms | tokens/sec: 39.72 | norm: 2.26\n",
      "step : 4537 | loss: 0.9378637075424194 | dt: 153.87 ms | tokens/sec: 39.93 | norm: 2.28\n",
      "step : 4538 | loss: 0.9798287749290466 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 2.32\n",
      "step : 4539 | loss: 1.0494616031646729 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.40\n",
      "step : 4540 | loss: 1.0291416645050049 | dt: 154.22 ms | tokens/sec: 39.84 | norm: 2.54\n",
      "step : 4541 | loss: 0.8922335505485535 | dt: 153.85 ms | tokens/sec: 39.94 | norm: 2.55\n",
      "step : 4542 | loss: 0.9331679344177246 | dt: 154.82 ms | tokens/sec: 39.68 | norm: 2.43\n",
      "step : 4543 | loss: 0.960519015789032 | dt: 153.87 ms | tokens/sec: 39.93 | norm: 2.38\n",
      "step : 4544 | loss: 0.8897745013237 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 2.50\n",
      "step : 4545 | loss: 0.8866380453109741 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.32\n",
      "step : 4546 | loss: 1.1405634880065918 | dt: 154.09 ms | tokens/sec: 39.87 | norm: 2.70\n",
      "step : 4547 | loss: 1.0828204154968262 | dt: 154.07 ms | tokens/sec: 39.88 | norm: 2.50\n",
      "step : 4548 | loss: 1.0287256240844727 | dt: 154.17 ms | tokens/sec: 39.85 | norm: 2.42\n",
      "step : 4549 | loss: 0.9929341077804565 | dt: 154.55 ms | tokens/sec: 39.75 | norm: 2.42\n",
      "step : 4550 | loss: 0.9456876516342163 | dt: 154.35 ms | tokens/sec: 39.81 | norm: 2.13\n",
      "step : 4551 | loss: 0.9737858772277832 | dt: 153.83 ms | tokens/sec: 39.94 | norm: 2.24\n",
      "step : 4552 | loss: 0.9430913925170898 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.23\n",
      "step : 4553 | loss: 0.9650148153305054 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.11\n",
      "step : 4554 | loss: 0.8990411162376404 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.20\n",
      "step : 4555 | loss: 0.9206169843673706 | dt: 154.65 ms | tokens/sec: 39.73 | norm: 2.39\n",
      "step : 4556 | loss: 0.7984554171562195 | dt: 154.14 ms | tokens/sec: 39.86 | norm: 2.33\n",
      "step : 4557 | loss: 0.9032394289970398 | dt: 154.21 ms | tokens/sec: 39.84 | norm: 2.36\n",
      "step : 4558 | loss: 0.8892631530761719 | dt: 154.51 ms | tokens/sec: 39.76 | norm: 2.35\n",
      "step : 4559 | loss: 1.0628975629806519 | dt: 154.29 ms | tokens/sec: 39.82 | norm: 2.57\n",
      "step : 4560 | loss: 0.974341869354248 | dt: 154.34 ms | tokens/sec: 39.81 | norm: 2.66\n",
      "step : 4561 | loss: 0.8548129796981812 | dt: 154.88 ms | tokens/sec: 39.67 | norm: 2.41\n",
      "step : 4562 | loss: 0.8733201026916504 | dt: 154.08 ms | tokens/sec: 39.88 | norm: 2.19\n",
      "step : 4563 | loss: 0.7089608907699585 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.04\n",
      "step : 4564 | loss: 0.9589970111846924 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.29\n",
      "step : 4565 | loss: 1.0034739971160889 | dt: 153.87 ms | tokens/sec: 39.93 | norm: 2.52\n",
      "step : 4566 | loss: 1.0574063062667847 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.51\n",
      "step : 4567 | loss: 1.038982629776001 | dt: 153.78 ms | tokens/sec: 39.95 | norm: 2.64\n",
      "step : 4568 | loss: 0.9590739011764526 | dt: 154.89 ms | tokens/sec: 39.67 | norm: 2.36\n",
      "step : 4569 | loss: 0.9007781744003296 | dt: 153.93 ms | tokens/sec: 39.91 | norm: 2.37\n",
      "step : 4570 | loss: 0.902788519859314 | dt: 154.03 ms | tokens/sec: 39.89 | norm: 2.43\n",
      "step : 4571 | loss: 0.8564102053642273 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.39\n",
      "step : 4572 | loss: 0.9154002666473389 | dt: 154.14 ms | tokens/sec: 39.86 | norm: 2.26\n",
      "step : 4573 | loss: 0.9228123426437378 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.29\n",
      "step : 4574 | loss: 0.9467951655387878 | dt: 154.68 ms | tokens/sec: 39.72 | norm: 2.56\n",
      "step : 4575 | loss: 0.8957381248474121 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.31\n",
      "step : 4576 | loss: 0.9753004908561707 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.31\n",
      "step : 4577 | loss: 0.9578984975814819 | dt: 154.15 ms | tokens/sec: 39.86 | norm: 2.34\n",
      "step : 4578 | loss: 0.8567728400230408 | dt: 154.20 ms | tokens/sec: 39.84 | norm: 2.17\n",
      "step : 4579 | loss: 0.7628746032714844 | dt: 154.15 ms | tokens/sec: 39.86 | norm: 2.07\n",
      "step : 4580 | loss: 0.7695653438568115 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.22\n",
      "step : 4581 | loss: 0.8225038051605225 | dt: 154.90 ms | tokens/sec: 39.66 | norm: 2.39\n",
      "step : 4582 | loss: 0.8606268167495728 | dt: 154.21 ms | tokens/sec: 39.84 | norm: 2.26\n",
      "step : 4583 | loss: 0.7914800643920898 | dt: 153.93 ms | tokens/sec: 39.92 | norm: 2.13\n",
      "step : 4584 | loss: 0.7842759490013123 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 2.14\n",
      "step : 4585 | loss: 0.8304757475852966 | dt: 153.91 ms | tokens/sec: 39.92 | norm: 2.26\n",
      "step : 4586 | loss: 0.7707803249359131 | dt: 153.94 ms | tokens/sec: 39.91 | norm: 2.10\n",
      "step : 4587 | loss: 0.8435006141662598 | dt: 154.53 ms | tokens/sec: 39.76 | norm: 2.25\n",
      "step : 4588 | loss: 0.887519121170044 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.36\n",
      "step : 4589 | loss: 0.9431113004684448 | dt: 153.82 ms | tokens/sec: 39.94 | norm: 2.40\n",
      "step : 4590 | loss: 0.8728029727935791 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 1.94\n",
      "step : 4591 | loss: 0.93748939037323 | dt: 153.77 ms | tokens/sec: 39.96 | norm: 2.26\n",
      "step : 4592 | loss: 0.8863652944564819 | dt: 153.86 ms | tokens/sec: 39.93 | norm: 2.27\n",
      "step : 4593 | loss: 0.935824990272522 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.26\n",
      "step : 4594 | loss: 1.0074419975280762 | dt: 155.00 ms | tokens/sec: 39.64 | norm: 2.26\n",
      "step : 4595 | loss: 0.9770320653915405 | dt: 153.84 ms | tokens/sec: 39.94 | norm: 3.06\n",
      "step : 4596 | loss: 0.8592928647994995 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 2.42\n",
      "step : 4597 | loss: 0.8835527300834656 | dt: 154.16 ms | tokens/sec: 39.85 | norm: 2.28\n",
      "step : 4598 | loss: 0.9272780418395996 | dt: 154.09 ms | tokens/sec: 39.87 | norm: 2.51\n",
      "step : 4599 | loss: 0.855618953704834 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.44\n",
      "step : 4600 | loss: 0.8342916369438171 | dt: 154.86 ms | tokens/sec: 39.67 | norm: 2.29\n",
      "step : 4601 | loss: 1.1097798347473145 | dt: 153.93 ms | tokens/sec: 39.92 | norm: 2.78\n",
      "step : 4602 | loss: 1.0506340265274048 | dt: 153.91 ms | tokens/sec: 39.92 | norm: 2.73\n",
      "step : 4603 | loss: 0.9960545301437378 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.68\n",
      "step : 4604 | loss: 0.9634990692138672 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.63\n",
      "step : 4605 | loss: 0.912487268447876 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.29\n",
      "step : 4606 | loss: 0.9433571696281433 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.41\n",
      "step : 4607 | loss: 0.8972574472427368 | dt: 154.64 ms | tokens/sec: 39.73 | norm: 2.22\n",
      "step : 4608 | loss: 0.9218865633010864 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.11\n",
      "step : 4609 | loss: 0.8647703528404236 | dt: 153.79 ms | tokens/sec: 39.95 | norm: 2.11\n",
      "step : 4610 | loss: 0.879824161529541 | dt: 154.26 ms | tokens/sec: 39.83 | norm: 2.26\n",
      "step : 4611 | loss: 0.7676148414611816 | dt: 154.24 ms | tokens/sec: 39.83 | norm: 2.17\n",
      "step : 4612 | loss: 0.8657634258270264 | dt: 154.18 ms | tokens/sec: 39.85 | norm: 2.23\n",
      "step : 4613 | loss: 0.8575408458709717 | dt: 154.91 ms | tokens/sec: 39.66 | norm: 2.17\n",
      "step : 4614 | loss: 1.0147690773010254 | dt: 154.14 ms | tokens/sec: 39.86 | norm: 2.52\n",
      "step : 4615 | loss: 0.9334422945976257 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.41\n",
      "step : 4616 | loss: 0.8103997111320496 | dt: 154.04 ms | tokens/sec: 39.89 | norm: 2.18\n",
      "step : 4617 | loss: 0.8337084650993347 | dt: 153.86 ms | tokens/sec: 39.93 | norm: 2.26\n",
      "step : 4618 | loss: 0.6741018295288086 | dt: 154.03 ms | tokens/sec: 39.89 | norm: 2.07\n",
      "step : 4619 | loss: 0.9135161638259888 | dt: 153.79 ms | tokens/sec: 39.95 | norm: 2.78\n",
      "step : 4620 | loss: 0.9631592631340027 | dt: 154.73 ms | tokens/sec: 39.71 | norm: 2.67\n",
      "step : 4621 | loss: 1.0146631002426147 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.90\n",
      "step : 4622 | loss: 0.9981168508529663 | dt: 154.04 ms | tokens/sec: 39.89 | norm: 2.76\n",
      "step : 4623 | loss: 0.9240036010742188 | dt: 154.22 ms | tokens/sec: 39.84 | norm: 2.75\n",
      "step : 4624 | loss: 0.8640115261077881 | dt: 154.17 ms | tokens/sec: 39.85 | norm: 2.53\n",
      "step : 4625 | loss: 0.8664660453796387 | dt: 154.27 ms | tokens/sec: 39.83 | norm: 2.33\n",
      "step : 4626 | loss: 0.8217141032218933 | dt: 155.36 ms | tokens/sec: 39.55 | norm: 2.18\n",
      "step : 4627 | loss: 0.8770002126693726 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.33\n",
      "step : 4628 | loss: 0.8843659162521362 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.34\n",
      "step : 4629 | loss: 0.9023289084434509 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.44\n",
      "step : 4630 | loss: 0.8555252552032471 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.25\n",
      "step : 4631 | loss: 0.9458419680595398 | dt: 153.89 ms | tokens/sec: 39.93 | norm: 2.41\n",
      "step : 4632 | loss: 0.9231650233268738 | dt: 154.03 ms | tokens/sec: 39.89 | norm: 2.53\n",
      "step : 4633 | loss: 0.8251820802688599 | dt: 154.80 ms | tokens/sec: 39.69 | norm: 2.37\n",
      "step : 4634 | loss: 0.7321146726608276 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.08\n",
      "step : 4635 | loss: 0.7392057180404663 | dt: 153.84 ms | tokens/sec: 39.94 | norm: 2.11\n",
      "step : 4636 | loss: 0.7947055101394653 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 2.84\n",
      "step : 4637 | loss: 0.8362963199615479 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.34\n",
      "step : 4638 | loss: 0.7628046274185181 | dt: 154.22 ms | tokens/sec: 39.84 | norm: 2.18\n",
      "step : 4639 | loss: 0.7574324011802673 | dt: 154.80 ms | tokens/sec: 39.69 | norm: 2.29\n",
      "step : 4640 | loss: 0.7981926798820496 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.10\n",
      "step : 4641 | loss: 0.7343076467514038 | dt: 153.84 ms | tokens/sec: 39.94 | norm: 2.18\n",
      "step : 4642 | loss: 0.8033081889152527 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.43\n",
      "step : 4643 | loss: 0.8564978837966919 | dt: 154.13 ms | tokens/sec: 39.86 | norm: 2.47\n",
      "step : 4644 | loss: 0.9046875834465027 | dt: 154.34 ms | tokens/sec: 39.81 | norm: 2.39\n",
      "step : 4645 | loss: 0.8345782160758972 | dt: 154.04 ms | tokens/sec: 39.88 | norm: 2.21\n",
      "step : 4646 | loss: 0.8944522738456726 | dt: 154.76 ms | tokens/sec: 39.70 | norm: 2.38\n",
      "step : 4647 | loss: 0.8518047332763672 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.16\n",
      "step : 4648 | loss: 0.8967205882072449 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.09\n",
      "step : 4649 | loss: 0.955431342124939 | dt: 153.89 ms | tokens/sec: 39.92 | norm: 2.23\n",
      "step : 4650 | loss: 0.9470710754394531 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 2.43\n",
      "step : 4651 | loss: 0.8308062553405762 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.36\n",
      "step : 4652 | loss: 0.8489350080490112 | dt: 154.77 ms | tokens/sec: 39.70 | norm: 2.52\n",
      "step : 4653 | loss: 0.8844589591026306 | dt: 153.94 ms | tokens/sec: 39.91 | norm: 2.33\n",
      "step : 4654 | loss: 0.8229390978813171 | dt: 153.93 ms | tokens/sec: 39.91 | norm: 2.34\n",
      "step : 4655 | loss: 0.8170427083969116 | dt: 153.83 ms | tokens/sec: 39.94 | norm: 2.43\n",
      "step : 4656 | loss: 1.0628327131271362 | dt: 154.15 ms | tokens/sec: 39.86 | norm: 2.70\n",
      "step : 4657 | loss: 1.0182116031646729 | dt: 154.32 ms | tokens/sec: 39.81 | norm: 2.60\n",
      "step : 4658 | loss: 0.9582840800285339 | dt: 154.53 ms | tokens/sec: 39.76 | norm: 2.64\n",
      "step : 4659 | loss: 0.9278385043144226 | dt: 154.79 ms | tokens/sec: 39.69 | norm: 2.42\n",
      "step : 4660 | loss: 0.8782243728637695 | dt: 154.12 ms | tokens/sec: 39.86 | norm: 2.55\n",
      "step : 4661 | loss: 0.9084194898605347 | dt: 153.76 ms | tokens/sec: 39.96 | norm: 2.33\n",
      "step : 4662 | loss: 0.8625466227531433 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.28\n",
      "step : 4663 | loss: 0.8781229853630066 | dt: 153.89 ms | tokens/sec: 39.92 | norm: 2.15\n",
      "step : 4664 | loss: 0.8288949728012085 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.17\n",
      "step : 4665 | loss: 0.8466957807540894 | dt: 154.85 ms | tokens/sec: 39.68 | norm: 2.16\n",
      "step : 4666 | loss: 0.7378270030021667 | dt: 154.07 ms | tokens/sec: 39.88 | norm: 2.32\n",
      "step : 4667 | loss: 0.8368799090385437 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 2.41\n",
      "step : 4668 | loss: 0.8198946714401245 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 2.12\n",
      "step : 4669 | loss: 0.9910973310470581 | dt: 153.89 ms | tokens/sec: 39.92 | norm: 2.59\n",
      "step : 4670 | loss: 0.9106737971305847 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 2.61\n",
      "step : 4671 | loss: 0.7900518774986267 | dt: 153.93 ms | tokens/sec: 39.91 | norm: 2.23\n",
      "step : 4672 | loss: 0.8170876502990723 | dt: 154.89 ms | tokens/sec: 39.67 | norm: 2.49\n",
      "step : 4673 | loss: 0.6550392508506775 | dt: 153.89 ms | tokens/sec: 39.92 | norm: 2.20\n",
      "step : 4674 | loss: 0.8763379454612732 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.40\n",
      "step : 4675 | loss: 0.9203382730484009 | dt: 154.22 ms | tokens/sec: 39.84 | norm: 2.49\n",
      "step : 4676 | loss: 0.9763774871826172 | dt: 154.27 ms | tokens/sec: 39.83 | norm: 2.57\n",
      "step : 4677 | loss: 0.9631475210189819 | dt: 154.02 ms | tokens/sec: 39.89 | norm: 3.15\n",
      "step : 4678 | loss: 0.8928179740905762 | dt: 154.94 ms | tokens/sec: 39.65 | norm: 2.67\n",
      "step : 4679 | loss: 0.8304829597473145 | dt: 154.08 ms | tokens/sec: 39.87 | norm: 2.48\n",
      "step : 4680 | loss: 0.8305220007896423 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.42\n",
      "step : 4681 | loss: 0.7809182405471802 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.37\n",
      "step : 4682 | loss: 0.8492686152458191 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.58\n",
      "step : 4683 | loss: 0.8486593961715698 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 2.35\n",
      "step : 4684 | loss: 0.8804613351821899 | dt: 154.20 ms | tokens/sec: 39.84 | norm: 2.43\n",
      "step : 4685 | loss: 0.832183301448822 | dt: 154.71 ms | tokens/sec: 39.71 | norm: 3.09\n",
      "step : 4686 | loss: 0.925068736076355 | dt: 154.16 ms | tokens/sec: 39.85 | norm: 2.54\n",
      "step : 4687 | loss: 0.9000792503356934 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.83\n",
      "step : 4688 | loss: 0.802464485168457 | dt: 154.17 ms | tokens/sec: 39.85 | norm: 2.38\n",
      "step : 4689 | loss: 0.7114366292953491 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 2.19\n",
      "step : 4690 | loss: 0.7136890292167664 | dt: 153.93 ms | tokens/sec: 39.91 | norm: 2.44\n",
      "step : 4691 | loss: 0.7727794647216797 | dt: 154.73 ms | tokens/sec: 39.71 | norm: 2.44\n",
      "step : 4692 | loss: 0.8065184354782104 | dt: 154.16 ms | tokens/sec: 39.85 | norm: 2.33\n",
      "step : 4693 | loss: 0.7357060313224792 | dt: 153.85 ms | tokens/sec: 39.94 | norm: 2.35\n",
      "step : 4694 | loss: 0.7245635986328125 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.19\n",
      "step : 4695 | loss: 0.7614642381668091 | dt: 154.18 ms | tokens/sec: 39.85 | norm: 2.36\n",
      "step : 4696 | loss: 0.7051459550857544 | dt: 154.30 ms | tokens/sec: 39.82 | norm: 2.18\n",
      "step : 4697 | loss: 0.7750372886657715 | dt: 154.12 ms | tokens/sec: 39.87 | norm: 2.20\n",
      "step : 4698 | loss: 0.8212590217590332 | dt: 154.94 ms | tokens/sec: 39.65 | norm: 2.47\n",
      "step : 4699 | loss: 0.8700391054153442 | dt: 154.02 ms | tokens/sec: 39.89 | norm: 2.37\n",
      "step : 4700 | loss: 0.793524444103241 | dt: 153.94 ms | tokens/sec: 39.91 | norm: 2.07\n",
      "step : 4701 | loss: 0.8599714636802673 | dt: 153.87 ms | tokens/sec: 39.93 | norm: 2.31\n",
      "step : 4702 | loss: 0.8156851530075073 | dt: 154.08 ms | tokens/sec: 39.88 | norm: 3.43\n",
      "step : 4703 | loss: 0.8515903353691101 | dt: 153.77 ms | tokens/sec: 39.96 | norm: 2.29\n",
      "step : 4704 | loss: 0.9402958750724792 | dt: 154.75 ms | tokens/sec: 39.70 | norm: 2.57\n",
      "step : 4705 | loss: 0.9052202105522156 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.33\n",
      "step : 4706 | loss: 0.7838878631591797 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.25\n",
      "step : 4707 | loss: 0.813961386680603 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.22\n",
      "step : 4708 | loss: 0.8424941897392273 | dt: 154.26 ms | tokens/sec: 39.83 | norm: 2.20\n",
      "step : 4709 | loss: 0.7809543609619141 | dt: 153.94 ms | tokens/sec: 39.91 | norm: 2.20\n",
      "step : 4710 | loss: 0.7621850371360779 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.32\n",
      "step : 4711 | loss: 1.0059964656829834 | dt: 154.76 ms | tokens/sec: 39.70 | norm: 2.77\n",
      "step : 4712 | loss: 0.9581645727157593 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.40\n",
      "step : 4713 | loss: 0.9134518504142761 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.31\n",
      "step : 4714 | loss: 0.8833690881729126 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.36\n",
      "step : 4715 | loss: 0.8416938781738281 | dt: 154.42 ms | tokens/sec: 39.79 | norm: 2.44\n",
      "step : 4716 | loss: 0.8659214973449707 | dt: 154.23 ms | tokens/sec: 39.84 | norm: 2.36\n",
      "step : 4717 | loss: 0.8325909376144409 | dt: 154.70 ms | tokens/sec: 39.72 | norm: 2.39\n",
      "step : 4718 | loss: 0.8564807176589966 | dt: 154.23 ms | tokens/sec: 39.84 | norm: 2.32\n",
      "step : 4719 | loss: 0.8031837344169617 | dt: 154.13 ms | tokens/sec: 39.86 | norm: 2.54\n",
      "step : 4720 | loss: 0.8246011137962341 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.67\n",
      "step : 4721 | loss: 0.7185103297233582 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.40\n",
      "step : 4722 | loss: 0.8124685287475586 | dt: 154.04 ms | tokens/sec: 39.88 | norm: 2.40\n",
      "step : 4723 | loss: 0.7827998399734497 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.47\n",
      "step : 4724 | loss: 0.9543728828430176 | dt: 154.54 ms | tokens/sec: 39.76 | norm: 2.85\n",
      "step : 4725 | loss: 0.8765236735343933 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.59\n",
      "step : 4726 | loss: 0.752287745475769 | dt: 154.28 ms | tokens/sec: 39.82 | norm: 2.40\n",
      "step : 4727 | loss: 0.7792094945907593 | dt: 155.00 ms | tokens/sec: 39.64 | norm: 2.26\n",
      "step : 4728 | loss: 0.6227232217788696 | dt: 154.49 ms | tokens/sec: 39.77 | norm: 2.09\n",
      "step : 4729 | loss: 0.8313481211662292 | dt: 154.23 ms | tokens/sec: 39.84 | norm: 2.66\n",
      "step : 4730 | loss: 0.8811302185058594 | dt: 155.04 ms | tokens/sec: 39.63 | norm: 3.04\n",
      "step : 4731 | loss: 0.9367077350616455 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.59\n",
      "step : 4732 | loss: 0.9338299632072449 | dt: 153.93 ms | tokens/sec: 39.91 | norm: 2.73\n",
      "step : 4733 | loss: 0.8562941551208496 | dt: 153.83 ms | tokens/sec: 39.94 | norm: 2.32\n",
      "step : 4734 | loss: 0.7933332920074463 | dt: 154.02 ms | tokens/sec: 39.89 | norm: 2.45\n",
      "step : 4735 | loss: 0.8029537200927734 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.30\n",
      "step : 4736 | loss: 0.7536818385124207 | dt: 153.93 ms | tokens/sec: 39.91 | norm: 2.36\n",
      "step : 4737 | loss: 0.8124139308929443 | dt: 154.80 ms | tokens/sec: 39.69 | norm: 2.44\n",
      "step : 4738 | loss: 0.823725700378418 | dt: 153.94 ms | tokens/sec: 39.91 | norm: 2.64\n",
      "step : 4739 | loss: 0.853223979473114 | dt: 153.87 ms | tokens/sec: 39.93 | norm: 2.50\n",
      "step : 4740 | loss: 0.8206825256347656 | dt: 154.63 ms | tokens/sec: 39.73 | norm: 2.64\n",
      "step : 4741 | loss: 0.896992564201355 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.84\n",
      "step : 4742 | loss: 0.8832482099533081 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.90\n",
      "step : 4743 | loss: 0.7768267393112183 | dt: 154.74 ms | tokens/sec: 39.71 | norm: 2.35\n",
      "step : 4744 | loss: 0.672202467918396 | dt: 154.17 ms | tokens/sec: 39.85 | norm: 2.35\n",
      "step : 4745 | loss: 0.6876963376998901 | dt: 153.81 ms | tokens/sec: 39.95 | norm: 2.42\n",
      "step : 4746 | loss: 0.7529575228691101 | dt: 154.13 ms | tokens/sec: 39.86 | norm: 3.02\n",
      "step : 4747 | loss: 0.7817853689193726 | dt: 154.15 ms | tokens/sec: 39.86 | norm: 2.32\n",
      "step : 4748 | loss: 0.7230625152587891 | dt: 154.28 ms | tokens/sec: 39.82 | norm: 2.29\n",
      "step : 4749 | loss: 0.7032922506332397 | dt: 154.21 ms | tokens/sec: 39.84 | norm: 2.32\n",
      "step : 4750 | loss: 0.7468856573104858 | dt: 154.86 ms | tokens/sec: 39.68 | norm: 2.31\n",
      "step : 4751 | loss: 0.6921310424804688 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.16\n",
      "step : 4752 | loss: 0.7585071325302124 | dt: 153.91 ms | tokens/sec: 39.92 | norm: 2.53\n",
      "step : 4753 | loss: 0.803501307964325 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.52\n",
      "step : 4754 | loss: 0.8524988889694214 | dt: 154.17 ms | tokens/sec: 39.85 | norm: 2.65\n",
      "step : 4755 | loss: 0.772618293762207 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.21\n",
      "step : 4756 | loss: 0.8412420749664307 | dt: 154.90 ms | tokens/sec: 39.66 | norm: 2.48\n",
      "step : 4757 | loss: 0.8084901571273804 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.52\n",
      "step : 4758 | loss: 0.8257073163986206 | dt: 155.34 ms | tokens/sec: 39.55 | norm: 2.44\n",
      "step : 4759 | loss: 0.9030644297599792 | dt: 153.84 ms | tokens/sec: 39.94 | norm: 2.53\n",
      "step : 4760 | loss: 0.8674054145812988 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.42\n",
      "step : 4761 | loss: 0.7582607269287109 | dt: 153.85 ms | tokens/sec: 39.93 | norm: 2.51\n",
      "step : 4762 | loss: 0.7849342226982117 | dt: 154.82 ms | tokens/sec: 39.68 | norm: 2.38\n",
      "step : 4763 | loss: 0.8095961809158325 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.58\n",
      "step : 4764 | loss: 0.7564587593078613 | dt: 154.14 ms | tokens/sec: 39.86 | norm: 2.29\n",
      "step : 4765 | loss: 0.7361253499984741 | dt: 154.14 ms | tokens/sec: 39.86 | norm: 2.23\n",
      "step : 4766 | loss: 0.9681364893913269 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.60\n",
      "step : 4767 | loss: 0.9292976260185242 | dt: 153.81 ms | tokens/sec: 39.95 | norm: 2.46\n",
      "step : 4768 | loss: 0.8855800628662109 | dt: 154.02 ms | tokens/sec: 39.89 | norm: 2.44\n",
      "step : 4769 | loss: 0.8543237447738647 | dt: 154.71 ms | tokens/sec: 39.71 | norm: 2.33\n",
      "step : 4770 | loss: 0.8142962455749512 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 2.12\n",
      "step : 4771 | loss: 0.8282603621482849 | dt: 153.84 ms | tokens/sec: 39.94 | norm: 2.21\n",
      "step : 4772 | loss: 0.7881579399108887 | dt: 154.18 ms | tokens/sec: 39.85 | norm: 2.08\n",
      "step : 4773 | loss: 0.8221267461776733 | dt: 154.15 ms | tokens/sec: 39.86 | norm: 2.19\n",
      "step : 4774 | loss: 0.7697542905807495 | dt: 154.38 ms | tokens/sec: 39.80 | norm: 2.07\n",
      "step : 4775 | loss: 0.7772239446640015 | dt: 154.63 ms | tokens/sec: 39.73 | norm: 2.21\n",
      "step : 4776 | loss: 0.6779509782791138 | dt: 155.18 ms | tokens/sec: 39.59 | norm: 2.20\n",
      "step : 4777 | loss: 0.7794097661972046 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 2.21\n",
      "step : 4778 | loss: 0.7548624873161316 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.35\n",
      "step : 4779 | loss: 0.9265653491020203 | dt: 153.93 ms | tokens/sec: 39.91 | norm: 2.75\n",
      "step : 4780 | loss: 0.8408002257347107 | dt: 154.12 ms | tokens/sec: 39.86 | norm: 2.53\n",
      "step : 4781 | loss: 0.7207565307617188 | dt: 153.79 ms | tokens/sec: 39.95 | norm: 2.20\n",
      "step : 4782 | loss: 0.739311158657074 | dt: 154.85 ms | tokens/sec: 39.68 | norm: 2.34\n",
      "step : 4783 | loss: 0.5964653491973877 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.08\n",
      "step : 4784 | loss: 0.8118869662284851 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.42\n",
      "step : 4785 | loss: 0.8607577681541443 | dt: 154.21 ms | tokens/sec: 39.84 | norm: 2.59\n",
      "step : 4786 | loss: 0.902977466583252 | dt: 154.37 ms | tokens/sec: 39.80 | norm: 2.70\n",
      "step : 4787 | loss: 0.8902386426925659 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 2.57\n",
      "step : 4788 | loss: 0.8186056017875671 | dt: 154.79 ms | tokens/sec: 39.69 | norm: 2.58\n",
      "step : 4789 | loss: 0.7678685188293457 | dt: 153.93 ms | tokens/sec: 39.91 | norm: 2.55\n",
      "step : 4790 | loss: 0.7621983289718628 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 2.34\n",
      "step : 4791 | loss: 0.7111884355545044 | dt: 153.78 ms | tokens/sec: 39.95 | norm: 2.30\n",
      "step : 4792 | loss: 0.7690727710723877 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.43\n",
      "step : 4793 | loss: 0.7837051153182983 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.78\n",
      "step : 4794 | loss: 0.8045209646224976 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.37\n",
      "step : 4795 | loss: 0.7877654433250427 | dt: 154.79 ms | tokens/sec: 39.69 | norm: 2.54\n",
      "step : 4796 | loss: 0.8838237524032593 | dt: 154.22 ms | tokens/sec: 39.84 | norm: 2.76\n",
      "step : 4797 | loss: 0.8624038696289062 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.71\n",
      "step : 4798 | loss: 0.7482722997665405 | dt: 154.12 ms | tokens/sec: 39.86 | norm: 2.68\n",
      "step : 4799 | loss: 0.6659655570983887 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.47\n",
      "step : 4800 | loss: 0.673224151134491 | dt: 154.28 ms | tokens/sec: 39.82 | norm: 2.47\n",
      "step : 4801 | loss: 0.742924690246582 | dt: 154.61 ms | tokens/sec: 39.74 | norm: 2.84\n",
      "step : 4802 | loss: 0.7511727213859558 | dt: 154.03 ms | tokens/sec: 39.89 | norm: 2.48\n",
      "step : 4803 | loss: 0.693257212638855 | dt: 153.82 ms | tokens/sec: 39.94 | norm: 2.52\n",
      "step : 4804 | loss: 0.6685983538627625 | dt: 154.07 ms | tokens/sec: 39.88 | norm: 2.18\n",
      "step : 4805 | loss: 0.715363621711731 | dt: 153.87 ms | tokens/sec: 39.93 | norm: 2.22\n",
      "step : 4806 | loss: 0.6550403833389282 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.16\n",
      "step : 4807 | loss: 0.7231711149215698 | dt: 154.02 ms | tokens/sec: 39.89 | norm: 2.53\n",
      "step : 4808 | loss: 0.7620817422866821 | dt: 154.86 ms | tokens/sec: 39.67 | norm: 2.51\n",
      "step : 4809 | loss: 0.8104712963104248 | dt: 153.91 ms | tokens/sec: 39.92 | norm: 2.43\n",
      "step : 4810 | loss: 0.7393333315849304 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 2.06\n",
      "step : 4811 | loss: 0.8066959381103516 | dt: 154.12 ms | tokens/sec: 39.86 | norm: 2.56\n",
      "step : 4812 | loss: 0.777480959892273 | dt: 154.14 ms | tokens/sec: 39.86 | norm: 2.38\n",
      "step : 4813 | loss: 0.7953559756278992 | dt: 153.86 ms | tokens/sec: 39.93 | norm: 2.29\n",
      "step : 4814 | loss: 0.8759692907333374 | dt: 154.81 ms | tokens/sec: 39.69 | norm: 2.53\n",
      "step : 4815 | loss: 0.8371561765670776 | dt: 153.86 ms | tokens/sec: 39.93 | norm: 2.69\n",
      "step : 4816 | loss: 0.736466109752655 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.95\n",
      "step : 4817 | loss: 0.7602413892745972 | dt: 153.86 ms | tokens/sec: 39.93 | norm: 2.55\n",
      "step : 4818 | loss: 0.7903911471366882 | dt: 154.07 ms | tokens/sec: 39.88 | norm: 2.76\n",
      "step : 4819 | loss: 0.7294745445251465 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.66\n",
      "step : 4820 | loss: 0.7140392065048218 | dt: 154.13 ms | tokens/sec: 39.86 | norm: 2.51\n",
      "step : 4821 | loss: 0.9428023099899292 | dt: 154.70 ms | tokens/sec: 39.72 | norm: 2.76\n",
      "step : 4822 | loss: 0.8971579074859619 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 2.64\n",
      "step : 4823 | loss: 0.8398818969726562 | dt: 153.89 ms | tokens/sec: 39.92 | norm: 2.56\n",
      "step : 4824 | loss: 0.8102049231529236 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.27\n",
      "step : 4825 | loss: 0.7734024524688721 | dt: 154.22 ms | tokens/sec: 39.84 | norm: 2.36\n",
      "step : 4826 | loss: 0.7844566106796265 | dt: 154.38 ms | tokens/sec: 39.80 | norm: 2.20\n",
      "step : 4827 | loss: 0.7536020278930664 | dt: 154.83 ms | tokens/sec: 39.68 | norm: 2.28\n",
      "step : 4828 | loss: 0.7846879959106445 | dt: 154.14 ms | tokens/sec: 39.86 | norm: 2.39\n",
      "step : 4829 | loss: 0.7348224520683289 | dt: 153.93 ms | tokens/sec: 39.91 | norm: 2.21\n",
      "step : 4830 | loss: 0.749121904373169 | dt: 154.09 ms | tokens/sec: 39.87 | norm: 2.41\n",
      "step : 4831 | loss: 0.6495813727378845 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.21\n",
      "step : 4832 | loss: 0.7454940676689148 | dt: 154.09 ms | tokens/sec: 39.87 | norm: 2.24\n",
      "step : 4833 | loss: 0.7272182703018188 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.34\n",
      "step : 4834 | loss: 0.9008145332336426 | dt: 154.86 ms | tokens/sec: 39.67 | norm: 2.79\n",
      "step : 4835 | loss: 0.8140841722488403 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.43\n",
      "step : 4836 | loss: 0.6921566724777222 | dt: 153.85 ms | tokens/sec: 39.94 | norm: 2.26\n",
      "step : 4837 | loss: 0.7115437388420105 | dt: 153.72 ms | tokens/sec: 39.97 | norm: 2.26\n",
      "step : 4838 | loss: 0.5706467628479004 | dt: 153.86 ms | tokens/sec: 39.93 | norm: 2.19\n",
      "step : 4839 | loss: 0.7736862897872925 | dt: 153.85 ms | tokens/sec: 39.93 | norm: 2.56\n",
      "step : 4840 | loss: 0.8252140879631042 | dt: 154.70 ms | tokens/sec: 39.72 | norm: 2.52\n",
      "step : 4841 | loss: 0.8568339347839355 | dt: 153.91 ms | tokens/sec: 39.92 | norm: 2.52\n",
      "step : 4842 | loss: 0.8407182693481445 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 2.61\n",
      "step : 4843 | loss: 0.7776307463645935 | dt: 153.70 ms | tokens/sec: 39.97 | norm: 2.47\n",
      "step : 4844 | loss: 0.7298910617828369 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.43\n",
      "step : 4845 | loss: 0.7317357063293457 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.40\n",
      "step : 4846 | loss: 0.6868039965629578 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.44\n",
      "step : 4847 | loss: 0.743492603302002 | dt: 154.68 ms | tokens/sec: 39.72 | norm: 2.47\n",
      "step : 4848 | loss: 0.7562588453292847 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.33\n",
      "step : 4849 | loss: 0.7735124826431274 | dt: 154.01 ms | tokens/sec: 39.89 | norm: 2.38\n",
      "step : 4850 | loss: 0.7418856024742126 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.31\n",
      "step : 4851 | loss: 0.8292127847671509 | dt: 153.82 ms | tokens/sec: 39.94 | norm: 2.34\n",
      "step : 4852 | loss: 0.8192182779312134 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 2.51\n",
      "step : 4853 | loss: 0.7039531469345093 | dt: 154.65 ms | tokens/sec: 39.73 | norm: 2.34\n",
      "step : 4854 | loss: 0.6113666296005249 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.00\n",
      "step : 4855 | loss: 0.6202964186668396 | dt: 153.87 ms | tokens/sec: 39.93 | norm: 2.20\n",
      "step : 4856 | loss: 0.6977871656417847 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 3.14\n",
      "step : 4857 | loss: 0.7063593864440918 | dt: 154.03 ms | tokens/sec: 39.89 | norm: 2.34\n",
      "step : 4858 | loss: 0.6536924242973328 | dt: 154.40 ms | tokens/sec: 39.79 | norm: 2.56\n",
      "step : 4859 | loss: 0.6360865831375122 | dt: 154.27 ms | tokens/sec: 39.83 | norm: 2.36\n",
      "step : 4860 | loss: 0.6789548397064209 | dt: 155.02 ms | tokens/sec: 39.63 | norm: 2.24\n",
      "step : 4861 | loss: 0.6311134099960327 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.24\n",
      "step : 4862 | loss: 0.7038421630859375 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.36\n",
      "step : 4863 | loss: 0.7541772723197937 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.47\n",
      "step : 4864 | loss: 0.7926483154296875 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.71\n",
      "step : 4865 | loss: 0.7206387519836426 | dt: 153.82 ms | tokens/sec: 39.94 | norm: 2.45\n",
      "step : 4866 | loss: 0.7853075861930847 | dt: 154.74 ms | tokens/sec: 39.70 | norm: 2.65\n",
      "step : 4867 | loss: 0.7535704374313354 | dt: 153.81 ms | tokens/sec: 39.94 | norm: 2.47\n",
      "step : 4868 | loss: 0.7640347480773926 | dt: 153.91 ms | tokens/sec: 39.92 | norm: 2.34\n",
      "step : 4869 | loss: 0.8427660465240479 | dt: 153.83 ms | tokens/sec: 39.94 | norm: 2.53\n",
      "step : 4870 | loss: 0.8022621870040894 | dt: 154.15 ms | tokens/sec: 39.86 | norm: 2.57\n",
      "step : 4871 | loss: 0.7097909450531006 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.69\n",
      "step : 4872 | loss: 0.7294806241989136 | dt: 154.37 ms | tokens/sec: 39.80 | norm: 2.58\n",
      "step : 4873 | loss: 0.7526049613952637 | dt: 154.76 ms | tokens/sec: 39.70 | norm: 2.59\n",
      "step : 4874 | loss: 0.6981387138366699 | dt: 154.17 ms | tokens/sec: 39.85 | norm: 2.50\n",
      "step : 4875 | loss: 0.6804455518722534 | dt: 153.85 ms | tokens/sec: 39.94 | norm: 2.46\n",
      "step : 4876 | loss: 0.9010242223739624 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.89\n",
      "step : 4877 | loss: 0.8589217066764832 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.83\n",
      "step : 4878 | loss: 0.8066972494125366 | dt: 153.91 ms | tokens/sec: 39.92 | norm: 2.71\n",
      "step : 4879 | loss: 0.7753099203109741 | dt: 154.65 ms | tokens/sec: 39.73 | norm: 2.37\n",
      "step : 4880 | loss: 0.7434906959533691 | dt: 154.16 ms | tokens/sec: 39.86 | norm: 2.57\n",
      "step : 4881 | loss: 0.7529465556144714 | dt: 153.80 ms | tokens/sec: 39.95 | norm: 2.50\n",
      "step : 4882 | loss: 0.7350715398788452 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.49\n",
      "step : 4883 | loss: 0.7616218328475952 | dt: 154.20 ms | tokens/sec: 39.84 | norm: 2.37\n",
      "step : 4884 | loss: 0.7096037864685059 | dt: 154.45 ms | tokens/sec: 39.78 | norm: 2.15\n",
      "step : 4885 | loss: 0.7255188226699829 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.34\n",
      "step : 4886 | loss: 0.6203874349594116 | dt: 154.70 ms | tokens/sec: 39.72 | norm: 2.30\n",
      "step : 4887 | loss: 0.7141380310058594 | dt: 153.93 ms | tokens/sec: 39.91 | norm: 2.24\n",
      "step : 4888 | loss: 0.6936804056167603 | dt: 154.09 ms | tokens/sec: 39.87 | norm: 2.20\n",
      "step : 4889 | loss: 0.8606971502304077 | dt: 153.81 ms | tokens/sec: 39.94 | norm: 2.60\n",
      "step : 4890 | loss: 0.7735716700553894 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.55\n",
      "step : 4891 | loss: 0.66371089220047 | dt: 153.80 ms | tokens/sec: 39.95 | norm: 2.30\n",
      "step : 4892 | loss: 0.6870274543762207 | dt: 154.69 ms | tokens/sec: 39.72 | norm: 2.24\n",
      "step : 4893 | loss: 0.5513091087341309 | dt: 154.04 ms | tokens/sec: 39.89 | norm: 2.07\n",
      "step : 4894 | loss: 0.7539659738540649 | dt: 154.02 ms | tokens/sec: 39.89 | norm: 2.52\n",
      "step : 4895 | loss: 0.8020739555358887 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.65\n",
      "step : 4896 | loss: 0.835119903087616 | dt: 154.32 ms | tokens/sec: 39.81 | norm: 2.50\n",
      "step : 4897 | loss: 0.8280806541442871 | dt: 154.13 ms | tokens/sec: 39.86 | norm: 2.77\n",
      "step : 4898 | loss: 0.7612177133560181 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.48\n",
      "step : 4899 | loss: 0.7080134153366089 | dt: 154.64 ms | tokens/sec: 39.73 | norm: 2.54\n",
      "step : 4900 | loss: 0.6971291303634644 | dt: 154.12 ms | tokens/sec: 39.87 | norm: 2.30\n",
      "step : 4901 | loss: 0.6510547995567322 | dt: 153.91 ms | tokens/sec: 39.92 | norm: 2.12\n",
      "step : 4902 | loss: 0.7083950042724609 | dt: 153.86 ms | tokens/sec: 39.93 | norm: 2.38\n",
      "step : 4903 | loss: 0.709944486618042 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.23\n",
      "step : 4904 | loss: 0.7229127883911133 | dt: 154.00 ms | tokens/sec: 39.90 | norm: 2.16\n",
      "step : 4905 | loss: 0.6962213516235352 | dt: 155.03 ms | tokens/sec: 39.63 | norm: 2.37\n",
      "step : 4906 | loss: 0.7746736407279968 | dt: 154.14 ms | tokens/sec: 39.86 | norm: 2.36\n",
      "step : 4907 | loss: 0.767536997795105 | dt: 153.80 ms | tokens/sec: 39.95 | norm: 2.51\n",
      "step : 4908 | loss: 0.6645002365112305 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.10\n",
      "step : 4909 | loss: 0.5767991542816162 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.11\n",
      "step : 4910 | loss: 0.5990755558013916 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.22\n",
      "step : 4911 | loss: 0.6660705208778381 | dt: 153.91 ms | tokens/sec: 39.92 | norm: 2.50\n",
      "step : 4912 | loss: 0.6694563627243042 | dt: 154.61 ms | tokens/sec: 39.74 | norm: 2.26\n",
      "step : 4913 | loss: 0.6226270794868469 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.23\n",
      "step : 4914 | loss: 0.6027519702911377 | dt: 153.85 ms | tokens/sec: 39.93 | norm: 2.16\n",
      "step : 4915 | loss: 0.6532547473907471 | dt: 154.07 ms | tokens/sec: 39.88 | norm: 2.29\n",
      "step : 4916 | loss: 0.5936319828033447 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.17\n",
      "step : 4917 | loss: 0.6728417873382568 | dt: 154.15 ms | tokens/sec: 39.86 | norm: 2.54\n",
      "step : 4918 | loss: 0.711950957775116 | dt: 154.94 ms | tokens/sec: 39.65 | norm: 2.49\n",
      "step : 4919 | loss: 0.7711472511291504 | dt: 153.85 ms | tokens/sec: 39.94 | norm: 2.43\n",
      "step : 4920 | loss: 0.6905717253684998 | dt: 153.89 ms | tokens/sec: 39.92 | norm: 2.15\n",
      "step : 4921 | loss: 0.7545339465141296 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.31\n",
      "step : 4922 | loss: 0.7199539542198181 | dt: 154.31 ms | tokens/sec: 39.81 | norm: 2.60\n",
      "step : 4923 | loss: 0.7271851301193237 | dt: 153.84 ms | tokens/sec: 39.94 | norm: 2.43\n",
      "step : 4924 | loss: 0.8119667768478394 | dt: 153.98 ms | tokens/sec: 39.90 | norm: 2.49\n",
      "step : 4925 | loss: 0.7750722765922546 | dt: 154.69 ms | tokens/sec: 39.72 | norm: 2.60\n",
      "step : 4926 | loss: 0.6819430589675903 | dt: 154.03 ms | tokens/sec: 39.89 | norm: 2.43\n",
      "step : 4927 | loss: 0.7057605981826782 | dt: 153.87 ms | tokens/sec: 39.93 | norm: 2.32\n",
      "step : 4928 | loss: 0.7268244624137878 | dt: 154.27 ms | tokens/sec: 39.83 | norm: 2.41\n",
      "step : 4929 | loss: 0.6699705123901367 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.78\n",
      "step : 4930 | loss: 0.6483026742935181 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.50\n",
      "step : 4931 | loss: 0.8752113580703735 | dt: 154.70 ms | tokens/sec: 39.72 | norm: 2.79\n",
      "step : 4932 | loss: 0.832000732421875 | dt: 154.05 ms | tokens/sec: 39.88 | norm: 2.97\n",
      "step : 4933 | loss: 0.779392421245575 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.70\n",
      "step : 4934 | loss: 0.7457417249679565 | dt: 153.93 ms | tokens/sec: 39.91 | norm: 2.42\n",
      "step : 4935 | loss: 0.7212753295898438 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.62\n",
      "step : 4936 | loss: 0.7256388664245605 | dt: 153.93 ms | tokens/sec: 39.92 | norm: 2.55\n",
      "step : 4937 | loss: 0.705574631690979 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.48\n",
      "step : 4938 | loss: 0.737693727016449 | dt: 154.85 ms | tokens/sec: 39.68 | norm: 2.49\n",
      "step : 4939 | loss: 0.6822690963745117 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.23\n",
      "step : 4940 | loss: 0.6932618618011475 | dt: 153.89 ms | tokens/sec: 39.92 | norm: 2.73\n",
      "step : 4941 | loss: 0.6014404296875 | dt: 154.00 ms | tokens/sec: 39.89 | norm: 2.38\n",
      "step : 4942 | loss: 0.6905485987663269 | dt: 154.17 ms | tokens/sec: 39.85 | norm: 2.31\n",
      "step : 4943 | loss: 0.663861095905304 | dt: 153.95 ms | tokens/sec: 39.91 | norm: 2.37\n",
      "step : 4944 | loss: 0.8303570747375488 | dt: 154.64 ms | tokens/sec: 39.73 | norm: 2.70\n",
      "step : 4945 | loss: 0.7460026144981384 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.56\n",
      "step : 4946 | loss: 0.6365751028060913 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.14\n",
      "step : 4947 | loss: 0.6552459001541138 | dt: 153.84 ms | tokens/sec: 39.94 | norm: 2.26\n",
      "step : 4948 | loss: 0.5256586074829102 | dt: 154.12 ms | tokens/sec: 39.87 | norm: 2.13\n",
      "step : 4949 | loss: 0.7223129272460938 | dt: 153.91 ms | tokens/sec: 39.92 | norm: 2.67\n",
      "step : 4950 | loss: 0.7755534648895264 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.72\n",
      "step : 4951 | loss: 0.8071774244308472 | dt: 154.76 ms | tokens/sec: 39.70 | norm: 2.87\n",
      "step : 4952 | loss: 0.8020934462547302 | dt: 153.94 ms | tokens/sec: 39.91 | norm: 2.90\n",
      "step : 4953 | loss: 0.7283656001091003 | dt: 153.89 ms | tokens/sec: 39.92 | norm: 2.61\n",
      "step : 4954 | loss: 0.6878107786178589 | dt: 153.91 ms | tokens/sec: 39.92 | norm: 2.62\n",
      "step : 4955 | loss: 0.672376811504364 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.39\n",
      "step : 4956 | loss: 0.635071873664856 | dt: 153.96 ms | tokens/sec: 39.91 | norm: 2.47\n",
      "step : 4957 | loss: 0.6777679324150085 | dt: 154.66 ms | tokens/sec: 39.73 | norm: 2.36\n",
      "step : 4958 | loss: 0.6907281875610352 | dt: 154.21 ms | tokens/sec: 39.84 | norm: 2.59\n",
      "step : 4959 | loss: 0.707805871963501 | dt: 153.89 ms | tokens/sec: 39.92 | norm: 2.32\n",
      "step : 4960 | loss: 0.6814185976982117 | dt: 154.19 ms | tokens/sec: 39.85 | norm: 2.26\n",
      "step : 4961 | loss: 0.7620352506637573 | dt: 153.97 ms | tokens/sec: 39.90 | norm: 2.32\n",
      "step : 4962 | loss: 0.7532650828361511 | dt: 154.14 ms | tokens/sec: 39.86 | norm: 2.82\n",
      "step : 4963 | loss: 0.6400637626647949 | dt: 154.08 ms | tokens/sec: 39.88 | norm: 2.22\n",
      "step : 4964 | loss: 0.555989146232605 | dt: 154.59 ms | tokens/sec: 39.74 | norm: 2.17\n",
      "step : 4965 | loss: 0.5689138174057007 | dt: 153.82 ms | tokens/sec: 39.94 | norm: 2.28\n",
      "step : 4966 | loss: 0.6292828917503357 | dt: 153.94 ms | tokens/sec: 39.91 | norm: 2.43\n",
      "step : 4967 | loss: 0.6399270296096802 | dt: 154.07 ms | tokens/sec: 39.88 | norm: 2.25\n",
      "step : 4968 | loss: 0.5988539457321167 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.43\n",
      "step : 4969 | loss: 0.567155659198761 | dt: 153.86 ms | tokens/sec: 39.93 | norm: 2.10\n",
      "step : 4970 | loss: 0.6221921443939209 | dt: 155.03 ms | tokens/sec: 39.63 | norm: 2.26\n",
      "step : 4971 | loss: 0.5772395133972168 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.63\n",
      "step : 4972 | loss: 0.653976321220398 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.68\n",
      "step : 4973 | loss: 0.6874210238456726 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.52\n",
      "step : 4974 | loss: 0.7473667860031128 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.54\n",
      "step : 4975 | loss: 0.6669771075248718 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.18\n",
      "step : 4976 | loss: 0.7296060919761658 | dt: 154.13 ms | tokens/sec: 39.86 | norm: 2.54\n",
      "step : 4977 | loss: 0.6968077421188354 | dt: 154.50 ms | tokens/sec: 39.77 | norm: 2.35\n",
      "step : 4978 | loss: 0.7095409631729126 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.55\n",
      "step : 4979 | loss: 0.784742534160614 | dt: 153.83 ms | tokens/sec: 39.94 | norm: 2.41\n",
      "step : 4980 | loss: 0.7536271810531616 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.68\n",
      "step : 4981 | loss: 0.6589382886886597 | dt: 153.78 ms | tokens/sec: 39.95 | norm: 2.37\n",
      "step : 4982 | loss: 0.6715074777603149 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.27\n",
      "step : 4983 | loss: 0.6946200132369995 | dt: 154.62 ms | tokens/sec: 39.74 | norm: 2.28\n",
      "step : 4984 | loss: 0.6362450122833252 | dt: 154.10 ms | tokens/sec: 39.87 | norm: 2.33\n",
      "step : 4985 | loss: 0.6210142374038696 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.22\n",
      "step : 4986 | loss: 0.8334760665893555 | dt: 153.92 ms | tokens/sec: 39.92 | norm: 2.78\n",
      "step : 4987 | loss: 0.7923305034637451 | dt: 153.88 ms | tokens/sec: 39.93 | norm: 2.83\n",
      "step : 4988 | loss: 0.7394313216209412 | dt: 154.11 ms | tokens/sec: 39.87 | norm: 2.50\n",
      "step : 4989 | loss: 0.7175101637840271 | dt: 154.68 ms | tokens/sec: 39.72 | norm: 2.42\n",
      "step : 4990 | loss: 0.6974479556083679 | dt: 154.24 ms | tokens/sec: 39.83 | norm: 2.64\n",
      "step : 4991 | loss: 0.7054398059844971 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.72\n",
      "step : 4992 | loss: 0.6896421313285828 | dt: 154.06 ms | tokens/sec: 39.88 | norm: 2.55\n",
      "step : 4993 | loss: 0.7300688624382019 | dt: 153.81 ms | tokens/sec: 39.94 | norm: 2.61\n",
      "step : 4994 | loss: 0.668886661529541 | dt: 153.99 ms | tokens/sec: 39.90 | norm: 2.37\n",
      "step : 4995 | loss: 0.6853994727134705 | dt: 153.76 ms | tokens/sec: 39.96 | norm: 2.41\n",
      "step : 4996 | loss: 0.5835204124450684 | dt: 154.82 ms | tokens/sec: 39.69 | norm: 2.50\n",
      "step : 4997 | loss: 0.6700631976127625 | dt: 153.93 ms | tokens/sec: 39.91 | norm: 2.46\n",
      "step : 4998 | loss: 0.6492064595222473 | dt: 154.34 ms | tokens/sec: 39.81 | norm: 2.37\n",
      "step : 4999 | loss: 0.8070663213729858 | dt: 153.90 ms | tokens/sec: 39.92 | norm: 2.94\n",
      "step : 5000 | loss: 0.7277253866195679 | dt: 154.15 ms | tokens/sec: 39.86 | norm: 2.61\n",
      "step : 5001 | loss: 0.6168433427810669 | dt: 153.91 ms | tokens/sec: 39.92 | norm: 2.50\n"
     ]
    }
   ],
   "source": [
    "start= time.time()\n",
    "for i in range(max_steps):\n",
    "    t0 = time.time()\n",
    "    x, y = train_loader.next_batch()\n",
    "    x, y = x.to(device=device), y.to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "        logits, loss = model(x, y)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    # grad clip\n",
    "    norm = torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n",
    "\n",
    "    lr = get_lr(i)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr \n",
    "\n",
    "    optimizer.step()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    t1 = time.time() \n",
    "    dt = (t1 - t0) * 1000\n",
    "    tokens_per_sec = (train_loader.B * train_loader.T) / (dt)\n",
    "    \n",
    "    # print happens via CPU, hence wait (synchronize GPU)\n",
    "    print(f'step : {i+1} | loss: {loss.item()} | dt: {dt:.2f} ms | tokens/sec: {tokens_per_sec:.2f} | norm: {norm:.2f}')\n",
    "    \n",
    "\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loss:  tensor(0.6168, device='cuda:0', grad_fn=<CompiledFunctionBackward>)\n",
      "total time: 842.1233501434326 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"final loss: \", loss)\n",
    "print(f\"total time: {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"5k-run.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
