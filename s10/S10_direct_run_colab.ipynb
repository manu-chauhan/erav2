{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aMIimxGGLcwa"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s18qOrYNmklj",
        "outputId": "ff2f2531-d0f3-4b65-caed-7a43bfef0325"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ERAV2'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 35 (delta 12), reused 27 (delta 7), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (35/35), 791.71 KiB | 2.81 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/MANU-CHAUHAN/ERAV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jaj2bCWRm08y",
        "outputId": "037ea6a0-5ffa-4f7a-d278-69e547465d3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ERAV2/s10\n"
          ]
        }
      ],
      "source": [
        "cd ERAV2/s10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmklCZ6um3gE",
        "outputId": "93810705-8582-4a23-cee4-494d98e64b3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main.py    README.md         S10_Custom_ResNet_1.ipynb  utils.py\n",
            "models.py  requirements.txt  S10_Custom_ResNet_2.ipynb\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2W_yjPzCnGp0",
        "outputId": "259b84f4-1194-4fba-8e66-40d79df8ca50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-05 17:53:09.587832: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-05 17:53:09.587893: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-05 17:53:09.589238: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-05 17:53:10.729923: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "All requirements installed successfully.\n",
            "usage: main.py [-h] [--lr LR] [--dataset DATASET] [--model MODEL] [--epochs EPOCHS]\n",
            "               [--lr_scheduler LR_SCHEDULER] [--gamma GAMMA] [--step_size STEP_SIZE]\n",
            "               [--optim OPTIM] [--save SAVE] [--max_lr MAX_LR] [--start_lr START_LR]\n",
            "               [--batch BATCH] [--pct_start PCT_START] [--cutout_prob CUTOUT_PROB]\n",
            "               [--anneal_fn ANNEAL_FN] [--cri CRI] [--find_lr FIND_LR]\n",
            "               [--find_lr_iter FIND_LR_ITER] [--Help]\n",
            "\n",
            "Training Deep Learning program for various models with multiple options.\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --lr LR               Learning rate to set for the model (default: 0.001)\n",
            "  --dataset DATASET     The dataset to use. (default: None)\n",
            "  --model MODEL         The model to use for training. (default: None)\n",
            "  --epochs EPOCHS       Number of epochs to run the training for. (default: 1)\n",
            "  --lr_scheduler LR_SCHEDULER\n",
            "                        Type of Learning Rate scheduler to use. Available options: 1. `StepLR` 2.\n",
            "                        `OneCycleLR` (default: OneCycleLR)\n",
            "  --gamma GAMMA         The `gamma` value to use for the LR scheduler. (default: 0.9)\n",
            "  --step_size STEP_SIZE\n",
            "                        Step Size for the LR scheduler to change LR = LR * gamma after the step\n",
            "                        size. (default: 1)\n",
            "  --optim OPTIM         Optimizer to select (sgd or adam) (default: sgd)\n",
            "  --save SAVE           To save the model or not after training. (default: False)\n",
            "  --max_lr MAX_LR       The maximum LR to be used with the One Cycle LR Scheduler. (default: 10)\n",
            "  --start_lr START_LR   The start LR to be used with the One Cycle LR Scheduler for the Optimizer.\n",
            "                        (default: 0.001)\n",
            "  --batch BATCH         The batch size for the dataloader. (default: 32)\n",
            "  --pct_start PCT_START\n",
            "                        The end of the warm-up phase and the peak or max LR epoch as a float value\n",
            "                        out of the total epochs. (default: 0.2)\n",
            "  --cutout_prob CUTOUT_PROB\n",
            "                        The probability to apply cutout in Transforms part, [0,1] float. (default:\n",
            "                        0.2)\n",
            "  --anneal_fn ANNEAL_FN\n",
            "                        Annealing function to use (Linear or Cosine) (default: linear)\n",
            "  --cri CRI             Criterion to be used (nll or crossentropy) (default: crossentropy)\n",
            "  --find_lr FIND_LR     To run LR Finder (These are needed: model, criterion, start_lr, max_lr,\n",
            "                        train_loader, optimizer, *, optimizer_type=`adam`, weight_decay=4e-4,\n",
            "                        num_iterations=300, log_lr=True, step_mode=`exp`) (default: False)\n",
            "  --find_lr_iter FIND_LR_ITER\n",
            "                        The number of iterations to use in LR finder. (default: 200)\n",
            "  --Help                Available arguments: 1. `--lr`: Learning rate, default 0.001 2.\n",
            "                        `--dataset`: Selecting the dataset, available options MNIST and CIFAR10 3.\n",
            "                        `--model`: Model name, check models.py 4. `--epochs`: Setting the number\n",
            "                        of epochs, default 1. 5. `--lr-scheduler`: Selecting which learning rate\n",
            "                        scheduler to use Available options: 1. `steplr` 2. `cycliclr` 6.\n",
            "                        `--gamma`: Gamma value to be used between 0 and 1.0 7. `--step_size`:\n",
            "                        Number of steps after which to change LR in the scheduler 8. `--optim`:\n",
            "                        Type of optimizer to use: 1. SGD 2. Adam 9. `--save`: If to save the model\n",
            "                        or not (true or false) 10. `--max-lr`: If cyclic policy is used, the\n",
            "                        maximum learning rate to be used. 11. `--batch`: The batch size for the\n",
            "                        dataloader. 12. `--pct_start`: The end of the warm-up phase and peak or\n",
            "                        max LR epoch as a float value out of total epochs. 13. `--anneal_fn`:\n",
            "                        Annealing function to decrease LR in the cool-down phase of the LR\n",
            "                        scheduler\n"
          ]
        }
      ],
      "source": [
        "!python main.py --help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Gn-94Tom464",
        "outputId": "73bd812e-6629-4823-a344-29b2fe090f40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-05 18:36:58.994695: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-05 18:36:58.994748: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-05 18:36:58.996181: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-05 18:37:00.236797: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "All requirements installed successfully.\n",
            "\n",
            "=========================================\n",
            "Device: cuda\n",
            "Files already downloaded and verified\n",
            "\n",
            "\n",
            "‚è≥ Computing mean and standard deviation...\n",
            "\n",
            "Done ‚úÖ\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "=========================================\n",
            "Device: cuda\n",
            "\n",
            "\n",
            "Running LR finder... üîçüëÄ \n",
            "Start LR: 0.001, End LR: 10.0, iterations: 400, step mode: exp\n",
            "\n",
            "\n",
            "=========================================\n",
            "Device: cuda\n",
            " 68% 271/400 [00:05<00:02, 57.93it/s]Stopping early, the loss has diverged\n",
            " 69% 276/400 [00:05<00:02, 46.51it/s]\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n",
            "LR suggestion: steepest gradient\n",
            "Suggested LR: 3.75E-02\n",
            "Figure(640x480)\n"
          ]
        }
      ],
      "source": [
        "!python main.py --dataset cifar10 --model s10resnet --optim adam --cri crossentropy --find_lr True --start_lr 0.001 --find_lr_iter 400 --max_lr 10 --cutout_prob 0.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx3YS2YunV32",
        "outputId": "f27bd8e4-08fa-4792-f850-c9cdf3dd20a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-05 18:38:04.923342: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-05 18:38:04.923395: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-05 18:38:04.924698: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-05 18:38:06.620770: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "All requirements installed successfully.\n",
            "\n",
            "=========================================\n",
            "Device: cuda\n",
            "Files already downloaded and verified\n",
            "\n",
            "\n",
            "‚è≥ Computing mean and standard deviation...\n",
            "\n",
            "Done ‚úÖ\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "=========================================\n",
            "Device: cuda\n",
            "torch.Size([512, 3, 32, 32])\n",
            "torch.Size([512])\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Figure(1500x1500)\n",
            "\n",
            "‚û§ Training started...‚Üí\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 1  |  LR: 0.0037500000\n",
            "Loss=1.5019639730453491 Accuracy=40.47: 100% 98/98 [00:29<00:00,  3.37it/s]\n",
            "\n",
            "Test set: Average loss: 0.00269, Accuracy: 5369/10000 (53.690%)\n",
            "\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 2  |  LR: 0.0122090793\n",
            "Loss=0.9663465619087219 Accuracy=60.00: 100% 98/98 [00:18<00:00,  5.22it/s]\n",
            "\n",
            "Test set: Average loss: 0.00205, Accuracy: 6649/10000 (66.490%)\n",
            "\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 3  |  LR: 0.0206681586\n",
            "Loss=0.8239324688911438 Accuracy=68.52: 100% 98/98 [00:18<00:00,  5.26it/s]\n",
            "\n",
            "Test set: Average loss: 0.00233, Accuracy: 6629/10000 (66.290%)\n",
            "\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 4  |  LR: 0.0291272379\n",
            "Loss=0.8930802941322327 Accuracy=69.84: 100% 98/98 [00:19<00:00,  5.07it/s]\n",
            "\n",
            "Test set: Average loss: 0.00174, Accuracy: 7311/10000 (73.110%)\n",
            "\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 5  |  LR: 0.0374808865\n",
            "Loss=0.594973623752594 Accuracy=77.73: 100% 98/98 [00:18<00:00,  5.16it/s]\n",
            "\n",
            "Test set: Average loss: 0.00135, Accuracy: 7816/10000 (78.160%)\n",
            "\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 6  |  LR: 0.0356077615\n",
            "Loss=0.41586747765541077 Accuracy=81.28: 100% 98/98 [00:18<00:00,  5.23it/s]\n",
            "\n",
            "Test set: Average loss: 0.00122, Accuracy: 8106/10000 (81.060%)\n",
            "\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 7  |  LR: 0.0337346365\n",
            "Loss=0.5764670372009277 Accuracy=82.97: 100% 98/98 [00:19<00:00,  5.04it/s]\n",
            "\n",
            "Test set: Average loss: 0.00110, Accuracy: 8260/10000 (82.600%)\n",
            "\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 8  |  LR: 0.0318615115\n",
            "Loss=0.37910693883895874 Accuracy=84.95: 100% 98/98 [00:18<00:00,  5.18it/s]\n",
            "\n",
            "Test set: Average loss: 0.00093, Accuracy: 8502/10000 (85.020%)\n",
            "\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 9  |  LR: 0.0299883865\n",
            "Loss=0.3730149567127228 Accuracy=86.30: 100% 98/98 [00:18<00:00,  5.21it/s]\n",
            "\n",
            "Test set: Average loss: 0.00103, Accuracy: 8402/10000 (84.020%)\n",
            "\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 10  |  LR: 0.0281152615\n",
            "Loss=0.33634743094444275 Accuracy=87.59: 100% 98/98 [00:19<00:00,  5.09it/s]\n",
            "\n",
            "Test set: Average loss: 0.00089, Accuracy: 8639/10000 (86.390%)\n",
            "\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 11  |  LR: 0.0262421365\n",
            "Loss=0.4180854558944702 Accuracy=88.47: 100% 98/98 [00:19<00:00,  5.11it/s]\n",
            "\n",
            "Test set: Average loss: 0.00081, Accuracy: 8749/10000 (87.490%)\n",
            "\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 12  |  LR: 0.0243690115\n",
            "Loss=0.22387650609016418 Accuracy=89.80: 100% 98/98 [00:18<00:00,  5.22it/s]\n",
            "\n",
            "Test set: Average loss: 0.00076, Accuracy: 8798/10000 (87.980%)\n",
            "\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 13  |  LR: 0.0224958865\n",
            "Loss=0.2804417908191681 Accuracy=90.83: 100% 98/98 [00:19<00:00,  5.02it/s]\n",
            "\n",
            "Test set: Average loss: 0.00072, Accuracy: 8812/10000 (88.120%)\n",
            "\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 14  |  LR: 0.0206227615\n",
            "Loss=0.2208472490310669 Accuracy=91.85: 100% 98/98 [00:19<00:00,  5.11it/s]\n",
            "\n",
            "Test set: Average loss: 0.00082, Accuracy: 8750/10000 (87.500%)\n",
            "\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 15  |  LR: 0.0187496365\n",
            "Loss=0.2460627257823944 Accuracy=92.25: 100% 98/98 [00:18<00:00,  5.22it/s]\n",
            "\n",
            "Test set: Average loss: 0.00072, Accuracy: 8912/10000 (89.120%)\n",
            "\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 16  |  LR: 0.0168765115\n",
            "Loss=0.21108175814151764 Accuracy=92.77: 100% 98/98 [00:19<00:00,  5.09it/s]\n",
            "\n",
            "Test set: Average loss: 0.00074, Accuracy: 8886/10000 (88.860%)\n",
            "\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 17  |  LR: 0.0150033865\n",
            "Loss=0.18077008426189423 Accuracy=93.74: 100% 98/98 [00:19<00:00,  5.12it/s]\n",
            "\n",
            "Test set: Average loss: 0.00073, Accuracy: 8897/10000 (88.970%)\n",
            "\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 18  |  LR: 0.0131302615\n",
            "Loss=0.16855446994304657 Accuracy=94.48: 100% 98/98 [00:18<00:00,  5.20it/s]\n",
            "\n",
            "Test set: Average loss: 0.00065, Accuracy: 9016/10000 (90.160%)\n",
            "\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 19  |  LR: 0.0112571365\n",
            "Loss=0.1439722776412964 Accuracy=95.19: 100% 98/98 [00:19<00:00,  5.13it/s]\n",
            "\n",
            "Test set: Average loss: 0.00069, Accuracy: 8965/10000 (89.650%)\n",
            "\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 20  |  LR: 0.0093840115\n",
            "Loss=0.08929401636123657 Accuracy=95.65: 100% 98/98 [00:19<00:00,  5.07it/s]\n",
            "\n",
            "Test set: Average loss: 0.00065, Accuracy: 9023/10000 (90.230%)\n",
            "\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 21  |  LR: 0.0075108865\n",
            "Loss=0.09441486746072769 Accuracy=95.93: 100% 98/98 [00:18<00:00,  5.21it/s]\n",
            "\n",
            "Test set: Average loss: 0.00065, Accuracy: 9061/10000 (90.610%)\n",
            "\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 22  |  LR: 0.0056377615\n",
            "Loss=0.06803592294454575 Accuracy=96.59: 100% 98/98 [00:18<00:00,  5.18it/s]\n",
            "\n",
            "Test set: Average loss: 0.00062, Accuracy: 9095/10000 (90.950%)\n",
            "\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 23  |  LR: 0.0037646365\n",
            "Loss=0.06655067205429077 Accuracy=97.24: 100% 98/98 [00:19<00:00,  5.11it/s]\n",
            "\n",
            "Test set: Average loss: 0.00062, Accuracy: 9117/10000 (91.170%)\n",
            "\n",
            "  0% 0/98 [00:00<?, ?it/s]\n",
            "Epoch num: 24  |  LR: 0.0018915115\n",
            "Loss=0.09223302453756332 Accuracy=97.65: 100% 98/98 [00:18<00:00,  5.18it/s]\n",
            "\n",
            "Test set: Average loss: 0.00062, Accuracy: 9114/10000 (91.140%)\n",
            "\n",
            "Figure(1000x500)\n",
            "Figure(1000x500)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python main.py --dataset cifar10 --model s10resnet --epochs 24 --lr_scheduler onecycle --max_lr 3.75E-02 --batch 512 --anneal_fn linear --pct_start 4/24 --cutout_prob 0.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kudh3DegxY5l"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}